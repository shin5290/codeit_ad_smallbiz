# ì´í˜„ì„ë‹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
## ì´ë¯¸ì§€ ìƒì„± (SDXL, UnifiedImageGenerator)

**ë‹´ë‹¹ ë²”ìœ„**: 
- SDXL ëª¨ë¸ ì„¤ì • ë° ë¡œë“œ
- ì´ë¯¸ì§€ ìƒì„± (text-to-image)
- í›„ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì§•, ì••ì¶•, í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´)
- GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

**í”„ë¡œì íŠ¸ ê¸°ê°„**: 2025-12-29 ~ 2026-01-27

---

## ğŸ“… 1ë‹¨ê³„ (MVP): ~ 2026-01-15

### ğŸ—“ 1ì£¼ì°¨ (12/29 ~ 1/4): í™˜ê²½ ì„¤ì • ë° SDXL ê¸°ë³¸ ì—°ë™

#### Day 1-2 (12/29-12/30): GPU í™˜ê²½ ì„¤ì • (GCP VM)

**Python í™˜ê²½ êµ¬ì„±**
- [ ] GCP VM ì ‘ì† í™•ì¸
- [ ] GPU í™•ì¸
  ```bash
  nvidia-smi
  # NVIDIA L4, Driver 570.x, CUDA 12.6 í™•ì¸
  ```
- [ ] Python ê°€ìƒ í™˜ê²½ ìƒì„±
  ```bash
  cd ~/ad-generator
  python3.10 -m venv venv
  source venv/bin/activate
  ```

**PyTorch ì„¤ì¹˜ (CUDA 12.1)**
- [ ] PyTorch ì„¤ì¹˜
  ```bash
  pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
  ```
- [ ] GPU ë™ì‘ í™•ì¸
  ```python
  import torch
  print(f"CUDA Available: {torch.cuda.is_available()}")
  print(f"CUDA Version: {torch.version.cuda}")
  print(f"GPU Name: {torch.cuda.get_device_name(0)}")
  # ì¶œë ¥: NVIDIA L4
  ```

**ì˜ì¡´ì„± ì„¤ì¹˜**
- [ ] Diffusers, Transformers ì„¤ì¹˜
  ```bash
  pip install diffusers==0.25.0
  pip install transformers==4.36.0
  pip install accelerate==0.25.0
  pip install pillow==10.1.0
  ```
- [ ] ì„¤ì¹˜ í™•ì¸
  ```python
  import diffusers
  import transformers
  print(f"Diffusers: {diffusers.__version__}")
  print(f"Transformers: {transformers.__version__}")
  ```

#### Day 3-5 (12/31-1/2): SDXL ëª¨ë¸ ë¡œë“œ

**UnifiedImageGenerator í´ë˜ìŠ¤ ê¸°ë³¸ êµ¬ì¡°**
- [ ] íŒŒì¼ ìƒì„±: `src/generation/image_generation/unified_generator.py`
- [ ] Import êµ¬ë¬¸
  ```python
  import torch
  from diffusers import StableDiffusionXLPipeline
  from PIL import Image, ImageDraw, ImageFont
  import logging
  import os
  ```
- [ ] í´ë˜ìŠ¤ ì •ì˜
  ```python
  class UnifiedImageGenerator:
      def __init__(self, model_type="sdxl", device="cuda"):
          self.model_type = model_type
          self.device = device if torch.cuda.is_available() else "cpu"
          self.pipeline = None
          self.last_seed = None
  ```

**SDXL ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ**
- [ ] ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ, ì•½ 7GB)
  ```python
  self.pipeline = StableDiffusionXLPipeline.from_pretrained(
      "stabilityai/stable-diffusion-xl-base-1.0",
      torch_dtype=torch.float16 if self.device == "cuda" else torch.float32,
      use_safetensors=True
  )
  ```
- [ ] GPUë¡œ ì´ë™
  ```python
  self.pipeline.to(self.device)
  ```
- [ ] ë¡œë“œ ì‹œê°„ ì¸¡ì •
  ```python
  import time
  start = time.time()
  generator = UnifiedImageGenerator()
  print(f"Model loaded in {time.time() - start:.2f}s")
  ```

**GPU ë©”ëª¨ë¦¬ í™•ì¸**
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
  ```python
  import torch
  print(f"GPU Memory Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
  print(f"GPU Memory Reserved: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")
  ```
- [ ] ìºì‹œ ì •ë¦¬ í…ŒìŠ¤íŠ¸
  ```python
  torch.cuda.empty_cache()
  ```

#### Day 6-7 (1/3-1/4): ê¸°ë³¸ t2i ìƒì„±

**_generate_t2i() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _generate_t2i(self, prompt, resolution):
      import random
      
      # ì‹œë“œ ìƒì„±
      seed = random.randint(0, 2**32 - 1)
      self.last_seed = seed
      generator = torch.Generator(device=self.device).manual_seed(seed)
      
      # ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸
      negative_prompt = "low quality, blurry, text, watermark, bad anatomy"
      
      # ì´ë¯¸ì§€ ìƒì„±
      with torch.no_grad():
          result = self.pipeline(
              prompt=prompt,
              negative_prompt=negative_prompt,
              width=resolution[0],
              height=resolution[1],
              num_inference_steps=30,
              guidance_scale=7.5,
              generator=generator
          )
      
      image = result.images[0]
      
      # GPU ìºì‹œ ì •ë¦¬
      if self.device == "cuda":
          torch.cuda.empty_cache()
      
      return image
  ```

**_get_resolution() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _get_resolution(self, aspect_ratio):
      resolutions = {
          "1:1": (1024, 1024),
          "4:3": (1024, 768),
          "3:4": (768, 1024)
      }
      return resolutions.get(aspect_ratio, (1024, 1024))
  ```

**ìƒì„± í…ŒìŠ¤íŠ¸**
- [ ] í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
  ```python
  prompt = "cafe interior, warm lighting, cozy atmosphere, coffee beans, high quality"
  resolution = (1024, 1024)
  image = generator._generate_t2i(prompt, resolution)
  image.save("test_output.png")
  ```
- [ ] ìƒì„± ì‹œê°„ ì¸¡ì • (ëª©í‘œ: 30ì´ˆ ì´ë‚´)
  ```python
  start = time.time()
  image = generator._generate_t2i(prompt, resolution)
  print(f"Generation time: {time.time() - start:.2f}s")
  ```
- [ ] ê²°ê³¼ ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸

**âœ… 1ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: SDXLë¡œ ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì„±ê³µ

---

### ğŸ—“ 2ì£¼ì°¨ (1/5 ~ 1/11): í›„ì²˜ë¦¬ ë° ìµœì í™”

#### Day 8-10 (1/5-1/7): í›„ì²˜ë¦¬ í•¨ìˆ˜

**_postprocess() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _postprocess(self, image):
      # í˜„ì¬ëŠ” ë³„ë„ ì²˜ë¦¬ ì—†ìŒ
      # í•„ìš” ì‹œ ì¶”ê°€ ì••ì¶• ë¡œì§ êµ¬í˜„
      return image
  ```

**ì´ë¯¸ì§€ ì••ì¶• í…ŒìŠ¤íŠ¸**
- [ ] JPEG ì••ì¶•
  ```python
  import tempfile
  temp_path = tempfile.mktemp(suffix=".jpg")
  image.save(temp_path, "JPEG", quality=85, optimize=True)
  
  # íŒŒì¼ í¬ê¸° í™•ì¸
  import os
  file_size = os.path.getsize(temp_path) / 1024 / 1024
  print(f"File size: {file_size:.2f} MB")
  # ëª©í‘œ: < 2MB
  ```

**ë¹„ìœ¨ë³„ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸**
- [ ] 1:1 ë¹„ìœ¨ (1024x1024)
- [ ] 4:3 ë¹„ìœ¨ (1024x768)
- [ ] 3:4 ë¹„ìœ¨ (768x1024)
- [ ] ê° ë¹„ìœ¨ë³„ í’ˆì§ˆ í™•ì¸

#### Day 11-12 (1/8-1/9): í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´

**_add_text_overlay() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _add_text_overlay(self, image, text, position="bottom"):
      from PIL import ImageDraw, ImageFont
      
      draw = ImageDraw.Draw(image)
      width, height = image.size
      
      # í°íŠ¸ í¬ê¸° ê³„ì‚° (ì´ë¯¸ì§€ ë„ˆë¹„ì˜ 5%)
      font_size = int(width * 0.05)
      
      try:
          # í•œê¸€ í°íŠ¸ ë¡œë“œ
          font = ImageFont.truetype("/usr/share/fonts/truetype/nanum/NanumGothic.ttf", font_size)
      except:
          # í°íŠ¸ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸
          font = ImageFont.load_default()
      
      # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
      bbox = draw.textbbox((0, 0), text, font=font)
      text_width = bbox[2] - bbox[0]
      text_height = bbox[3] - bbox[1]
      
      # ìœ„ì¹˜ ê³„ì‚°
      if position == "bottom":
          x = (width - text_width) // 2
          y = height - text_height - 50
      elif position == "top":
          x = (width - text_width) // 2
          y = 50
      else:  # center
          x = (width - text_width) // 2
          y = (height - text_height) // 2
      
      # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
      padding = 20
      draw.rectangle(
          [(x - padding, y - padding), (x + text_width + padding, y + text_height + padding)],
          fill=(0, 0, 0, 180)
      )
      
      # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
      draw.text((x, y), text, fill="white", font=font)
      
      return image
  ```

**í•œê¸€ í°íŠ¸ ì„¤ì¹˜**
- [ ] NanumGothic ì„¤ì¹˜
  ```bash
  sudo apt-get install fonts-nanum
  ```
- [ ] í°íŠ¸ ê²½ë¡œ í™•ì¸
  ```bash
  fc-list | grep Nanum
  ```
- [ ] í•œê¸€ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
  ```python
  image = generator._generate_t2i(prompt, (1024, 1024))
  image_with_text = generator._add_text_overlay(image, "ë”°ëœ»í•œ ê²¨ìš¸, ìƒˆë¡œìš´ ë§›")
  image_with_text.save("test_with_text.png")
  ```

**í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì˜µì…˜ í…ŒìŠ¤íŠ¸**
- [ ] position="top"
- [ ] position="bottom"
- [ ] position="center"

#### Day 13-14 (1/10-1/11): services.py ì—°ë™

**generate() í•¨ìˆ˜ ì™„ì„±**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def generate(self, prompt, aspect_ratio, ad_copy=None):
      # 1. í•´ìƒë„ ê³„ì‚°
      resolution = self._get_resolution(aspect_ratio)
      
      # 2. t2i ìƒì„±
      image = self._generate_t2i(prompt, resolution)
      
      # 3. í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
      if ad_copy:
          image = self._add_text_overlay(image, ad_copy)
      
      # 4. í›„ì²˜ë¦¬
      image = self._postprocess(image)
      
      # 5. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
      import tempfile
      temp_path = tempfile.mktemp(suffix=".png")
      image.save(temp_path, "PNG", quality=85)
      
      # 6. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
      metadata = {
          "seed": self.last_seed,
          "style": self._extract_style_tags(prompt),
          "model": self.model_type
      }
      
      return {
          "image_path": temp_path,
          "metadata": metadata
      }
  ```

**_extract_style_tags() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _extract_style_tags(self, prompt):
      # ì²« 5ê°œ ë‹¨ì–´ ì¶”ì¶œ
      tags = prompt.split(',')[:5]
      return ', '.join([tag.strip() for tag in tags])
  ```

**services.pyì™€ í†µí•© í…ŒìŠ¤íŠ¸ (2ë²ˆ ë‹´ë‹¹ì í˜‘ì—…)**
- [ ] services.create_advertisement()ì—ì„œ í˜¸ì¶œ
- [ ] ë°˜í™˜ê°’ í˜•ì‹ í™•ì¸
- [ ] ë©”íƒ€ë°ì´í„° DB ì €ì¥ í™•ì¸

**âœ… 2ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: ì´ë¯¸ì§€ ìƒì„± + í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì™„ì„±

---

### ğŸ—“ 3ì£¼ì°¨ (1/12 ~ 1/15): ì—ëŸ¬ ì²˜ë¦¬ ë° ì•ˆì •í™”

#### Day 15-17 (1/12-1/14): ì—ëŸ¬ ì²˜ë¦¬

**GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì²˜ë¦¬**
- [ ] OutOfMemoryError ìºì¹˜
  ```python
  def _generate_t2i(self, prompt, resolution):
      try:
          # ì´ë¯¸ì§€ ìƒì„± ì½”ë“œ
          ...
      except torch.cuda.OutOfMemoryError:
          logger.warning("GPU memory insufficient, clearing cache and retrying...")
          torch.cuda.empty_cache()
          
          # ì¬ì‹œë„ (1íšŒ)
          try:
              result = self.pipeline(...)
          except torch.cuda.OutOfMemoryError:
              logger.error("GPU memory still insufficient after retry")
              raise RuntimeError("GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
      
      return image
  ```

**íƒ€ì„ì•„ì›ƒ ì„¤ì •**
- [ ] ìµœëŒ€ ìƒì„± ì‹œê°„ ì„¤ì • (60ì´ˆ)
  ```python
  import signal
  
  def timeout_handler(signum, frame):
      raise TimeoutError("ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼")
  
  # generate() í•¨ìˆ˜ì—ì„œ
  signal.signal(signal.SIGALRM, timeout_handler)
  signal.alarm(60)  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
  try:
      image = self._generate_t2i(prompt, resolution)
  finally:
      signal.alarm(0)  # íƒ€ì„ì•„ì›ƒ í•´ì œ
  ```

**ì—ëŸ¬ ë¡œê¹…**
- [ ] logger ì„¤ì •
  ```python
  import logging
  logger = logging.getLogger(__name__)
  ```
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
  ```python
  logger.error(f"Image generation failed: {str(e)}", exc_info=True)
  ```

**CPU í´ë°± (ì„ íƒ)**
- [ ] GPU ì˜¤ë¥˜ ì‹œ CPUë¡œ ì „í™˜
  ```python
  if self.device == "cuda":
      try:
          image = self._generate_t2i(prompt, resolution)
      except RuntimeError:
          logger.warning("GPU failed, falling back to CPU")
          self.device = "cpu"
          self.pipeline.to(self.device)
          image = self._generate_t2i(prompt, resolution)
  ```

#### Day 18 (1/15): ìµœì¢… í…ŒìŠ¤íŠ¸

**ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸**
- [ ] ê° ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ (1:1, 4:3, 3:4)
  ```python
  for ratio in ["1:1", "4:3", "3:4"]:
      result = generator.generate(
          prompt="cafe interior, warm lighting",
          aspect_ratio=ratio,
          ad_copy="ë”°ëœ»í•œ ê²¨ìš¸"
      )
      print(f"{ratio}: {result['image_path']}")
  ```

**í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í…ŒìŠ¤íŠ¸**
- [ ] ì§§ì€ í”„ë¡¬í”„íŠ¸ (10ì ì´í•˜)
- [ ] ì¤‘ê°„ í”„ë¡¬í”„íŠ¸ (50ì ë‚´ì™¸)
- [ ] ê¸´ í”„ë¡¬í”„íŠ¸ (100ì ì´ìƒ)

**í•œê¸€ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ í…ŒìŠ¤íŠ¸**
- [ ] ì§§ì€ ë¬¸êµ¬ (10ì)
- [ ] ê¸´ ë¬¸êµ¬ (30ì)
- [ ] íŠ¹ìˆ˜ë¬¸ì í¬í•¨

**ì•ˆì •ì„± í…ŒìŠ¤íŠ¸**
- [ ] 10íšŒ ì—°ì† ìƒì„±
- [ ] GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸
  ```python
  for i in range(10):
      result = generator.generate(...)
      print(f"Iteration {i}: GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
  ```

**âœ… 3ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: ì´ë¯¸ì§€ ìƒì„± ì•ˆì •í™”

---

## ğŸ“… 2ë‹¨ê³„ (ê°œì„ ): 2026-01-16 ~ 27

### ğŸ—“ 4ì£¼ì°¨ (1/16 ~ 1/22): ê³ ê¸‰ ê¸°ëŠ¥

#### Day 19-21 (1/16-1/18): Flux.1 ëª¨ë¸ ì§€ì› (ì„ íƒ)

**Flux.1 ëª¨ë¸ ë¡œë“œ**
- [ ] Flux íŒŒì´í”„ë¼ì¸ ì„¤ì¹˜
  ```bash
  pip install diffusers[flux]
  ```
- [ ] Flux ëª¨ë¸ ë¡œë“œ
  ```python
  from diffusers import FluxPipeline
  
  if model_type == "flux":
      self.pipeline = FluxPipeline.from_pretrained(
          "black-forest-labs/FLUX.1-schnell",
          torch_dtype=torch.bfloat16
      )
      self.pipeline.to(self.device)
  ```

**decide_model() í•¨ìˆ˜**
- [ ] í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
  ```python
  def decide_model(self, prompt):
      # ì• ë‹ˆë©”ì´ì…˜, ë¹ ë¥¸ ìƒì„± â†’ SDXL
      if "anime" in prompt.lower() or "fast" in prompt.lower():
          return "sdxl"
      
      # ì‚¬ì‹¤ì , ê³ í’ˆì§ˆ â†’ Flux
      if "realistic" in prompt.lower() or "photorealistic" in prompt.lower():
          return "flux"
      
      return "sdxl"  # ê¸°ë³¸ê°’
  ```

**ëª¨ë¸ ì „í™˜ ë¡œì§**
- [ ] generate() í•¨ìˆ˜ ìˆ˜ì •
  ```python
  def generate(self, prompt, aspect_ratio, ad_copy=None, model_type=None):
      # ëª¨ë¸ ì„ íƒ
      if model_type is None:
          model_type = self.decide_model(prompt)
      
      # ëª¨ë¸ ì „í™˜ (í•„ìš” ì‹œ)
      if model_type != self.model_type:
          self._switch_model(model_type)
      
      # ì´ë¯¸ì§€ ìƒì„±
      ...
  ```

#### Day 22-24 (1/19-1/21): ControlNet (ì„ íƒ)

**ControlNet ì„¤ì¹˜**
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜
  ```bash
  pip install controlnet_aux
  ```

**ë¡œê³  ì´ë¯¸ì§€ ì²˜ë¦¬**
- [ ] ë¡œê³  ì´ë¯¸ì§€ ë¡œë“œ
  ```python
  def _load_logo(self, logo_path):
      from PIL import Image
      logo = Image.open(logo_path)
      logo = logo.resize((256, 256))
      return logo
  ```

**ControlNet ì ìš© (ë³µì¡ë„ ë†’ìŒ, ì„ íƒ)**
- [ ] ControlNet íŒŒì´í”„ë¼ì¸ ë¡œë“œ
- [ ] ë¡œê³  ìœ„ì¹˜ ì œì–´
- [ ] ìƒì„± í…ŒìŠ¤íŠ¸

### ğŸ—“ 5ì£¼ì°¨ (1/23 ~ 1/27): ë§ˆë¬´ë¦¬

#### Day 25-27 (1/23-1/25): ì„±ëŠ¥ ìµœì í™”

**ì¶”ë¡  ë‹¨ê³„ ì¡°ì •**
- [ ] num_inference_steps ìµœì í™”
  - [ ] ë¹ ë¥¸ ìƒì„±: 20 steps
  - [ ] ê¸°ë³¸: 30 steps
  - [ ] ê³ í’ˆì§ˆ: 50 steps

**ë©”ëª¨ë¦¬ ìµœì í™”**
- [ ] Half precision (fp16) ì‚¬ìš©
- [ ] attention_slicing í™œì„±í™”
  ```python
  self.pipeline.enable_attention_slicing()
  ```
- [ ] VAE tiling (ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ìš©)
  ```python
  self.pipeline.enable_vae_tiling()
  ```

**ë°°ì¹˜ ìƒì„± (ì„ íƒ)**
- [ ] ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ìƒì„±
  ```python
  result = self.pipeline(
      prompt=[prompt] * 4,  # 4ê°œ ë™ì‹œ ìƒì„±
      ...
  )
  images = result.images
  ```

#### Day 28-30 (1/26-1/27): Docker ì»¨í…Œì´ë„ˆí™”

**Dockerfile ì‘ì„± (5ë²ˆ ë‹´ë‹¹ì í˜‘ì—…)**
- [ ] GPU ì§€ì› Docker ì´ë¯¸ì§€
- [ ] ëª¨ë¸ ê°€ì¤‘ì¹˜ í¬í•¨ ì—¬ë¶€ ê²°ì •

**ë¬¸ì„œí™”**
- [ ] UnifiedImageGenerator ì‚¬ìš© ê°€ì´ë“œ
  ```markdown
  ## UnifiedImageGenerator ì‚¬ìš©ë²•
  
  ### ì´ˆê¸°í™”
  generator = UnifiedImageGenerator(model_type="sdxl", device="cuda")
  
  ### ì´ë¯¸ì§€ ìƒì„±
  result = generator.generate(
      prompt="cafe interior, warm lighting",
      aspect_ratio="3:4",
      ad_copy="ë”°ëœ»í•œ ê²¨ìš¸"
  )
  
  ### ì¶œë ¥
  - result["image_path"]: ì„ì‹œ íŒŒì¼ ê²½ë¡œ
  - result["metadata"]: {"seed", "style", "model"}
  ```

**âœ… ìµœì¢… ì™„ë£Œ**: ì´ë¯¸ì§€ ìƒì„± ëª¨ë“ˆ ì™„ì„± ë° ë°°í¬ ì¤€ë¹„

---

## ğŸ“Š ì§„í–‰ ìƒí™© ì¶”ì 

### 1ë‹¨ê³„ (MVP) ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½

**1ì£¼ì°¨**: GPU í™˜ê²½ + SDXL ë¡œë“œ + ê¸°ë³¸ ìƒì„±
- [ ] PyTorch CUDA 12.1 ì„¤ì¹˜
- [ ] SDXL ëª¨ë¸ ë¡œë“œ (7GB)
- [ ] ê¸°ë³¸ t2i ìƒì„± í…ŒìŠ¤íŠ¸

**2ì£¼ì°¨**: í›„ì²˜ë¦¬ + í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
- [ ] ë¹„ìœ¨ë³„ í•´ìƒë„ ì„¤ì •
- [ ] ì´ë¯¸ì§€ ì••ì¶•
- [ ] í•œê¸€ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´

**3ì£¼ì°¨**: ì—ëŸ¬ ì²˜ë¦¬ + ì•ˆì •í™”
- [ ] GPU ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ì²˜ë¦¬
- [ ] íƒ€ì„ì•„ì›ƒ ì„¤ì •
- [ ] ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸

### 2ë‹¨ê³„ (ê°œì„ ) ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½

**4ì£¼ì°¨**: Flux.1 + ControlNet (ì„ íƒ)
- [ ] Flux.1 ëª¨ë¸ ì§€ì›
- [ ] ëª¨ë¸ ìë™ ì„ íƒ
- [ ] ControlNet (ì„ íƒ)

**5ì£¼ì°¨**: ì„±ëŠ¥ ìµœì í™” + Docker
- [ ] ì¶”ë¡  ë‹¨ê³„ ì¡°ì •
- [ ] ë©”ëª¨ë¦¬ ìµœì í™”
- [ ] ë¬¸ì„œí™”

---

## ğŸ¤ í˜‘ì—… í¬ì¸íŠ¸

### ì§„ìˆ˜ê²½ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] services.create_advertisement()ì—ì„œ generate() í˜¸ì¶œ
- [ ] ë°˜í™˜ê°’ í˜•ì‹ í™•ì¸
  - [ ] {"image_path": str, "metadata": dict}
- [ ] ë©”íƒ€ë°ì´í„° DB ì €ì¥ í™•ì¸

### ë°°í˜„ì„ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] PromptTemplateManagerì—ì„œ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
- [ ] TextGeneratorì—ì„œ ìƒì„±í•œ ad_copy ì‚¬ìš©

### ì‹ ìŠ¹ëª©ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ (save_image)
- [ ] ì„ì‹œ íŒŒì¼ ì •ë¦¬
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ

---

## ğŸ“ ì°¸ê³  ì‚¬í•­

### SDXL ëª¨ë¸ íŒŒë¼ë¯¸í„°
```python
# ê¸°ë³¸ ì„¤ì •
num_inference_steps=30  # ì¶”ë¡  ë‹¨ê³„ (20-50)
guidance_scale=7.5      # CFG scale (5-15)
width=1024             # ë„ˆë¹„
height=1024            # ë†’ì´
```

### GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- SDXL ëª¨ë¸ ë¡œë“œ: ì•½ 6-7GB
- ì´ë¯¸ì§€ ìƒì„± ì‹œ: ì•½ 2-3GB ì¶”ê°€
- ì´: ì•½ 10GB í•„ìš” (L4 GPU: 24GB, ì¶©ë¶„í•¨)

### ìœ ìš©í•œ ëª…ë ¹ì–´
```bash
# GPU í™•ì¸
nvidia-smi

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜ í™•ì¸
ls -lh ~/.cache/huggingface/hub/
```

### í”„ë¡¬í”„íŠ¸ ì‘ì„± íŒ
```
Good prompt:
"cafe interior, warm lighting, cozy atmosphere, coffee beans, latte art, winter season, high quality, detailed"

Bad prompt:
"ì¹´í˜" (í•œê¸€, ë„ˆë¬´ ì§§ìŒ)
```

---

**ì‘ì„±ì¼**: 2026-01-02 
**ë‹´ë‹¹ì**: ì´í˜„ì„ë‹˜ (ì´ë¯¸ì§€ ìƒì„±)  
**ìµœì¢… ìˆ˜ì •**: 2026-01-02
