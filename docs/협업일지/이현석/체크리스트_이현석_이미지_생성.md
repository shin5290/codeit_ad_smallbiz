# ì´í˜„ì„ë‹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
## ì´ë¯¸ì§€ ìƒì„± (SDXL ëª¨ë¸ í™œìš©)

**ë‹´ë‹¹ ë²”ìœ„**: 
- SDXL ëª¨ë¸ ì„¤ì • ë° ë¡œë“œ
- ì´ë¯¸ì§€ ìƒì„± (text-to-image)
- í›„ì²˜ë¦¬ (ë¦¬ì‚¬ì´ì§•, ì••ì¶•, í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´)
- ì´ë¯¸ì§€ ìƒì„± ì‹œ GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

**í”„ë¡œì íŠ¸ ê¸°ê°„**: 2025-12-29 ~ 2026-01-27

---

## ğŸ“… 1ë‹¨ê³„ (MVP): ~ 2026-01-15

### ğŸ—“ 1ì£¼ì°¨ (12/29 ~ 1/4): í™˜ê²½ ì„¤ì • ë° SDXL ê¸°ë³¸ ì—°ë™

#### Day 1-2 (12/29-12/30): GPU í™˜ê²½ ì„¤ì • (GCP VM)

**Python í™˜ê²½ êµ¬ì„±**
- [V] GCP VM ì ‘ì† í™•ì¸
- [V] GPU í™•ì¸: NVIDIA L4, Driver 570.x, CUDA 12.6
  - í™•ì¸ ëª…ë ¹ì–´: nvidia-smi
- [V] Python ê°€ìƒ í™˜ê²½ ìƒì„±
  source /opt/jhub-venv/bin/activate

**PyTorch ì„¤ì¹˜ (CUDA 12.6)**
- [V] PyTorch ì„¤ì¹˜ 2.6.0
- [ ] GPU ë™ì‘ í™•ì¸
  ```python
  import torch
  print(f"CUDA Available: {torch.cuda.is_available()}")
  print(f"CUDA Version: {torch.version.cuda}")
  print(f"GPU Name: {torch.cuda.get_device_name(0)}")
  # ì¶œë ¥: NVIDIA L4
  ```

**ì˜ì¡´ì„± ì„¤ì¹˜**
- [ ] Diffusers, Transformers ì„¤ì¹˜
  ```bash
  pip install diffusers==0.25.0
  pip install transformers==4.36.0
  pip install accelerate==0.25.0
  pip install pillow==10.1.0
  ```
- [ ] ì„¤ì¹˜ í™•ì¸
  ```python
  import diffusers
  import transformers
  print(f"Diffusers: {diffusers.__version__}")
  print(f"Transformers: {transformers.__version__}")
  ```

#### Day 3-5 (12/31-1/2): ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜ êµ¬í˜„

**ë…¸ë“œ ì‹œìŠ¤í…œ ì„¤ê³„**
- [V] íŒŒì¼ êµ¬ì¡° ìƒì„±
  - nodes/base.py: ì¶”ìƒ í´ë˜ìŠ¤ BaseNode
  - nodes/generation.py: Text2ImageNode
  - workflow.py: ImageGenerationWorkflow
  - config.py: ì„¤ì • ê´€ë¦¬

**BaseNode ì¶”ìƒ í´ë˜ìŠ¤ êµ¬í˜„**
- [V] ì¶”ìƒ ë©”ì„œë“œ ì •ì˜
  ```python
  from abc import ABC, abstractmethod

  class BaseNode(ABC):
      @abstractmethod
      def process(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
          pass

      @abstractmethod
      def get_required_inputs(self) -> list:
          pass

      @abstractmethod
      def get_output_keys(self) -> list:
          pass
  ```
- [V] ë©”íƒ€ë°ì´í„° ì¶”ì  (NodeMetadata)
- [V] execute() ë©”ì„œë“œë¡œ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •

**ImageGenerationWorkflow êµ¬í˜„**
- [V] ë…¸ë“œ ì²´ì´ë‹ ì‹œìŠ¤í…œ
  ```python
  workflow = ImageGenerationWorkflow(name="Test")
  workflow.add_node(Text2ImageNode())
  result = workflow.run({"prompt": "..."})
  ```
- [V] ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë° ë¦¬í¬íŠ¸

**ë©€í‹° ëª¨ë¸ ì‹œìŠ¤í…œ êµ¬ì¶•**
- [V] ìŠ¤íƒ€ì¼ë³„ ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸ ì§€ì›
  - Ultra Realistic: SG161222/RealVisXL_V4.0
  - Semi Realistic: John6666/bss-equinox-il-semi-realistic-model-v25-sdxl
  - Anime: cagliostrolab/animagine-xl-3.1
- [V] ë¡œì»¬ ëª¨ë¸ ìºì‹± (models/ í´ë”)
- [V] ìë™ ì–¸ë¡œë“œ ë©”ëª¨ë¦¬ ê´€ë¦¬
- [V] Variant fallback ì²˜ë¦¬ (fp16 ë¯¸ì§€ì› ëª¨ë¸ ëŒ€ì‘)

#### Day 6-7 (1/3-1/4): Text2ImageNode êµ¬í˜„ ë° ìŠ¤íƒ€ì¼ í…ŒìŠ¤íŠ¸

**Text2ImageNode êµ¬í˜„**
- [V] SDXL íŒŒì´í”„ë¼ì¸ lazy loading
  ```python
  def _load_pipeline(self):
      # ë¡œì»¬ ìºì‹œ í™•ì¸
      local_model_path = MODELS_DIR / self.model_id.replace("/", "--")

      # ë¡œì»¬ì— ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ
      if local_model_path.exists():
          self.pipe = StableDiffusionXLPipeline.from_pretrained(...)
      else:
          # HuggingFaceì—ì„œ ë‹¤ìš´ë¡œë“œ ë° ìºì‹±
          ...
  ```
- [V] process() ë©”ì„œë“œë¡œ ì´ë¯¸ì§€ ìƒì„±
- [V] aspect_ratio ì§€ì› (1:1, 3:4, 4:3, 16:9, 9:16)
- [V] negative_prompt ê°œì„  (ì†ê°€ë½ ê´€ë ¨ í¬í•¨)

**config.py ì‘ì„±**
- [V] AspectRatioTemplates í´ë˜ìŠ¤
- [V] GenerationConfig (steps, CFG, negative prompt)
- [V] ModelConfig (ë””ë°”ì´ìŠ¤, dtype, variant)
- [V] ì—…ì¢…ë³„ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹

**ìŠ¤íƒ€ì¼ë³„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±**
- [V] test_workflow.py ì‘ì„±
- [V] 9ê°€ì§€ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
  - Ultra Realistic: ë² ì´ì»¤ë¦¬, ë°”ë¦¬ìŠ¤íƒ€, í—¤ì–´ìƒµ
  - Semi Realistic: ê½ƒì§‘, ê½ƒì§‘ ì§ì›, ì„œì 
  - Anime: ì¹´í˜, ë°”ë¦¬ìŠ¤íƒ€, ì œë¹µì‚¬
- [V] ê° ìŠ¤íƒ€ì¼ë³„ ë‹¤ë¥¸ ëª¨ë¸ ìë™ ë¡œë“œ
- [V] test_images/ í´ë”ì— ê²°ê³¼ ì €ì¥

**âœ… 1ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì™„ì„± ë° ë©€í‹° ëª¨ë¸ ì‹œìŠ¤í…œ êµ¬ì¶•

---

### ğŸ—“ 2ì£¼ì°¨ (1/5 ~ 1/11): ì½”ë“œ ê°œì„  ë° ë°±ì—”ë“œ í†µí•©

#### Day 8 (1/5): ì½”ë“œ í’ˆì§ˆ ê°œì„  ë° ë°±ì—”ë“œ í†µí•© ë ˆì´ì–´

**ì½”ë“œ í’ˆì§ˆ ê°œì„ **
- [V] ì¤‘ë³µ ì €ì¥ ë¡œì§ ì œê±° (ë””ìŠ¤í¬ ê³µê°„ ìµœì í™”)
- [V] ìŠ¤íƒ€ì¼ë³„ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ë¶„ë¦¬ (STYLE_NEGATIVE_PROMPTS)
- [V] VAE í´ë˜ìŠ¤ ë³€ìˆ˜ ìºì‹± (_vae_cache)
- [V] get_negative_prompt(style) ë©”ì„œë“œ êµ¬í˜„
- [V] ìƒì„± ì†ë„ ë¬¸ì„œ ìˆ˜ì • (15-20ì´ˆ ì‹¤ì¸¡ê°’ ë°˜ì˜)

**ë°±ì—”ë“œ í†µí•© ë ˆì´ì–´ (generator.py)**
- [V] generate_and_save_image() í•¨ìˆ˜ êµ¬í˜„
  - Text Generator ì¶œë ¥ â†’ ì´ë¯¸ì§€ ìƒì„± â†’ ì €ì¥ â†’ ê²½ë¡œ ë°˜í™˜
  - business_id ê¸°ë°˜ í´ë” êµ¬ì¡°
  - ìë™ íŒŒì¼ëª… ìƒì„± (timestamp_uuid.png)
  - ìƒëŒ€ ê²½ë¡œ ë°˜í™˜ (URL ìƒì„±ìš©)
- [V] generate_batch_images() í•¨ìˆ˜ êµ¬í˜„
- [V] STYLE_MODEL_MAP ì •ì˜ (ìŠ¤íƒ€ì¼ë³„ ëª¨ë¸ ìë™ ì„ íƒ)

#### Day 9-10 (1/6-1/7): í›„ì²˜ë¦¬ í•¨ìˆ˜

**_postprocess() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _postprocess(self, image):
      # í˜„ì¬ëŠ” ë³„ë„ ì²˜ë¦¬ ì—†ìŒ
      # í•„ìš” ì‹œ ì¶”ê°€ ì••ì¶• ë¡œì§ êµ¬í˜„
      return image
  ```

**ì´ë¯¸ì§€ ì••ì¶• í…ŒìŠ¤íŠ¸**
- [ ] JPEG ì••ì¶•
  ```python
  import tempfile
  temp_path = tempfile.mktemp(suffix=".jpg")
  image.save(temp_path, "JPEG", quality=85, optimize=True)
  
  # íŒŒì¼ í¬ê¸° í™•ì¸
  import os
  file_size = os.path.getsize(temp_path) / 1024 / 1024
  print(f"File size: {file_size:.2f} MB")
  # ëª©í‘œ: < 2MB
  ```

**ë¹„ìœ¨ë³„ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸**
- [ ] 1:1 ë¹„ìœ¨ (1024x1024)
- [ ] 4:3 ë¹„ìœ¨ (1024x768)
- [ ] 3:4 ë¹„ìœ¨ (768x1024)
- [ ] ê° ë¹„ìœ¨ë³„ í’ˆì§ˆ í™•ì¸

#### Day 11-12 (1/8-1/9): í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´

**_add_text_overlay() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _add_text_overlay(self, image, text, position="bottom"):
      from PIL import ImageDraw, ImageFont
      
      draw = ImageDraw.Draw(image)
      width, height = image.size
      
      # í°íŠ¸ í¬ê¸° ê³„ì‚° (ì´ë¯¸ì§€ ë„ˆë¹„ì˜ 5%)
      font_size = int(width * 0.05)
      
      try:
          # í•œê¸€ í°íŠ¸ ë¡œë“œ
          font = ImageFont.truetype("/usr/share/fonts/truetype/nanum/NanumGothic.ttf", font_size)
      except:
          # í°íŠ¸ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸
          font = ImageFont.load_default()
      
      # í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚°
      bbox = draw.textbbox((0, 0), text, font=font)
      text_width = bbox[2] - bbox[0]
      text_height = bbox[3] - bbox[1]
      
      # ìœ„ì¹˜ ê³„ì‚°
      if position == "bottom":
          x = (width - text_width) // 2
          y = height - text_height - 50
      elif position == "top":
          x = (width - text_width) // 2
          y = 50
      else:  # center
          x = (width - text_width) // 2
          y = (height - text_height) // 2
      
      # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤
      padding = 20
      draw.rectangle(
          [(x - padding, y - padding), (x + text_width + padding, y + text_height + padding)],
          fill=(0, 0, 0, 180)
      )
      
      # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
      draw.text((x, y), text, fill="white", font=font)
      
      return image
  ```

**í•œê¸€ í°íŠ¸ ì„¤ì¹˜**
- [ ] NanumGothic ì„¤ì¹˜
  ```bash
  sudo apt-get install fonts-nanum
  ```
- [ ] í°íŠ¸ ê²½ë¡œ í™•ì¸
  ```bash
  fc-list | grep Nanum
  ```
- [ ] í•œê¸€ í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸
  ```python
  image = generator._generate_t2i(prompt, (1024, 1024))
  image_with_text = generator._add_text_overlay(image, "ë”°ëœ»í•œ ê²¨ìš¸, ìƒˆë¡œìš´ ë§›")
  image_with_text.save("test_with_text.png")
  ```

**í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì˜µì…˜ í…ŒìŠ¤íŠ¸**
- [ ] position="top"
- [ ] position="bottom"
- [ ] position="center"

#### Day 13-14 (1/10-1/11): services.py ì—°ë™

**generate() í•¨ìˆ˜ ì™„ì„±**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def generate(self, prompt, aspect_ratio, ad_copy=None):
      # 1. í•´ìƒë„ ê³„ì‚°
      resolution = self._get_resolution(aspect_ratio)
      
      # 2. t2i ìƒì„±
      image = self._generate_t2i(prompt, resolution)
      
      # 3. í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
      if ad_copy:
          image = self._add_text_overlay(image, ad_copy)
      
      # 4. í›„ì²˜ë¦¬
      image = self._postprocess(image)
      
      # 5. ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
      import tempfile
      temp_path = tempfile.mktemp(suffix=".png")
      image.save(temp_path, "PNG", quality=85)
      
      # 6. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
      metadata = {
          "seed": self.last_seed,
          "style": self._extract_style_tags(prompt),
          "model": self.model_type
      }
      
      return {
          "image_path": temp_path,
          "metadata": metadata
      }
  ```

**_extract_style_tags() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def _extract_style_tags(self, prompt):
      # ì²« 5ê°œ ë‹¨ì–´ ì¶”ì¶œ
      tags = prompt.split(',')[:5]
      return ', '.join([tag.strip() for tag in tags])
  ```

**services.pyì™€ í†µí•© í…ŒìŠ¤íŠ¸ (ì§„ìˆ˜ê²½ë‹˜ê³¼ í˜‘ì—…)**
- [ ] services.create_advertisement()ì—ì„œ í˜¸ì¶œ
- [ ] ë°˜í™˜ê°’ í˜•ì‹ í™•ì¸
- [ ] ë©”íƒ€ë°ì´í„° DB ì €ì¥ í™•ì¸

**âœ… 2ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: ì´ë¯¸ì§€ ìƒì„± + í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì™„ì„±

---

### ğŸ—“ 3ì£¼ì°¨ (1/12 ~ 1/15): ì—ëŸ¬ ì²˜ë¦¬ ë° ì•ˆì •í™”

#### Day 15-17 (1/12-1/14): ì—ëŸ¬ ì²˜ë¦¬

**GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì²˜ë¦¬**
- [ ] OutOfMemoryError ìºì¹˜
  ```python
  def _generate_t2i(self, prompt, resolution):
      try:
          # ì´ë¯¸ì§€ ìƒì„± ì½”ë“œ
          ...
      except torch.cuda.OutOfMemoryError:
          logger.warning("GPU memory insufficient, clearing cache and retrying...")
          torch.cuda.empty_cache()
          
          # ì¬ì‹œë„ (1íšŒ)
          try:
              result = self.pipeline(...)
          except torch.cuda.OutOfMemoryError:
              logger.error("GPU memory still insufficient after retry")
              raise RuntimeError("GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
      
      return image
  ```

**íƒ€ì„ì•„ì›ƒ ì„¤ì •**
- [ ] ìµœëŒ€ ìƒì„± ì‹œê°„ ì„¤ì • (60ì´ˆ)
  ```python
  import signal
  
  def timeout_handler(signum, frame):
      raise TimeoutError("ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼")
  
  # generate() í•¨ìˆ˜ì—ì„œ
  signal.signal(signal.SIGALRM, timeout_handler)
  signal.alarm(60)  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ
  try:
      image = self._generate_t2i(prompt, resolution)
  finally:
      signal.alarm(0)  # íƒ€ì„ì•„ì›ƒ í•´ì œ
  ```

**ì—ëŸ¬ ë¡œê¹…**
- [ ] logger ì„¤ì •
  ```python
  import logging
  logger = logging.getLogger(__name__)
  ```
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ê¸°ë¡
  ```python
  logger.error(f"Image generation failed: {str(e)}", exc_info=True)
  ```

**CPU í´ë°± (ì„ íƒ)**
- [ ] GPU ì˜¤ë¥˜ ì‹œ CPUë¡œ ì „í™˜
  ```python
  if self.device == "cuda":
      try:
          image = self._generate_t2i(prompt, resolution)
      except RuntimeError:
          logger.warning("GPU failed, falling back to CPU")
          self.device = "cpu"
          self.pipeline.to(self.device)
          image = self._generate_t2i(prompt, resolution)
  ```

#### Day 18 (1/15): ìµœì¢… í…ŒìŠ¤íŠ¸

**ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸**
- [ ] ê° ë¹„ìœ¨ í…ŒìŠ¤íŠ¸ (1:1, 4:3, 3:4)
  ```python
  for ratio in ["1:1", "4:3", "3:4"]:
      result = generator.generate(
          prompt="cafe interior, warm lighting",
          aspect_ratio=ratio,
          ad_copy="ë”°ëœ»í•œ ê²¨ìš¸"
      )
      print(f"{ratio}: {result['image_path']}")
  ```

**í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í…ŒìŠ¤íŠ¸**
- [ ] ì§§ì€ í”„ë¡¬í”„íŠ¸ (10ì ì´í•˜)
- [ ] ì¤‘ê°„ í”„ë¡¬í”„íŠ¸ (50ì ë‚´ì™¸)
- [ ] ê¸´ í”„ë¡¬í”„íŠ¸ (100ì ì´ìƒ)

**í•œê¸€ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ í…ŒìŠ¤íŠ¸**
- [ ] ì§§ì€ ë¬¸êµ¬ (10ì)
- [ ] ê¸´ ë¬¸êµ¬ (30ì)
- [ ] íŠ¹ìˆ˜ë¬¸ì í¬í•¨

**ì•ˆì •ì„± í…ŒìŠ¤íŠ¸**
- [ ] 10íšŒ ì—°ì† ìƒì„±
- [ ] GPU ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸
  ```python
  for i in range(10):
      result = generator.generate(...)
      print(f"Iteration {i}: GPU Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
  ```

**âœ… 3ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: ì´ë¯¸ì§€ ìƒì„± ì•ˆì •í™”

---

## ğŸ“… 2ë‹¨ê³„ (ê°œì„ ): 2026-01-16 ~ 27

### ğŸ—“ 4ì£¼ì°¨ (1/16 ~ 1/22): ê³ ê¸‰ ê¸°ëŠ¥

#### Day 19-21 (1/16-1/18): Flux.1 ëª¨ë¸ ì§€ì› (ì„ íƒ)

**Flux.1 ëª¨ë¸ ë¡œë“œ**
- [ ] Flux íŒŒì´í”„ë¼ì¸ ì„¤ì¹˜
  ```bash
  pip install diffusers[flux]
  ```
- [ ] Flux ëª¨ë¸ ë¡œë“œ
  ```python
  from diffusers import FluxPipeline
  
  if model_type == "flux":
      self.pipeline = FluxPipeline.from_pretrained(
          "black-forest-labs/FLUX.1-schnell",
          torch_dtype=torch.bfloat16
      )
      self.pipeline.to(self.device)
  ```

**decide_model() í•¨ìˆ˜**
- [ ] í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
  ```python
  def decide_model(self, prompt):
      # ì• ë‹ˆë©”ì´ì…˜, ë¹ ë¥¸ ìƒì„± â†’ SDXL
      if "anime" in prompt.lower() or "fast" in prompt.lower():
          return "sdxl"
      
      # ì‚¬ì‹¤ì , ê³ í’ˆì§ˆ â†’ Flux
      if "realistic" in prompt.lower() or "photorealistic" in prompt.lower():
          return "flux"
      
      return "sdxl"  # ê¸°ë³¸ê°’
  ```

**ëª¨ë¸ ì „í™˜ ë¡œì§**
- [ ] generate() í•¨ìˆ˜ ìˆ˜ì •
  ```python
  def generate(self, prompt, aspect_ratio, ad_copy=None, model_type=None):
      # ëª¨ë¸ ì„ íƒ
      if model_type is None:
          model_type = self.decide_model(prompt)
      
      # ëª¨ë¸ ì „í™˜ (í•„ìš” ì‹œ)
      if model_type != self.model_type:
          self._switch_model(model_type)
      
      # ì´ë¯¸ì§€ ìƒì„±
      ...
  ```

#### Day 22-24 (1/19-1/21): ControlNet (ì„ íƒ)

**ControlNet ì„¤ì¹˜**
- [ ] ì˜ì¡´ì„± ì„¤ì¹˜
  ```bash
  pip install controlnet_aux
  ```

**ë¡œê³  ì´ë¯¸ì§€ ì²˜ë¦¬**
- [ ] ë¡œê³  ì´ë¯¸ì§€ ë¡œë“œ
  ```python
  def _load_logo(self, logo_path):
      from PIL import Image
      logo = Image.open(logo_path)
      logo = logo.resize((256, 256))
      return logo
  ```

**ControlNet ì ìš© (ë³µì¡ë„ ë†’ìŒ, ì„ íƒ)**
- [ ] ControlNet íŒŒì´í”„ë¼ì¸ ë¡œë“œ
- [ ] ë¡œê³  ìœ„ì¹˜ ì œì–´
- [ ] ìƒì„± í…ŒìŠ¤íŠ¸

### ğŸ—“ 5ì£¼ì°¨ (1/23 ~ 1/27): ë§ˆë¬´ë¦¬

#### Day 25-27 (1/23-1/25): ì„±ëŠ¥ ìµœì í™”

**ì¶”ë¡  ë‹¨ê³„ ì¡°ì •**
- [ ] num_inference_steps ìµœì í™”
  - [ ] ë¹ ë¥¸ ìƒì„±: 20 steps
  - [ ] ê¸°ë³¸: 30 steps
  - [ ] ê³ í’ˆì§ˆ: 50 steps

**ë©”ëª¨ë¦¬ ìµœì í™”**
- [ ] Half precision (fp16) ì‚¬ìš©
- [ ] attention_slicing í™œì„±í™”
  ```python
  self.pipeline.enable_attention_slicing()
  ```
- [ ] VAE tiling (ëŒ€ìš©ëŸ‰ ì´ë¯¸ì§€ìš©)
  ```python
  self.pipeline.enable_vae_tiling()
  ```

**ë°°ì¹˜ ìƒì„± (ì„ íƒ)**
- [ ] ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ìƒì„±
  ```python
  result = self.pipeline(
      prompt=[prompt] * 4,  # 4ê°œ ë™ì‹œ ìƒì„±
      ...
  )
  images = result.images
  ```

#### Day 28-30 (1/26-1/27): Docker ì»¨í…Œì´ë„ˆí™”

**Dockerfile ì‘ì„± (ì‹ ìŠ¹ëª©ë‹˜ê³¼ í˜‘ì—…)**
- [ ] GPU ì§€ì› Docker ì´ë¯¸ì§€
- [ ] ëª¨ë¸ ê°€ì¤‘ì¹˜ í¬í•¨ ì—¬ë¶€ ê²°ì •

**ë¬¸ì„œí™”**
- [ ] UnifiedImageGenerator ì‚¬ìš© ê°€ì´ë“œ
  ```markdown
  ## UnifiedImageGenerator ì‚¬ìš©ë²•
  
  ### ì´ˆê¸°í™”
  generator = UnifiedImageGenerator(model_type="sdxl", device="cuda")
  
  ### ì´ë¯¸ì§€ ìƒì„±
  result = generator.generate(
      prompt="cafe interior, warm lighting",
      aspect_ratio="3:4",
      ad_copy="ë”°ëœ»í•œ ê²¨ìš¸"
  )
  
  ### ì¶œë ¥
  - result["image_path"]: ì„ì‹œ íŒŒì¼ ê²½ë¡œ
  - result["metadata"]: {"seed", "style", "model"}
  ```

**âœ… ìµœì¢… ì™„ë£Œ**: ì´ë¯¸ì§€ ìƒì„± ëª¨ë“ˆ ì™„ì„± ë° ë°°í¬ ì¤€ë¹„

---

## ğŸ“Š ì§„í–‰ ìƒí™© ì¶”ì 

### 1ë‹¨ê³„ (MVP) ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½

**1ì£¼ì°¨**: GPU í™˜ê²½ + ë…¸ë“œ ì•„í‚¤í…ì²˜ + ë©€í‹° ëª¨ë¸ ì‹œìŠ¤í…œ
- [V] PyTorch CUDA 12.6 ì„¤ì¹˜ ë° GPU í™•ì¸
- [V] ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜ êµ¬í˜„ (BaseNode, Workflow)
- [V] ë©€í‹° ëª¨ë¸ ì‹œìŠ¤í…œ (RealVisXL, Equinox, Animagine)
- [V] ë¡œì»¬ ìºì‹± ë° ìë™ ì–¸ë¡œë“œ
- [V] ìŠ¤íƒ€ì¼ë³„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (9ê°œ ì¼€ì´ìŠ¤)

**2ì£¼ì°¨**: ì½”ë“œ ê°œì„  + ë°±ì—”ë“œ í†µí•©
- [V] ì½”ë“œ í’ˆì§ˆ ê°œì„  (ì¤‘ë³µ ì €ì¥ ì œê±°, VAE ìºì‹±, ìŠ¤íƒ€ì¼ë³„ ë„¤ê±°í‹°ë¸Œ)
- [V] generator.py ë°±ì—”ë“œ í†µí•© ë ˆì´ì–´ êµ¬í˜„
- [V] ìƒì„± ì†ë„ ë¬¸ì„œ ì—…ë°ì´íŠ¸
- [ ] ì „ì²˜ë¦¬/í›„ì²˜ë¦¬ ë…¸ë“œ êµ¬í˜„

**3ì£¼ì°¨**: ì—ëŸ¬ ì²˜ë¦¬ + ì•ˆì •í™”
- [ ] GPU ë©”ëª¨ë¦¬ ì˜¤ë¥˜ ì²˜ë¦¬
- [ ] íƒ€ì„ì•„ì›ƒ ì„¤ì •
- [ ] ë‹¤ì–‘í•œ ì¼€ì´ìŠ¤ í…ŒìŠ¤íŠ¸

### 2ë‹¨ê³„ (ê°œì„ ) ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½

**4ì£¼ì°¨**: Flux.1 + ControlNet (ì„ íƒ)
- [ ] Flux.1 ëª¨ë¸ ì§€ì›
- [ ] ëª¨ë¸ ìë™ ì„ íƒ
- [ ] ControlNet (ì„ íƒ)

**5ì£¼ì°¨**: ì„±ëŠ¥ ìµœì í™” + Docker
- [ ] ì¶”ë¡  ë‹¨ê³„ ì¡°ì •
- [ ] ë©”ëª¨ë¦¬ ìµœì í™”
- [ ] ë¬¸ì„œí™”

---

## ğŸ¤ í˜‘ì—… í¬ì¸íŠ¸

### ì§„ìˆ˜ê²½ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] services.create_advertisement()ì—ì„œ generate() í˜¸ì¶œ
- [ ] ë°˜í™˜ê°’ í˜•ì‹ í™•ì¸
  - [ ] {"image_path": str, "metadata": dict}
- [ ] ë©”íƒ€ë°ì´í„° DB ì €ì¥ í™•ì¸

### ë°°í˜„ì„ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] PromptTemplateManagerì—ì„œ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
- [ ] TextGeneratorì—ì„œ ìƒì„±í•œ ad_copy ì‚¬ìš©

### ì‹ ìŠ¹ëª©ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ (save_image)
- [ ] ì„ì‹œ íŒŒì¼ ì •ë¦¬
- [ ] Docker ì´ë¯¸ì§€ ë¹Œë“œ

---

## ğŸ“ ì°¸ê³  ì‚¬í•­

### SDXL ëª¨ë¸ íŒŒë¼ë¯¸í„°
```python
# ê¸°ë³¸ ì„¤ì •
num_inference_steps=30  # ì¶”ë¡  ë‹¨ê³„ (20-50)
guidance_scale=7.5      # CFG scale (5-15)
width=1024             # ë„ˆë¹„
height=1024            # ë†’ì´
```

### GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
- SDXL ëª¨ë¸ ë¡œë“œ: ì•½ 6-7GB
- ì´ë¯¸ì§€ ìƒì„± ì‹œ: ì•½ 2-3GB ì¶”ê°€
- ì´: ì•½ 10GB í•„ìš” (L4 GPU: 22GB, ì¶©ë¶„í•¨)
- ìë™ ì–¸ë¡œë“œë¡œ ëª¨ë¸ êµì²´ ì‹œì—ë„ ì•ˆì •ì  ìš´ì˜

### ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸
- Ultra Realistic: SG161222/RealVisXL_V4.0 (~6.5GB)
- Semi Realistic: John6666/bss-equinox-il-semi-realistic-model-v25-sdxl (~6.5GB)
- Anime: cagliostrolab/animagine-xl-3.1 (~6.5GB)

### ìœ ìš©í•œ ëª…ë ¹ì–´
```bash
# GPU í™•ì¸
nvidia-smi

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
python -c "import torch; torch.cuda.empty_cache()"

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜ í™•ì¸
ls -lh ~/.cache/huggingface/hub/
```

### í”„ë¡¬í”„íŠ¸ ì‘ì„± íŒ
```
Good prompt:
"cafe interior, warm lighting, cozy atmosphere, coffee beans, latte art, winter season, high quality, detailed"

Bad prompt:
"ì¹´í˜" (í•œê¸€, ë„ˆë¬´ ì§§ìŒ)
```

---

**ì‘ì„±ì¼**: 2026-01-02
**ë‹´ë‹¹ì**: ì´í˜„ì„ (ì´ë¯¸ì§€ ìƒì„±)
**ìµœì¢… ìˆ˜ì •**: 2026-01-05

---

## ğŸ“ ì£¼ìš” êµ¬í˜„ ì‚¬í•­ (2026-01-05 ê¸°ì¤€)

### âœ… ì™„ë£Œëœ ê¸°ëŠ¥
1. **ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜**
   - BaseNode ì¶”ìƒ í´ë˜ìŠ¤
   - ImageGenerationWorkflow ì²´ì´ë‹ ì‹œìŠ¤í…œ
   - ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì 

2. **ë©€í‹° ëª¨ë¸ ì‹œìŠ¤í…œ**
   - 3ê°€ì§€ ìŠ¤íƒ€ì¼ë³„ ì „ë¬¸ ëª¨ë¸ ì§€ì›
   - ë¡œì»¬ ìºì‹± ì‹œìŠ¤í…œ (models/ í´ë”)
   - ìë™ ì–¸ë¡œë“œ ë©”ëª¨ë¦¬ ê´€ë¦¬
   - Variant fallback ìë™ ì²˜ë¦¬
   - VAE í´ë˜ìŠ¤ ë³€ìˆ˜ ìºì‹± (ì¤‘ë³µ ë¡œë“œ ë°©ì§€)

3. **Text2ImageNode**
   - SDXL íŒŒì´í”„ë¼ì¸ lazy loading
   - 5ê°€ì§€ aspect ratio ì§€ì›
   - ìŠ¤íƒ€ì¼ë³„ ë„¤ê±°í‹°ë¸Œ í”„ë¡¬í”„íŠ¸ ìë™ ì„ íƒ
   - ì—…ì¢…ë³„ ìŠ¤íƒ€ì¼ í”„ë¦¬ì…‹

4. **í…ŒìŠ¤íŠ¸ ì¸í”„ë¼**
   - 9ê°€ì§€ ì¼€ì´ìŠ¤ ìë™ í…ŒìŠ¤íŠ¸
   - ìŠ¤íƒ€ì¼ë³„ ëª¨ë¸ ìë™ ì „í™˜
   - ê²°ê³¼ ì´ë¯¸ì§€ ìë™ ì €ì¥

5. **ë°±ì—”ë“œ í†µí•© ë ˆì´ì–´ (generator.py)** â­ NEW
   - generate_and_save_image(): ë©”ì¸ ì§„ì…ì  í•¨ìˆ˜
   - generate_batch_images(): ë°°ì¹˜ ìƒì„± í•¨ìˆ˜
   - business_id ê¸°ë°˜ ì €ì¥ êµ¬ì¡°
   - ì„±ê³µ/ì‹¤íŒ¨ ì²˜ë¦¬ ë° ì—ëŸ¬ ë¡œê¹…
   - ìƒì„± ì‹œê°„ ì¸¡ì •

### ğŸš§ ì§„í–‰ ì˜ˆì •
1. ì „ì²˜ë¦¬ ë…¸ë“œ êµ¬í˜„ (BackgroundRemovalNode, ResizeNode)
2. í›„ì²˜ë¦¬ ë…¸ë“œ êµ¬í˜„ (TextOverlayNode, ImageCompressionNode)
3. Text Generator ì—°ë™ í…ŒìŠ¤íŠ¸ (ë°°í˜„ì„ë‹˜)
4. API ì—”ë“œí¬ì¸íŠ¸ í†µí•© (ì§„ìˆ˜ê²½ë‹˜)
5. ìŠ¤í† ë¦¬ì§€ ëª¨ë“ˆ ì—°ë™ (ì‹ ìŠ¹ëª©ë‹˜)
