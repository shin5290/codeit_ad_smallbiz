# ë°°í˜„ì„ë‹˜ ì²´í¬ë¦¬ìŠ¤íŠ¸
## í…ìŠ¤íŠ¸ ë° í”„ë¡¬í”„íŠ¸ ìƒì„± (GPT API)

**ë‹´ë‹¹ ë²”ìœ„**: 
- OpenAI GPT API ì—°ë™
- ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
- ê´‘ê³  ë¬¸êµ¬ ìƒì„±
- API ë¹„ìš© ìµœì í™”

**í”„ë¡œì íŠ¸ ê¸°ê°„**: 2025-12-29 ~ 2026-01-27

---

## ğŸ“… 1ë‹¨ê³„ (MVP): ~ 2026-01-15

### ğŸ—“ 1ì£¼ì°¨ (12/29 ~ 1/4): GPT API ì—°ë™

#### Day 1-2 (12/29-12/30): í™˜ê²½ ì„¤ì •

**OpenAI API í‚¤ ì €ì¥(.env)**
- [X] .env íŒŒì¼ì— ì €ì¥
  ```bash
  OPENAI_API_KEY=sk-...
  ```

**ì˜ì¡´ì„± ì„¤ì¹˜**
- [X] OpenAI Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
  ```bash
  pip install openai==1.6.1
  ```
- [X] ì„¤ì¹˜ í™•ì¸
  ```python
  import openai
  print(openai.__version__)
  ```

**API ì—°ê²° í…ŒìŠ¤íŠ¸**
- [X] ê¸°ë³¸ API í˜¸ì¶œ í…ŒìŠ¤íŠ¸
  ```python
  from openai import OpenAI
  # api_keyëŠ” .envì— ì €ì¥ëœ OPENAI_API_KEYë¥¼ í™œìš©í•˜ê²Œ í•´ì•¼ í•¨
  client = OpenAI(api_key="sk-...")
  
  response = client.chat.completions.create(
      model="gpt-4o-mini",
      messages=[{"role": "user", "content": "Hello!"}]
  )
  print(response.choices[0].message.content)
  ```

#### Day 3-5 (12/31-1/2): TextGenerator í´ë˜ìŠ¤

**íŒŒì¼ ìƒì„±**
- [X] íŒŒì¼ ìƒì„±: `src/generation/text_generation/text_generator.py`
- [X] Import êµ¬ë¬¸
  ```python
  import os
  from dotenv import load_dotenv
  from openai import OpenAI
  
  load_dotenv()
  ```

**TextGenerator í´ë˜ìŠ¤ ê¸°ë³¸ êµ¬ì¡°**
- [X] í´ë˜ìŠ¤ ì •ì˜
  ```python
  class TextGenerator:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
  ```

**generate_ad_copy() í•¨ìˆ˜**
- [X] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
  ```python
 base_prompt=f"""ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ê´‘ê³  ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê·œì¹™:
- {max_length}ì ì´ë‚´ (ê³µë°± í¬í•¨)
- ë²ˆí˜¸, íŠ¹ìˆ˜ë¬¸ì ì—†ì´ ë¬¸êµ¬ë§Œ ì‘ì„±
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ê´‘ê³  ë¬¸êµ¬ 1ê°œë§Œ ìƒì„±"""
  ```
  
- [X] í•¨ìˆ˜ êµ¬í˜„
  ```python
  def generate_ad_copy(self, user_input, tone="warm", max_length=20):
        """
        ê´‘ê³  ë¬¸êµ¬ ìƒì„±
        
        Args:
            user_input (str): ì‚¬ìš©ì ìš”ì²­ í…ìŠ¤íŠ¸
                ì˜ˆ: "ì¹´í˜ ì‹ ë©”ë‰´ í™ë³´, ë”°ëœ»í•œ ëŠë‚Œ, ê²¨ìš¸"
            tone (str): í†¤ ì•¤ ë§¤ë„ˆ ("warm", "professional", "friendly")
            max_length (int): ìµœëŒ€ ê¸€ì ìˆ˜ (ê¸°ë³¸ 20ì)
        
        Returns:
            str: ìƒì„±ëœ ê´‘ê³  ë¬¸êµ¬
                ì˜ˆ: "ë”°ëœ»í•œ ê²¨ìš¸, ìƒˆë¡œìš´ ë§›"
        """
        
        print(f"ğŸ“ ê´‘ê³  ë¬¸êµ¬ ìƒì„± ì¤‘...")
        print(f"   ì…ë ¥: {user_input}")
        print(f"   í†¤: {tone}, ìµœëŒ€ {max_length}ì")
        
        try:
            # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„ íƒ
            system_prompt = self._get_system_prompt(tone, max_length)
            
            # 2. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            user_prompt = self._build_user_prompt(user_input, max_length)
            
            # 3. GPT API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=100
            )
            
            # 4. ì‘ë‹µ ì¶”ì¶œ
            ad_copy = response.choices[0].message.content.strip()
            
            # 5. í›„ì²˜ë¦¬
            ad_copy = self._postprocess(ad_copy, max_length)
            
            print(f"âœ… ìƒì„± ì™„ë£Œ: {ad_copy}")
            return ad_copy
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._get_fallback_copy()
    
    def _get_system_prompt(self, tone, max_length):
        """í†¤ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        
        base_prompt = f"""ë‹¹ì‹ ì€ ì†Œìƒê³µì¸ì„ ìœ„í•œ ì „ë¬¸ ê´‘ê³  ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
ì§§ê³  ì„íŒ©íŠ¸ ìˆëŠ” ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê·œì¹™:
- {max_length}ì ì´ë‚´ (ê³µë°± í¬í•¨)
- ë²ˆí˜¸, íŠ¹ìˆ˜ë¬¸ì ì—†ì´ ë¬¸êµ¬ë§Œ ì‘ì„±
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ê´‘ê³  ë¬¸êµ¬ 1ê°œë§Œ ìƒì„±"""
        
        tone_styles = {
            "warm": "ë”°ëœ»í•˜ê³  ê°ì„±ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. í¸ì•ˆí•˜ê³  ì•„ëŠ‘í•œ ëŠë‚Œì„ ì£¼ì„¸ìš”.",
            "professional": "ì „ë¬¸ì ì´ê³  ì‹ ë¢°ê° ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ê²©ì‹ ìˆê³  ì„¸ë ¨ëœ ëŠë‚Œì„ ì£¼ì„¸ìš”.",
            "friendly": "ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ëŒ€í™”í•˜ë“¯ ìì—°ìŠ¤ëŸ¬ìš´ ëŠë‚Œì„ ì£¼ì„¸ìš”.",
            "energetic": "í™œê¸°ì°¨ê³  ì—­ë™ì ì¸ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì—´ì •ì ì´ê³  ê¸ì •ì ì¸ ëŠë‚Œì„ ì£¼ì„¸ìš”."
        }
        
        tone_guide = tone_styles.get(tone, tone_styles["warm"])
        
        return f"{base_prompt}\n\ní†¤ ì•¤ ë§¤ë„ˆ:\n{tone_guide}"
    
    def _build_user_prompt(self, user_input, max_length):
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        return f"""ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ ê´‘ê³  ë¬¸êµ¬ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”:

{user_input}

ìš”êµ¬ì‚¬í•­:
- {max_length}ì ì´ë‚´
- ê´‘ê³  ë¬¸êµ¬ë§Œ ì‘ì„± (ì„¤ëª…, ë²ˆí˜¸ ë“± ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œì™¸)
- ê°ì„±ì ì´ë©´ì„œë„ ëª…í™•í•œ ë©”ì‹œì§€ ì „ë‹¬

ê´‘ê³  ë¬¸êµ¬:"""

def _postprocess(self, text, max_length):
        """í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬"""
        
        # 1. ë¶ˆí•„ìš”í•œ ë¬¸ì ì œê±°
        text = text.replace("1. ", "").replace("2. ", "").replace("- ", "")
        text = text.replace('"', '').replace("'", "").replace('ã€Œ', '').replace('ã€', '')
        text = text.strip()
        
        # 2. ê¸¸ì´ ì œí•œ
        if len(text) > max_length:
            text = text[:max_length].strip()
        
        # 3. ë¹ˆ ë¬¸ìì—´ ì²´í¬
        if not text:
            return self._get_fallback_copy()
        
        return text
    
    def _get_fallback_copy(self):
        """GPT ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¬¸êµ¬ ë°˜í™˜"""
        return "íŠ¹ë³„í•œ ìˆœê°„ì„ í•¨ê»˜í•˜ì„¸ìš”"
  ```

**í…ŒìŠ¤íŠ¸**
- [X] ë‹¤ì–‘í•œ ì…ë ¥ í…ŒìŠ¤íŠ¸
  ```python
  gen = TextGenerator(api_key="sk-...")
  
  # ì¹´í˜
  copy1 = gen.generate_ad_copy("ì¹´í˜ ì‹ ë©”ë‰´ í™ë³´, ê²¨ìš¸ ì‹œì¦Œ")
  print(f"ì¹´í˜: {copy1}")
  
  # í—¬ìŠ¤ì¥
  copy2 = gen.generate_ad_copy("í—¬ìŠ¤ì¥ íšŒì› ëª¨ì§‘, ì‹ ë…„ íŠ¹ê°€")
  print(f"í—¬ìŠ¤ì¥: {copy2}")
  
  # ê½ƒì§‘
  copy3 = gen.generate_ad_copy("ê½ƒì§‘ ë´„ ì´ë²¤íŠ¸, ì¥ë¯¸ í• ì¸")
  print(f"ê½ƒì§‘: {copy3}")
  ```

#### Day 6-7 (1/3-1/4): ì‘ë‹µ í’ˆì§ˆ í™•ì¸

**ì‘ë‹µ í’ˆì§ˆ í…ŒìŠ¤íŠ¸**
- [X] 20ì ì´ë‚´ ì œì•½ í™•ì¸
- [X] í†¤ ì í•©ì„± í™•ì¸ (warm, professional ë“±)
- [X] ì´ëª¨ì§€ í¬í•¨ ì—¬ë¶€ í™•ì¸
- [X] íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ í™•ì¸

**ì—ëŸ¬ ì²˜ë¦¬**
- [X] API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ í´ë°±
- [ ] íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬ (10ì´ˆ)
- [ ] ë¡œê·¸ ê¸°ë¡

**âœ… 1ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: GPT APIë¡œ ê´‘ê³  ë¬¸êµ¬ ìƒì„± ì„±ê³µ

---

### ğŸ—“ 2ì£¼ì°¨ (1/5 ~ 1/11): í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ê´€ë¦¬

#### Day 8-10 (1/5-1/7): PromptTemplateManager í´ë˜ìŠ¤

**íŒŒì¼ ìƒì„±**
- [X] íŒŒì¼ ìƒì„±: `src/generation/text_generation/prompt_manager.py`
- [X] Import êµ¬ë¬¸
  ```python
  import os
  from dotenv import load_dotenv
  from openai import OpenAI

  load_dotenv()
  ```

**PromptTemplateManager í´ë˜ìŠ¤**
- [X] í´ë˜ìŠ¤ ì •ì˜
  ```python
  class PromptTemplateManager:
    def __init__(self):
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        self.client = OpenAI(api_key=api_key)
        self.model = "gpt-4o-mini"
  ```

**generate_image_prompt() í•¨ìˆ˜**
- [X] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‘ì„±
  ```python
  base_prompt = """You are an expert in creating image generation prompts for Stable Diffusion.
Convert Korean user input into English tags that AI image generators can understand.

CRITICAL RULES:
1. Output ONLY English tags
2. Separate tags with commas
3. Focus on VISUAL elements only (no abstract concepts)
4. Maximum 20 tags
5. Include: subject, setting, atmosphere, lighting, style, quality

Output format example:
cafe interior, new menu board, warm lighting, cozy atmosphere, winter season, coffee cups, wooden table, soft focus, professional photography, high quality"""
  ```
- [X] í•¨ìˆ˜ êµ¬í˜„
  ```python
  def generate_image_prompt(self, user_input, style="realistic"):
        """
        ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸(íƒœê·¸) ìƒì„±
        
        Args:
            user_input (str): ì‚¬ìš©ì ìš”ì²­
                ì˜ˆ: "ì¹´í˜ ì‹ ë©”ë‰´ í™ë³´, ë”°ëœ»í•œ ëŠë‚Œ, ê²¨ìš¸"
            style (str): ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ ("realistic", "illustration", "minimal")
        
        Returns:
            str: ì˜ë¬¸ íƒœê·¸ (ì‰¼í‘œë¡œ êµ¬ë¶„)
                ì˜ˆ: "cafe interior, new menu board, warm lighting, cozy atmosphere, ..."
        """
        
        print(f"ğŸ¨ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
        print(f"   ì…ë ¥: {user_input}")
        print(f"   ìŠ¤íƒ€ì¼: {style}")
        
        try:
            # 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = self._get_system_prompt(style)
            
            # 2. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
            user_prompt = self._build_user_prompt(user_input)
            
            # 3. GPT API í˜¸ì¶œ
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.5,  # ì•ˆì •ì ì¸ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì¶¤
                max_tokens=200
            )
            
            # 4. ì‘ë‹µ ì¶”ì¶œ
            prompt = response.choices[0].message.content.strip()
            
            # 5. í›„ì²˜ë¦¬
            prompt = self._postprocess(prompt, style)
            
            print(f"âœ… ìƒì„± ì™„ë£Œ")
            print(f"   í”„ë¡¬í”„íŠ¸: {prompt[:80]}...")
            
            return prompt
            
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return self._get_fallback_prompt(style)
    
    def _get_system_prompt(self, style):
        base_prompt = """You are an expert in creating image generation prompts for Stable Diffusion.
Convert Korean user input into English tags that AI image generators can understand.

CRITICAL RULES:
1. Output ONLY English tags
2. Separate tags with commas
3. Focus on VISUAL elements only (no abstract concepts)
4. Maximum 20 tags
5. Include: subject, setting, atmosphere, lighting, style, quality

Output format example:
cafe interior, new menu board, warm lighting, cozy atmosphere, winter season, coffee cups, wooden table, soft focus, professional photography, high quality"""

        style_guides = {
            "realistic": """
Style focus: Photorealistic, professional photography
Include: natural lighting, detailed textures, realistic colors, sharp focus
Avoid: cartoon, anime, illustration, painting""",
            
            "illustration": """
Style focus: Hand-drawn, artistic illustration
Include: soft colors, artistic style, illustrated, painted, creative
Avoid: photorealistic, photograph, 3D render""",
            
            "minimal": """
Style focus: Clean, simple, minimalist design
Include: minimal, clean, simple, white background, modern, elegant
Avoid: cluttered, busy, complex, detailed"""
        }
        
        style_guide = style_guides.get(style, style_guides["realistic"])
        
        return f"{base_prompt}\n\n{style_guide}"
    
    def _build_user_prompt(self, user_input):
        return f"""Convert this Korean description into English image generation tags:

{user_input}

Remember:
- ONLY English tags
- Comma-separated
- Visual elements only
- 20 tags maximum

Tags:"""
    
    def _postprocess(self, prompt, style):
        # 1. í•œê¸€ ì œê±°
        prompt = ''.join(char for char in prompt if ord(char) < 0x3131 or ord(char) > 0x318e)
        prompt = ''.join(char for char in prompt if ord(char) < 0xac00 or ord(char) > 0xd7a3)
        
        # 2. ë¶ˆí•„ìš”í•œ ë¬¸ì ì •ë¦¬
        prompt = prompt.replace('"', '').replace("'", "").strip()
        
        # 3. í’ˆì§ˆ íƒœê·¸ ì¶”ê°€
        quality_tags = self._get_quality_tags(style)
        
        # ì´ë¯¸ í’ˆì§ˆ íƒœê·¸ê°€ ìˆëŠ”ì§€ í™•ì¸
        if "high quality" not in prompt.lower():
            prompt = f"{prompt}, {quality_tags}"
        
        # 4. ì¤‘ë³µ ì œê±°
        tags = [tag.strip() for tag in prompt.split(',')]
        unique_tags = []
        seen = set()
        
        for tag in tags:
            tag_lower = tag.lower()
            if tag_lower not in seen and tag:
                unique_tags.append(tag)
                seen.add(tag_lower)
        
        # 5. 20ê°œ ì œí•œ
        if len(unique_tags) > 20:
            unique_tags = unique_tags[:20]
        
        return ', '.join(unique_tags)
    
    def _get_quality_tags(self, style):
        quality_tags = {
            "realistic": "high quality, detailed, professional photography, sharp focus, 4k",
            "illustration": "high quality, detailed artwork, professional illustration, artistic",
            "minimal": "high quality, clean design, professional, elegant, modern"
        }
        
        return quality_tags.get(style, quality_tags["realistic"])
    
    def _get_fallback_prompt(self, style):
        fallback = {
            "realistic": "professional photography, high quality, detailed, sharp focus, natural lighting",
            "illustration": "artistic illustration, hand-drawn style, colorful, creative, high quality",
            "minimal": "minimal design, clean, simple, modern, elegant, white background"
        }
        
        return fallback.get(style, fallback["realistic"])
  ```

**í…ŒìŠ¤íŠ¸**
- [X] ë‹¤ì–‘í•œ ì—…ì¢… í…ŒìŠ¤íŠ¸
  ```python
  pm = PromptTemplateManager(api_key="sk-...")
  
  # ì¹´í˜
  prompt1 = pm.generate_image_prompt("ì¹´í˜ ì‹ ë©”ë‰´ í™ë³´, ë”°ëœ»í•œ ëŠë‚Œ")
  print(f"ì¹´í˜ í”„ë¡¬í”„íŠ¸: {prompt1}")
  
  # í—¬ìŠ¤ì¥
  prompt2 = pm.generate_image_prompt("í—¬ìŠ¤ì¥ íšŒì› ëª¨ì§‘, ê°•ë ¬í•œ ì´ë¯¸ì§€")
  print(f"í—¬ìŠ¤ì¥ í”„ë¡¬í”„íŠ¸: {prompt2}")
  
  # ê½ƒì§‘
  prompt3 = pm.generate_image_prompt("ê½ƒì§‘ ë´„ ì´ë²¤íŠ¸, í™”ì‚¬í•œ ë¶„ìœ„ê¸°")
  print(f"ê½ƒì§‘ í”„ë¡¬í”„íŠ¸: {prompt3}")
  ```

#### Day 11-12 (1/8-1/9): í†µí•© í…ŒìŠ¤íŠ¸

**í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸ (3ë²ˆ ë‹´ë‹¹ì í˜‘ì—…)**
- [ ] PromptTemplateManagerë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
- [ ] UnifiedImageGeneratorì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬
- [ ] ìƒì„±ëœ ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸
- [ ] í”„ë¡¬í”„íŠ¸ì™€ ì´ë¯¸ì§€ ì¼ì¹˜ë„ í™•ì¸

**í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í†µí•© í…ŒìŠ¤íŠ¸**
- [ ] ê´‘ê³  ë¬¸êµ¬ ìƒì„±
- [ ] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
- [ ] ì´ë¯¸ì§€ ìƒì„± (í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ í¬í•¨)
- [ ] ì „ì²´ ê²°ê³¼ í™•ì¸

#### Day 13-14 (1/10-1/11): ì—ëŸ¬ ì²˜ë¦¬

**API í˜¸ì¶œ ì‹¤íŒ¨ ì²˜ë¦¬**
- [ ] ì¬ì‹œë„ ë¡œì§ (ìµœëŒ€ 3íšŒ)
  ```python
  def _call_api_with_retry(self, messages, max_retries=3):
      for attempt in range(max_retries):
          try:
              response = self.client.chat.completions.create(
                  model="gpt-4o-mini",
                  messages=messages,
                  temperature=0.7,
                  max_tokens=150
              )
              return response
          except Exception as e:
              logger.warning(f"API call failed (attempt {attempt+1}/{max_retries}): {e}")
              if attempt == max_retries - 1:
                  raise
              time.sleep(2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
  ```
- [ ] íƒ€ì„ì•„ì›ƒ 10ì´ˆ
- [ ] í´ë°± ì‘ë‹µ

**ë¹„ìš© ëª¨ë‹ˆí„°ë§**
- [ ] API í˜¸ì¶œ íšŸìˆ˜ ë¡œê·¸
  ```python
  logger.info(f"GPT API call count: {self.call_count}")
  ```
- [ ] í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ
  ```python
  if len(user_input) > 500:
      user_input = user_input[:500]
  ```

**âœ… 2ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: í”„ë¡¬í”„íŠ¸ ìƒì„± â†’ ì´ë¯¸ì§€ ìƒì„± ì „ì²´ í”Œë¡œìš°

---

### ğŸ—“ 3ì£¼ì°¨ (1/12 ~ 1/15): í’ˆì§ˆ ê°œì„ 

#### Day 15-17 (1/12-1/14): ì‘ë‹µ í›„ì²˜ë¦¬

**ê¸¸ì´ ì œí•œ**
- [ ] ê´‘ê³  ë¬¸êµ¬ 30ì ì´ˆê³¼ ì‹œ ìë¥´ê¸°
  ```python
  if len(ad_copy) > 30:
      ad_copy = ad_copy[:27] + "..."
  ```
- [ ] í”„ë¡¬í”„íŠ¸ 150í† í° ì œí•œ

**íŠ¹ìˆ˜ë¬¸ì ì œê±°**
- [ ] ì´ëª¨ì§€ ì œê±°
  ```python
  import re
  ad_copy = re.sub(r'[\U00010000-\U0010ffff]', '', ad_copy)
  ```
- [ ] ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±° (*, #, @ ë“±)
  ```python
  ad_copy = re.sub(r'[*#@]', '', ad_copy)
  ```

**í’ˆì§ˆ ê²€ì¦**
- [ ] ë¹ˆ ì‘ë‹µ ì²˜ë¦¬
  ```python
  if not ad_copy.strip():
      ad_copy = "íŠ¹ë³„í•œ ìˆœê°„ì„ ìœ„í•œ ì„ íƒ"
  ```
- [ ] ë¶€ì ì ˆí•œ ë‚´ìš© í•„í„°ë§ (ì„ íƒ)

#### Day 18 (1/15): ìµœì¢… í…ŒìŠ¤íŠ¸

**ë‹¤ì–‘í•œ ì—…ì¢… í…ŒìŠ¤íŠ¸**
- [ ] ì¹´í˜
- [ ] ì‹ë‹¹
- [ ] í—¬ìŠ¤ì¥
- [ ] ê½ƒì§‘
- [ ] ë¯¸ìš©ì‹¤
- [ ] ì˜ë¥˜ ë§¤ì¥
- [ ] ì„œì 
- [ ] ë² ì´ì»¤ë¦¬

**í†¤ë³„ í…ŒìŠ¤íŠ¸**
- [ ] warm (ë”°ëœ»í•œ)
- [ ] professional (ì „ë¬¸ì ì¸)
- [ ] friendly (ì¹œê·¼í•œ)
- [ ] energetic (ì—­ë™ì ì¸)

**âœ… 3ì£¼ì°¨ ë§ˆì¼ìŠ¤í†¤**: í”„ë¡¬í”„íŠ¸ ìƒì„± ì•ˆì •í™”

---

## ğŸ“… 2ë‹¨ê³„ (ê°œì„ ): 2026-01-16 ~ 27

### ğŸ—“ 4ì£¼ì°¨ (1/16 ~ 1/22): ê³ ê¸‰ ê¸°ëŠ¥

#### Day 19-21 (1/16-1/18): í‚¤ì›Œë“œ ì¶”ì¶œ

**extract_keywords() í•¨ìˆ˜**
- [ ] í•¨ìˆ˜ ì‘ì„±
  ```python
  def extract_keywords(self, text):
      system_prompt = """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.
      ê²°ê³¼ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•˜ì„¸ìš”."""
      
      user_prompt = f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ:\n{text}"
      
      response = self.client.chat.completions.create(
          model="gpt-4o-mini",
          messages=[
              {"role": "system", "content": system_prompt},
              {"role": "user", "content": user_prompt}
          ],
          temperature=0.5,
          max_tokens=100
      )
      
      keywords_str = response.choices[0].message.content.strip()
      keywords = [k.strip() for k in keywords_str.split(',')]
      
      return keywords
  ```
- [ ] í…ŒìŠ¤íŠ¸

**í†¤ë³„ í”„ë¡¬í”„íŠ¸ ê°œì„ **
- [ ] tone íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë³€ê²½
- [ ] Few-shot ì˜ˆì‹œ ì¶”ê°€
  ```python
  few_shot_examples = {
      "warm": [
          {"input": "ì¹´í˜ ì‹ ë©”ë‰´", "output": "ë”°ëœ»í•œ ê²¨ìš¸, ìƒˆë¡œìš´ ë§›"},
          {"input": "ë² ì´ì»¤ë¦¬ í• ì¸", "output": "ì˜¤ëŠ˜ë§Œì˜ íŠ¹ë³„í•œ ì„ íƒ"}
      ],
      ...
  }
  ```

#### Day 22-24 (1/19-1/21): API ì¬ì‹œë„ ë¡œì§

**ì¬ì‹œë„ ë¡œì§ ê°œì„ **
- [ ] ì§€ìˆ˜ ë°±ì˜¤í”„ ì ìš©
- [ ] ì—ëŸ¬ íƒ€ì…ë³„ ì²˜ë¦¬
  - [ ] RateLimitError â†’ ê¸´ ëŒ€ê¸°
  - [ ] APIError â†’ ì¬ì‹œë„
  - [ ] InvalidRequestError â†’ ì¦‰ì‹œ ì‹¤íŒ¨

**API ë¹„ìš© ìµœì í™”**
- [ ] í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ìµœì†Œí™”
- [ ] ìºì‹± (ì„ íƒ)
  ```python
  @lru_cache(maxsize=100)
  def generate_ad_copy_cached(self, user_input, tone):
      return self.generate_ad_copy(user_input, tone)
  ```
- [ ] í˜¸ì¶œ íšŸìˆ˜ ëª¨ë‹ˆí„°ë§

### ğŸ—“ 5ì£¼ì°¨ (1/23 ~ 1/27): ë§ˆë¬´ë¦¬

#### Day 25-27 (1/23-1/25): í’ˆì§ˆ ê°œì„ 

**Few-shot ì˜ˆì‹œ ì¶”ê°€**
- [ ] ê° í†¤ë³„ 5ê°œ ì˜ˆì‹œ ì¶”ê°€
- [ ] ì—…ì¢…ë³„ ì˜ˆì‹œ ì¶”ê°€

**ì‘ë‹µ í’ˆì§ˆ ê²€ì¦**
- [ ] ê¸¸ì´ í™•ì¸ (10-30ì)
- [ ] í•œê¸€ ë¹„ìœ¨ í™•ì¸ (80% ì´ìƒ)
- [ ] ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ í™•ì¸

#### Day 28-30 (1/26-1/27): ë¬¸ì„œí™”

**ì‚¬ìš© ê°€ì´ë“œ ì‘ì„±**
- [ ] API í‚¤ ì„¤ì • ë°©ë²•
- [ ] í•¨ìˆ˜ë³„ ì‚¬ìš© ì˜ˆì‹œ
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë°©ë²•

**âœ… ìµœì¢… ì™„ë£Œ**: í…ìŠ¤íŠ¸ ë° í”„ë¡¬í”„íŠ¸ ìƒì„± ëª¨ë“ˆ ì™„ì„±

---

## ğŸ“Š ì§„í–‰ ìƒí™© ì¶”ì 

### 1ë‹¨ê³„ (MVP) ìš”ì•½
- [ ] GPT API ì—°ë™
- [ ] TextGenerator í´ë˜ìŠ¤
- [ ] PromptTemplateManager í´ë˜ìŠ¤
- [ ] ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„

### 2ë‹¨ê³„ (ê°œì„ ) ìš”ì•½
- [ ] í‚¤ì›Œë“œ ì¶”ì¶œ ê¸°ëŠ¥
- [ ] í†¤ë³„ í”„ë¡¬í”„íŠ¸ ê°œì„ 
- [ ] API ë¹„ìš© ìµœì í™”
- [ ] í’ˆì§ˆ ê²€ì¦ ê°•í™”

---

## ğŸ¤ í˜‘ì—… í¬ì¸íŠ¸

### ì§„ìˆ˜ê²½ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] services.create_advertisement()ì—ì„œ í˜¸ì¶œ
- [ ] ë°˜í™˜ê°’ í˜•ì‹ í™•ì¸

### ì´í˜„ì„ë‹˜ê³¼ì˜ í˜‘ì—…
- [ ] ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ìƒì„±
- [ ] ê´‘ê³  ë¬¸êµ¬ë¥¼ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ë¡œ ì‚¬ìš©

---

## ğŸ“ ì°¸ê³  ì‚¬í•­

### OpenAI API ì‚¬ìš©ëŸ‰ í™•ì¸
https://platform.openai.com/usage

### gpt-4o-mini ê°€ê²© (2024ë…„ ê¸°ì¤€)
- Input: $0.15 / 1M tokens
- Output: $0.6 / 1M tokens

### ì˜ˆìƒ ë¹„ìš© (1íšŒ ìƒì„±)
- í”„ë¡¬í”„íŠ¸ ìƒì„±: ~300 tokens â†’ $0.0003
- ê´‘ê³  ë¬¸êµ¬ ìƒì„±: ~200 tokens â†’ $0.0002
- ì´: ~$0.0005 / 1íšŒ

---

**ì‘ì„±ì¼**: 2026-01-02  
**ë‹´ë‹¹ì**: ë°°í˜„ì„ (í…ìŠ¤íŠ¸ ë° í”„ë¡¬í”„íŠ¸ ìƒì„±)  
**ìµœì¢… ìˆ˜ì •**: 2026-01-05
