# ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œ ê²°ê³¼ ë³´ê³ ì„œ

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

**ëª©í‘œ**: ì†Œìƒê³µì¸ì„ ìœ„í•œ ê´‘ê³  ì´ë¯¸ì§€ ìë™ ìƒì„± ì‹œìŠ¤í…œ êµ¬ì¶•
**ê¸°ê°„**: 2025-12 ~ 2026-01
**í•µì‹¬ ì„±ê³¼**: ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜ + Z-Image Turbo ê¸°ë°˜ íš¨ìœ¨ì  ìƒì„± ì‹œìŠ¤í…œ

---

## 1. ì‹œìŠ¤í…œ ê°œë°œ ê³¼ì •

### 1.1 ì´ˆê¸° ëª©í‘œ ë° ì ‘ê·¼

**ë¬¸ì œ ì •ì˜**:
```
ì†Œìƒê³µì¸ì˜ ê´‘ê³  ì´ë¯¸ì§€ ì œì‘ ì§„ì…ì¥ë²½ í•´ì†Œ
â†’ ì „ë¬¸ ë””ìì´ë„ˆ ì—†ì´ë„ í’ˆì§ˆ ë†’ì€ ê´‘ê³  ì´ë¯¸ì§€ ìƒì„±
â†’ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ê³¼ ì—…ì¢…ë³„ ë§ì¶¤ ìƒì„± í•„ìš”
```

**ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜ ì±„íƒ ë°°ê²½**:

1. **ëª¨ë“ˆí™” ë° ì¬ì‚¬ìš©ì„±**: ì „ì²˜ë¦¬â†’ìƒì„±â†’í›„ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë…ë¦½ì ì¸ ë…¸ë“œë¡œ êµ¬í˜„
2. **í™•ì¥ ê°€ëŠ¥ì„±**: ìƒˆë¡œìš´ ê¸°ëŠ¥ì„ ë…¸ë“œ ì¶”ê°€ë§Œìœ¼ë¡œ êµ¬í˜„ ê°€ëŠ¥
3. **ìœ ì§€ë³´ìˆ˜ì„±**: BaseNode ì¶”ìƒ í´ë˜ìŠ¤ ê¸°ë°˜ì˜ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤
4. **ì›Œí¬í”Œë¡œìš° ìœ ì—°ì„±**: ë™ì¼í•œ ë…¸ë“œë¥¼ ë‹¤ì–‘í•˜ê²Œ ì¡°í•©í•˜ì—¬ ì—¬ëŸ¬ ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„

**í•µì‹¬ ì»´í¬ë„ŒíŠ¸**:
- `BaseNode`: ëª¨ë“  ë…¸ë“œì˜ ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤ (process, execute ë©”ì„œë“œ í‘œì¤€í™”)
- `ImageGenerationWorkflow`: ë…¸ë“œ ì²´ì¸ ì‹¤í–‰ ë° ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘
- ë…¸ë“œë³„ ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì  (ì‹¤í–‰ ì‹œê°„, ìƒíƒœ, ì—ëŸ¬)

### 1.2 ê¸°ìˆ  ìŠ¤íƒ ì „í™˜ ê³¼ì •

#### Phase 1: SDXL ê¸°ë°˜ ì´ˆê¸° êµ¬í˜„

**ì„ íƒ ì´ìœ **:
- ê²€ì¦ëœ ì•ˆì •ì„±ê³¼ ê´‘ë²”ìœ„í•œ ì»¤ë®¤ë‹ˆí‹° ì§€ì›
- ë©€í‹° ëª¨ë¸ ì „ëµ (Realistic, Semi-Realistic, Anime)
- ControlNet í†µí•©ìœ¼ë¡œ I2I ê¸°ëŠ¥ êµ¬í˜„

**êµ¬í˜„ ë‚´ìš©**:
- 3ê°œì˜ ìŠ¤íƒ€ì¼ë³„ SDXL ì²´í¬í¬ì¸íŠ¸ ëª¨ë¸ (ê° 33GB)
- ControlNetPreprocessorNode, ControlNetLoaderNode ì™„ì„±
- Image2ImageControlNetNodeë¡œ ì œí’ˆ í˜•íƒœ ìœ ì§€ + ìŠ¤íƒ€ì¼ ë³€í™˜

**í•œê³„ ë°œê²¬**:
1. **CLIP 77í† í° ì œí•œ**: ê´‘ê³  ë¬¸êµ¬ëŠ” ê¸´ í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•˜ì§€ë§Œ ì˜ë¦¼ ë°œìƒ
2. **ìŠ¤í† ë¦¬ì§€ ê³¼ë‹¤ ì‚¬ìš©**: 3ê°œ ëª¨ë¸ Ã— 33GB = 99GB ë””ìŠ¤í¬ ì ìœ 
3. **ìŠ¤íƒ€ì¼ ì „í™˜ ì˜¤ë²„í—¤ë“œ**: ì „ì²´ ëª¨ë¸ ì¬ë¡œë”© í•„ìš” (ëŠë¦° ì „í™˜)

#### Phase 2: Z-Image Turbo ì „í™˜ (2026-01-16)

**ì „í™˜ ê²°ì •ì˜ ë°°ê²½**:

**1. í”„ë¡¬í”„íŠ¸ ì´í•´ë„ í–¥ìƒ**
- **ë¬¸ì œ**: CLIP í…ìŠ¤íŠ¸ ì¸ì½”ë”ì˜ 77í† í° ì œí•œìœ¼ë¡œ ìƒì„¸í•œ ê´‘ê³  ë¬¸êµ¬ í‘œí˜„ ë¶ˆê°€
  ```
  ì˜ˆì‹œ: "ì¹´í˜ ì‹ ë©”ë‰´ ë”¸ê¸°ë¼ë–¼, ë”°ëœ»í•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°, ì°½ê°€ ìì—°ê´‘, ìš°ìœ  ê±°í’ˆ ìœ„ ë”¸ê¸° ìŠ¬ë¼ì´ìŠ¤"
  â†’ CLIP: 77í† í° ì´ˆê³¼ë¡œ ë’·ë¶€ë¶„ ì˜ë¦¼
  ```
- **í•´ê²°**: Qwen 2.5 LLM ê¸°ë°˜ í…ìŠ¤íŠ¸ ì¸ì½”ë” ë„ì…
  - 512+ í† í° ì§€ì›ìœ¼ë¡œ ê¸´ ë¬¸ë§¥ ì²˜ë¦¬
  - í•œê¸€â†’ì˜ì–´ ë³€í™˜ ì‹œ ì˜ë¯¸ ë³´ì¡´ í–¥ìƒ
  - ì¶”ìƒì  ë¬˜ì‚¬ì˜ ì •í™•í•œ ì´ë¯¸ì§€ êµ¬í˜„

**2. "One Model, Multi-Style" ì „ëµ**
- **ë¬¸ì œ**: ìŠ¤íƒ€ì¼ë³„ë¡œ ì „ì²´ ëª¨ë¸ í•„ìš” (99GB ìŠ¤í† ë¦¬ì§€, ëŠë¦° ì „í™˜)
- **í•´ê²°**: ë‹¨ì¼ Base Model + LoRA ì–´ëŒ‘í„° êµì²´
  ```
  Base Model (20.5GB, ê³ ì •) + LoRA (ê° 500MB)
  â†’ ìŠ¤íƒ€ì¼ ì „í™˜ ì‹œ LoRAë§Œ êµì²´ (ë¹ ë¥¸ ì „í™˜, ìŠ¤í† ë¦¬ì§€ ì ˆê°)
  ```

**3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´**
- **ë¬¸ì œ**: SDXL FP32 ëª¨ë¸ì˜ ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš© (33GB)
- **í•´ê²°**: BF16 ìµœì í™” ëª¨ë¸ (`dimitribarbot/Z-Image-Turbo-BF16`, 20.5GB)
  - GCP L4 24GB VRAMì— ìµœì í™”
  - S3-DiT (Scaling-Shift-Squish DiT) ì•„í‚¤í…ì²˜ë¡œ ê³ ì† ì¶”ë¡ 

**ì „í™˜ ê²°ê³¼**:
| ì§€í‘œ | SDXL | Z-Image Turbo | ê°œì„  |
|------|------|---------------|------|
| ìŠ¤í† ë¦¬ì§€ | 99GB (3ëª¨ë¸) | 21GB (1ëª¨ë¸+LoRA) | 78% â†“ |
| í”„ë¡¬í”„íŠ¸ ê¸¸ì´ | 77 í† í° | 512+ í† í° | 6ë°° â†‘ |
| ìŠ¤íƒ€ì¼ ì „í™˜ | ì „ì²´ ëª¨ë¸ ì¬ë¡œë”© | LoRA êµì²´ | êµ¬ì¡°ì  ê°œì„  |

---

## 2. í•µì‹¬ ê¸°ìˆ  ìŠ¤íƒ

### 2.1 ìƒì„± ì—”ì§„

| êµ¬ì„±ìš”ì†Œ | ê¸°ìˆ  | ì„ íƒ ì´ìœ  |
|---------|------|----------|
| **Base Model** | Z-Image Turbo BF16 (20.5GB) | S3-DiT ì•„í‚¤í…ì²˜, 8ìŠ¤í… ê³ ì • ì¶”ë¡  |
| **Text Encoder** | Qwen 2.5 (LLM) | 512+ í† í° ì§€ì›, ê¸´ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ |
| **VAE** | SDXL Compatible VAE | Tiling/Slicingìœ¼ë¡œ ë©”ëª¨ë¦¬ ìµœì í™” |
| **Style System** | LoRA (Realistic/Semi/Anime) | ë‹¨ì¼ ë² ì´ìŠ¤ + ë™ì  ì „í™˜ |

**Note**: í˜„ì¬ëŠ” Base Modelì˜ Anime í’ˆì§ˆì´ ì¶©ë¶„í•˜ì—¬ LoRA ì ìš©ì€ í–¥í›„ ê³¼ì œë¡œ ì„¤ì •

### 2.2 ì›Œí¬í”Œë¡œìš° êµ¬ì„±

#### 2.2.1 ê¸°ë³¸ T2I (Text-to-Image) ì›Œí¬í”Œë¡œìš°

```python
ì‚¬ìš©ì í•œê¸€ ì…ë ¥
   â†“
PromptProcessorNode
   - í•œê¸€â†’ì˜ì–´ í”„ë¡¬í”„íŠ¸ ë³€í™˜ (GPT API)
   - ì—…ì¢…ë³„ í…œí”Œë¦¿ ì ìš© (industries.yaml)
   - Positive/Negative í”„ë¡¬í”„íŠ¸ ìƒì„±
   â†“
Text2ImageNode
   - Z-Image Turbo íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
   - 8ìŠ¤í… ê³ ì • ì¶”ë¡ 
   - ê³µìœ  ìºì‹œ í™œìš© (Transformer, VAE, Encoder)
   â†“
GPTLayoutAnalyzerNode (ì˜µì…˜)
   - GPT-4Vê°€ ì´ë¯¸ì§€ ë¶„ì„
   - í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìµœì  ìœ„ì¹˜/ìƒ‰ìƒ ê²°ì •
   â†“
TextOverlayNode (ì˜µì…˜)
   - PIL ImageDrawë¡œ ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ ë Œë”ë§
   - Nanum/Noto CJK í°íŠ¸ ìë™ ê²€ìƒ‰
   - ê·¸ë¦¼ì, ì™¸ê³½ì„ , ë°°ê²½ ë°•ìŠ¤ íš¨ê³¼
   â†“
SaveImageNode
   - í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€ ì €ì¥
   - origin/ í´ë”ì— ì›ë³¸ ì´ë¯¸ì§€ ë³´ì¡´
```

**íŠ¹ì§•**:
- Diffusion ëª¨ë¸ì€ ì •í™•í•œ í…ìŠ¤íŠ¸ ë Œë”ë§ ë¶ˆê°€ â†’ í›„ì²˜ë¦¬ ì˜¤ë²„ë ˆì´ í•„ìˆ˜
- GPT-4V ê¸°ë°˜ ìë™ ë°°ì¹˜ë¡œ ìµœì ì˜ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê²°ì •
- ì—…ì¢…ë³„ í”„ë¦¬ì…‹ (cafe, restaurant, retail, service)

#### 2.2.2 I2I (Image-to-Image) ì›Œí¬í”Œë¡œìš°

```python
ì‚¬ìš©ì ì°¸ì¡° ì´ë¯¸ì§€ + í•œê¸€ ì…ë ¥
   â†“
PromptProcessorNode
   - í•œê¸€â†’ì˜ì–´ í”„ë¡¬í”„íŠ¸ ë³€í™˜
   â†“
Image2ImageNode
   - Strength íŒŒë¼ë¯¸í„°ë¡œ ë³€í˜• ê°•ë„ ì¡°ì ˆ
   - ê³µìœ  ìºì‹œ í™œìš© (T2Iì™€ ì»´í¬ë„ŒíŠ¸ ì¬ì‚¬ìš©)
   - ì›ë³¸ êµ¬ë„ ìœ ì§€ + ìŠ¤íƒ€ì¼ ë³€í™˜
   â†“
TextOverlayNode (ì˜µì…˜)
   â†“
SaveImageNode
```

**Strength ì´í•´**:
```python
num_inference_steps = 8
strength = 0.6
actual_steps = int(8 * 0.6) = 4~5 steps

- strength = 0.3: ì›ë³¸ 70% ìœ ì§€ (ì•½ê°„ì˜ ìƒ‰ê° ì¡°ì •)
- strength = 0.6: ì›ë³¸ 40% ìœ ì§€ (ìŠ¤íƒ€ì¼ ë³€í™˜, ê¸°ë³¸ê°’)
- strength = 0.9: ì›ë³¸ 10% ìœ ì§€ (ê±°ì˜ ìƒˆë¡œ ìƒì„±)
```

**ì œì•½ì‚¬í•­**:
- I2IëŠ” ì›ë³¸ êµ¬ë„ ìœ ì§€ê°€ ëª©ì ì´ë¯€ë¡œ ì›ë³¸ì— ì—†ë˜ ìš”ì†Œ(ê¸€ì ë“±) ì¶”ê°€ ë¶ˆê°€ëŠ¥
- ê´‘ê³  ë¬¸êµ¬ëŠ” í›„ì²˜ë¦¬ TextOverlayNodeë¡œ ì˜¤ë²„ë ˆì´ ê¶Œì¥

#### 2.2.3 ì œí’ˆ ë°°ê²½ í•©ì„± ì›Œí¬í”Œë¡œìš° (NEW)

**ë„ì „ ê³¼ì œ**:
ì œí’ˆ ì´ë¯¸ì§€ì— AI ë°°ê²½ì„ í•©ì„±í•˜ë˜, 24GB VRAM ì œì•½ ë‚´ì—ì„œ êµ¬í˜„ í•„ìš”

**ControlNet ë°©ì‹ì˜ í•œê³„**:
```
ZIT Base: 20.5GB
ControlNet: 3GB
Total: 23.5GB â†’ OOM ë°œìƒ (L4ëŠ” 24GB)
```

**ìƒˆë¡œìš´ ì ‘ê·¼: ìˆœì°¨ ì‹¤í–‰ + ì¦‰ì‹œ ì–¸ë¡œë“œ ì „ëµ**

```python
ì œí’ˆ ì´ë¯¸ì§€ ì…ë ¥
   â†“
BackgroundRemovalNode
   - rembg (U2-Net) ëª¨ë¸ë¡œ ì œí’ˆ ë°°ê²½ ì œê±°
   - RGBA ì „ê²½ ì´ë¯¸ì§€ + ì•ŒíŒŒ ë§ˆìŠ¤í¬ ì¶”ì¶œ
   - VRAM ì‚¬ìš© í›„ ì¦‰ì‹œ ì–¸ë¡œë“œ (~500MB â†’ 0MB)
   â†“
PromptProcessorNode
   - ë°°ê²½ í”„ë¡¬í”„íŠ¸ ë³€í™˜
   - "modern cafe interior, professional lighting, clean background"
   â†“
Text2ImageNode
   - AI ë°°ê²½ ìƒì„± (ZIT 20.5GB)
   - rembg ì–¸ë¡œë“œ ì™„ë£Œ ìƒíƒœì—ì„œ ë¡œë“œ
   â†“
SaveImageNode (is_origin=True)
   - ìƒì„±ëœ ë°°ê²½ì„ origin/ í´ë”ì— ì €ì¥
   â†“
ProductLayoutAnalyzerNode (ì˜µì…˜)
   - GPT-4Vê°€ ì œí’ˆ íŠ¹ì„± ë¶„ì„
   - ìµœì  ë°°ì¹˜ (ìœ„ì¹˜, í¬ê¸°) ìë™ ê²°ì •
   - ìˆ˜ë™ ë°°ì¹˜ ì§€ì› (manual_scale, manual_position)
   â†“
BackgroundCompositeNode
   - ì•ŒíŒŒ ë¸”ë Œë”© ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„±
   - ìë™ ìŠ¤ì¼€ì¼ ì¡°ì • (ì œí’ˆì´ ë°°ê²½ë³´ë‹¤ í´ ê²½ìš°)
   - ì¤‘ì•™ ë°°ì¹˜ ë˜ëŠ” GPT-4V ê¸°ë°˜ ë°°ì¹˜
   â†“
SaveImageNode (is_origin=False)
   - ìµœì¢… í•©ì„± ì´ë¯¸ì§€ ì €ì¥
```

**ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**:
```
rembg ë¡œë“œ: ~500MB
rembg ì–¸ë¡œë“œ í›„: 0MB
ZIT ë¡œë“œ: 20.5GB
í•©ì„± ì²˜ë¦¬: ~500MB
í”¼í¬ ë©”ëª¨ë¦¬: 21GB âœ… (L4 24GB ë‚´ ì•ˆì • ì‘ë™)
```

**êµ¬í˜„ íŠ¹ì§•**:
- ìë™ ìŠ¤ì¼€ì¼ ì¡°ì •: ì œí’ˆì´ ë°°ê²½ë³´ë‹¤ í´ ê²½ìš° ìë™ ì¶•ì†Œ
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›: ë™ì¼ ë°°ê²½ì— ì—¬ëŸ¬ ì œí’ˆ í•©ì„± ê°€ëŠ¥
- GPT-4V ë°°ì¹˜ ë¶„ì„: ì œí’ˆ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê³ ë ¤í•œ ìµœì  ë°°ì¹˜

### 2.3 ì˜ì¡´ì„± ìŠ¤íƒ

```python
# Core ML Libraries
diffusers==0.36.0        # Diffusion íŒŒì´í”„ë¼ì¸
transformers==4.57.3     # Qwen í…ìŠ¤íŠ¸ ì¸ì½”ë”
accelerate==1.12.0       # ë©”ëª¨ë¦¬ ìµœì í™”
peft==0.18.0             # LoRA ë™ì  ë¡œë”©

# ControlNet (I2I)
controlnet-aux==0.0.10   # Canny/Depth/Openpose ì „ì²˜ë¦¬
mediapipe==0.10.9        # controlnet-aux ì˜ì¡´ì„±
timm==0.9.16             # controlnet-aux í˜¸í™˜ ë²„ì „

# Background Removal (ì œí’ˆ í•©ì„±)
rembg==2.0.69            # U2-Net ë°°ê²½ ì œê±°

# Image Processing
pillow==12.0.0           # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´, ì´ë¯¸ì§€ ì²˜ë¦¬
opencv-python==4.12.0.88 # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
numpy==2.2.6             # ë°°ì—´ ì—°ì‚°
scipy==1.15.3            # ì´ë¯¸ì§€ í•„í„°ë§
einops==0.8.1            # í…ì„œ ì—°ì‚°

# Infrastructure
huggingface-hub==0.36.0  # ëª¨ë¸ ë¡œë”©
requests==2.32.5         # API í˜¸ì¶œ
tqdm==4.67.1             # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
PyYAML==6.0.3            # ì„¤ì • íŒŒì¼ ë¡œë“œ
openai                   # GPT-4V API
```

---

## 3. ì£¼ìš” ê¸°ìˆ ì  ë¬¸ì œ í•´ê²°

### 3.1 ë©”ëª¨ë¦¬ ì´ˆê³¼(OOM) ë¬¸ì œ

**í™˜ê²½**: GCP L4 Instance (vCPU 4 / RAM 16GB / VRAM 24GB)

**ë„ì „ ê³¼ì œ**: ì‹œìŠ¤í…œ ë¬¼ë¦¬ RAM(16GB)ë³´ë‹¤ í° ëª¨ë¸(ì´ˆê¸° 32.9GB) êµ¬ë™ í•„ìš”

#### ë¬¸ì œ 1: ëª¨ë¸ ë¡œë”© ì‹œ ì‹œìŠ¤í…œ RAM ê³ ê°ˆ

**í˜„ìƒ**:
- 24GB ëª¨ë¸ ë¡œë“œ ì¤‘ 16GB ì‹œìŠ¤í…œ RAM ê³ ê°ˆ
- í”„ë¡œì„¸ìŠ¤ ê°•ì œ ì¢…ë£Œ(Kill) ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ í”„ë¦¬ì§•(Freezing)

**í•´ê²° ê³¼ì •**:

1. **Swap ë©”ëª¨ë¦¬ í™•ì¥**
   ```bash
   # 24GB ë””ìŠ¤í¬ ê¸°ë°˜ ê°€ìƒ ë©”ëª¨ë¦¬ í• ë‹¹
   sudo fallocate -l 24G /swapfile
   sudo chmod 600 /swapfile
   sudo mkswap /swapfile
   sudo swapon /swapfile
   ```
   - ë©”ëª¨ë¦¬ ìŠ¤íŒŒì´í¬ í¡ìˆ˜ ë²„í¼ í™•ë³´
   - ë¡œë”© ì‹œ ì„ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡± í•´ì†Œ

2. **ê²½ëŸ‰í™” ëª¨ë¸ ë°œêµ´ (í•µì‹¬ í•´ê²°ì±…)**
   - ê¸°ì¡´: 32.9GB ëª¨ë¸ â†’ L4 VRAM(24GB) ì´ˆê³¼
   - ê°œì„ : `dimitribarbot/Z-Image-Turbo-BF16` (20.5GB)
   - BF16 ì •ë°€ë„ë¡œ 38% ë©”ëª¨ë¦¬ ì ˆê° (33GB â†’ 20.5GB)

3. **VRAM Full Load ì „ëµ**
   ```python
   # ëŠë¦° CPU Offload ëŒ€ì‹  VRAM ì „ì²´ ë¡œë“œ
   pipe.to("cuda")  # ëª¨ë¸ ì „ì²´ë¥¼ VRAMì— ìƒì£¼
   ```
   - ì¶”ë¡  ì†ë„ ê·¹ëŒ€í™”
   - ì¬ë¡œë”© ì œê±°ë¡œ ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•

4. **ì´ì¤‘ ì•ˆì „ì¥ì¹˜ (Fallback)**
   ```python
   try:
       pipe.to("cuda")  # VRAM ë¡œë“œ ì‹œë„
   except RuntimeError:
       pipe.enable_model_cpu_offload()  # ì‹¤íŒ¨ ì‹œ CPU Offload
   ```
   - VRAM ë¡œë“œ ì‹¤íŒ¨ ì‹œ ìë™ CPU Offload ì „í™˜
   - ì‹œìŠ¤í…œ ë‹¤ìš´ ë°©ì§€

**ê²°ê³¼**: 24GB VRAM ë‚´ ì•ˆì •ì  ì¶”ë¡  ë³´ì¥

#### ë¬¸ì œ 2: ì•„í‚¤í…ì²˜ í˜¸í™˜ì„± ë¬¸ì œ

**í˜„ìƒ**:
- ZIT ë¡œë“œ ì‹œ `DeiTConfig`, `norm_type` ì—ëŸ¬ ë°œìƒ
- ëª¨ë¸ êµ¬ë™ ì‹¤íŒ¨

**í•´ê²° ê³¼ì •**:

1. **ìë™ ê°ì§€ ë¡œì§ ì ìš©**
   ```python
   from transformers import AutoModel, AutoTokenizer

   # Qwen êµ¬ì¡° ìë™ ê°ì§€
   tokenizer = AutoTokenizer.from_pretrained(model_id)
   text_encoder = AutoModel.from_pretrained(model_id)
   ```

2. **Self-Repair ë¡œì§ êµ¬í˜„**
   ```python
   def _fix_zit_config(model_id):
       """ì„¤ì • íŒŒì¼ ë¬´ê²°ì„± ê²€ì‚¬ ë° ìë™ ë³µêµ¬"""
       config_path = Path(model_id) / "config.json"
       with open(config_path) as f:
           config = json.load(f)

       # norm_type í‚¤ ëˆ„ë½ ë²„ê·¸ ìë™ íŒ¨ì¹˜
       if "norm_type" not in config:
           config["norm_type"] = "rms_norm"
           with open(config_path, "w") as f:
               json.dump(config, f, indent=2)
   ```
   - ë°°í¬ëœ ëª¨ë¸ ì„¤ì • íŒŒì¼ ë²„ê·¸ ë°œê²¬ ë° ì˜êµ¬ í•´ê²°
   - ì‹¤í–‰ ì‹œ ìë™ íŒ¨ì¹˜ë¡œ ì‚¬ìš©ì ê°œì… ë¶ˆí•„ìš”

**ê²°ê³¼**: ëª¨ë¸ ë¡œë”© ì•ˆì •ì„± í™•ë³´

### 3.2 ê³µìœ  ìºì‹œ ì‹œìŠ¤í…œ (Shared Component Cache)

**ë„ì… ë°°ê²½** (2026-01-19):

Text2ImageNodeì™€ Image2ImageNodeëŠ” ë§ì€ ì»´í¬ë„ŒíŠ¸ë¥¼ ê³µìœ :
- Base Model Transformer (20.5GB)
- Text Encoder (Qwen 2.5)
- VAE
- Scheduler

ê¸°ì¡´ ë°©ì‹: ê° ë…¸ë“œê°€ ë…ë¦½ì ìœ¼ë¡œ ë¡œë“œ â†’ ë©”ëª¨ë¦¬ ì¤‘ë³µ ì‚¬ìš©

**ë¬¸ì œ**:
```
T2I íŒŒì´í”„ë¼ì¸: 20.5GB (Transformer + VAE + Encoder)
I2I íŒŒì´í”„ë¼ì¸: 20.5GB (ë™ì¼ ì»´í¬ë„ŒíŠ¸ ì¤‘ë³µ ë¡œë“œ)
ì´ ë©”ëª¨ë¦¬: 40GB â†’ OOM ë°œìƒ (L4ëŠ” 24GB)
```

**í•´ê²°ì±…: ì»´í¬ë„ŒíŠ¸ ë ˆë²¨ ìºì‹œ ê³µìœ **

```python
# nodes/shared_cache.py
_SHARED_COMPONENTS = {
    "transformer": None,
    "vae": None,
    "text_encoder": None,
    "text_encoder_2": None,
    "scheduler": None,
}

_CACHE_LOCK = threading.Lock()      # ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹œ ë™ì‹œì„± ì œì–´
_PIPELINE_LOCK = threading.Lock()   # íŒŒì´í”„ë¼ì¸ flush ë°©ì§€
_EXECUTION_LOCK = threading.Lock()  # GPU ìˆœì°¨ ì²˜ë¦¬

def get_t2i_pipeline(device="cuda"):
    """T2I íŒŒì´í”„ë¼ì¸ ìƒì„± (ê³µìœ  ì»´í¬ë„ŒíŠ¸ ì¬ì‚¬ìš©)"""
    with _CACHE_LOCK:
        if _SHARED_COMPONENTS["transformer"] is None:
            # ìµœì´ˆ 1íšŒë§Œ ë¡œë“œ
            _SHARED_COMPONENTS["transformer"] = load_transformer()
            _SHARED_COMPONENTS["vae"] = load_vae()
            _SHARED_COMPONENTS["text_encoder"] = load_text_encoder()

    # ê³µìœ  ì»´í¬ë„ŒíŠ¸ë¡œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±
    return ZImagePipeline(
        transformer=_SHARED_COMPONENTS["transformer"],  # ì¬ì‚¬ìš©
        vae=_SHARED_COMPONENTS["vae"],                  # ì¬ì‚¬ìš©
        text_encoder=_SHARED_COMPONENTS["text_encoder"], # ì¬ì‚¬ìš©
    )

def get_i2i_pipeline(device="cuda"):
    """I2I íŒŒì´í”„ë¼ì¸ ìƒì„± (ë™ì¼ ì»´í¬ë„ŒíŠ¸ ì¬ì‚¬ìš©)"""
    # T2Iì™€ ë™ì¼í•œ ê³µìœ  ì»´í¬ë„ŒíŠ¸ ì‚¬ìš©
    return get_t2i_pipeline(device)
```

**3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œ**:
1. `_CACHE_LOCK`: ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹œ ë™ì‹œì„± ì œì–´
2. `_PIPELINE_LOCK`: íŒŒì´í”„ë¼ì¸ flush ë°©ì§€ (ë©€í‹°ì“°ë ˆë“œ ì•ˆì „)
3. `_EXECUTION_LOCK`: GPU ìˆœì°¨ ì²˜ë¦¬ (ë™ì‹œ ì¶”ë¡  ë°©ì§€)

**íš¨ê³¼**:
| í•­ëª© | Before | After | ê°œì„  |
|------|--------|-------|------|
| ë©”ëª¨ë¦¬ ì‚¬ìš© | 40GB | 24GB | 40% â†“ |
| T2I â†’ I2I ì „í™˜ | ì „ì²´ ì¬ë¡œë”© | ì»´í¬ë„ŒíŠ¸ ì¬ì‚¬ìš© | ì¶”ê°€ ë©”ëª¨ë¦¬ 0GB |
| íŒŒì´í”„ë¼ì¸ ì•ˆì •ì„± | Flush ë°œìƒ ê°€ëŠ¥ | ë½ìœ¼ë¡œ ë³´í˜¸ | ì•ˆì •ì„± í–¥ìƒ |

**ì£¼ê¸°ì  ë¦¬ì†ŒìŠ¤ ì •ë¦¬**:
```python
_GENERATION_COUNT = 0

def process(self, inputs):
    global _GENERATION_COUNT

    # ì¶”ë¡  ì‹¤í–‰
    output = self.pipeline(prompt=prompt)

    # 5íšŒë§ˆë‹¤ ë©”ëª¨ë¦¬ ì •ë¦¬ (ì„±ëŠ¥ê³¼ ì•ˆì •ì„± ê· í˜•)
    _GENERATION_COUNT += 1
    if _GENERATION_COUNT % 5 == 0:
        gc.collect()
        torch.cuda.empty_cache()
```

### 3.3 í…ìŠ¤íŠ¸ ìƒì„± ë¬¸ì œ

**ë¬¸ì œ**: Diffusion ëª¨ë¸ì€ ì •í™•í•œ í…ìŠ¤íŠ¸ ë Œë”ë§ ë¶ˆê°€

**ê·¼ë³¸ ì›ì¸**:
- FLUX, SDXL, ZIT ë“± ëª¨ë“  Diffusion ëª¨ë¸ì˜ ê³µí†µ í•œê³„
- í”½ì…€ ë‹¨ìœ„ ë…¸ì´ì¦ˆ ì œê±° ë°©ì‹ìœ¼ë¡œëŠ” ì •í™•í•œ ë¬¸ì í˜•íƒœ ìƒì„± ì–´ë ¤ì›€
- I2IëŠ” ì›ë³¸ êµ¬ë„ ìœ ì§€ê°€ ëª©ì ì´ë¯€ë¡œ ìƒˆ ìš”ì†Œ(ê¸€ì) ì¶”ê°€ ë¶ˆê°€ëŠ¥

**í•´ê²° ë°©ì•ˆ**: 2ë‹¨ê³„ í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

```python
1. GPT-4V ë¶„ì„ (GPTLayoutAnalyzerNode)
   - ìƒì„±ëœ ì´ë¯¸ì§€ ë¶„ì„
   - í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìµœì  ìœ„ì¹˜ ê²°ì •
   - ë°°ê²½ ìƒ‰ìƒ ê³ ë ¤í•œ í…ìŠ¤íŠ¸ ìƒ‰ìƒ ì¶”ì²œ
   - ì—¬ë°±/êµ¬ë„ ë¶„ì„

2. PIL í…ìŠ¤íŠ¸ ë Œë”ë§ (TextOverlayNode)
   - PIL ImageDrawë¡œ ê³ í’ˆì§ˆ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
   - Nanum/Noto CJK í°íŠ¸ ìë™ ê²€ìƒ‰
   - ê·¸ë¦¼ì, ì™¸ê³½ì„ , ë°°ê²½ ë°•ìŠ¤ íš¨ê³¼
   - ì•µì»¤ í¬ì¸íŠ¸ ê¸°ë°˜ ì •ë ¬ (top-left, center, bottom-right ë“±)
```

**êµ¬í˜„ íŠ¹ì§•**:
```python
class TextOverlayNode(BaseNode):
    def process(self, inputs):
        image = inputs["image"]
        text = inputs["text"]
        position = inputs.get("position")  # GPT-4V ì¶”ì²œ ìœ„ì¹˜
        color = inputs.get("color")        # GPT-4V ì¶”ì²œ ìƒ‰ìƒ

        # í°íŠ¸ ìë™ ê²€ìƒ‰
        font = self._find_font(["NanumGothic", "NotoSansCJK"])

        # ê³ í’ˆì§ˆ ë Œë”ë§
        draw = ImageDraw.Draw(image)

        # ì™¸ê³½ì„  íš¨ê³¼ (ê°€ë…ì„± í–¥ìƒ)
        for dx, dy in [(-1, -1), (-1, 1), (1, -1), (1, 1)]:
            draw.text((x+dx, y+dy), text, font=font, fill="black")

        # ë©”ì¸ í…ìŠ¤íŠ¸
        draw.text((x, y), text, font=font, fill=color)

        return {"image": image}
```

### 3.4 ì œí’ˆ ë°°ê²½ í•©ì„±ì˜ ë©”ëª¨ë¦¬ ì œì•½

**ë¬¸ì œ**: ControlNet ë°©ì‹ìœ¼ë¡œëŠ” VRAM ì´ˆê³¼

**ê¸°ì¡´ ë°©ì‹ (ControlNet)**:
```
ZIT Base Model: 20.5GB
ControlNet SDXL: 3GB
Total: 23.5GB â†’ OOM ë°œìƒ (L4ëŠ” 24GB)
```

**ìƒˆë¡œìš´ ì ‘ê·¼: ìˆœì°¨ ì‹¤í–‰ + ì¦‰ì‹œ ì–¸ë¡œë“œ**

**í•µì‹¬ ì„¤ê³„ ê²°ì •**:
1. **rembgì™€ ZITì˜ ë©”ëª¨ë¦¬ ì¤‘ì²© ìµœì†Œí™”**
   - ZITëŠ” í•­ìƒ VRAM ìƒì£¼ (20.5GB ê³ ì •)
   - rembgëŠ” í•„ìš” ì‹œì—ë§Œ ZIT ìœ„ì— ì˜¬ë¼ê°”ë‹¤ê°€ ì¦‰ì‹œ ì–¸ë¡œë“œ
   - ë©”ëª¨ë¦¬ í”¼í¬: ZIT(20.5GB) + rembg(0.5GB) = 21GB

2. **ì¦‰ì‹œ ì–¸ë¡œë“œ êµ¬í˜„**
   ```python
   # preprocessing.py - BackgroundRemovalNode
   def process(self, inputs):
       global _REMBG_SESSION

       # 1. ë°°ê²½ ì œê±° ì‹¤í–‰
       if _REMBG_SESSION is None:
           _REMBG_SESSION = new_session("u2net")  # ~500MB

       output_image = remove(inputs["image"], session=_REMBG_SESSION)
       foreground = output_image  # RGBA
       mask = output_image.split()[3]  # ì•ŒíŒŒ ì±„ë„

       # 2. CRITICAL: ì¦‰ì‹œ ì–¸ë¡œë“œ
       del _REMBG_SESSION
       _REMBG_SESSION = None

       if torch.cuda.is_available():
           torch.cuda.empty_cache()

       logger.info("[BackgroundRemoval] Released rembg session to free VRAM")

       return {"foreground": foreground, "mask": mask}
   ```

3. **ë©”ëª¨ë¦¬ íƒ€ì„ë¼ì¸**
   ```
   ì‹œìŠ¤í…œ ì‹œì‘: ZIT ì²« ë¡œë“œ (ìµœì´ˆ 1íšŒ)
   â†’ Shared Cacheì— ì»´í¬ë„ŒíŠ¸ ë¡œë“œ
   â†’ Transformer, VAE, Text Encoder â†’ VRAM ìƒì£¼ (20.5GB)
   â†“
   ì œí’ˆ ë°°ê²½ í•©ì„± ì›Œí¬í”Œë¡œìš° ì‹œì‘
   â†’ ZITëŠ” ì´ë¯¸ VRAMì— ìƒì£¼ (20.5GB ìœ ì§€)
   â†“
   BackgroundRemovalNode ì‹œì‘
   â†’ rembg ë¡œë“œ: 20.5GB + 0.5GB = 21GB
   â†“ ë°°ê²½ ì œê±° ì™„ë£Œ
   â†’ rembg ì¦‰ì‹œ ì–¸ë¡œë“œ: 21GB - 0.5GB = 20.5GB
   â†“
   Text2ImageNode ì‹œì‘
   â†’ ZIT ì¬ì‚¬ìš© (ì´ë¯¸ ë¡œë“œë¨, ì¬ë¡œë”© ì—†ìŒ)
   â†’ ë°°ê²½ ìƒì„± ì‹¤í–‰: 20.5GB ìœ ì§€
   â†“
   BackgroundCompositeNode
   â†’ í•©ì„± ì²˜ë¦¬: 20.5GB + 0.5GB = 21GB
   â†“ ìµœì¢… ì €ì¥
   â†’ í•©ì„± ì™„ë£Œ: 20.5GB (ZITëŠ” ê³„ì† ìƒì£¼)

   í”¼í¬ ë©”ëª¨ë¦¬: 21GB âœ…
   ```

**í•µì‹¬ ì›ë¦¬**:
- **ZITëŠ” Singletonìœ¼ë¡œ í•­ìƒ VRAM ìƒì£¼** (ì²« ë¡œë“œ í›„ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œê¹Œì§€ ìœ ì§€)
- **rembgë§Œ ë™ì  ë¡œë“œ/ì–¸ë¡œë“œ** (í•„ìš” ì‹œ ZIT ìœ„ì— ì˜¬ë¼ê°”ë‹¤ê°€ ì¦‰ì‹œ ì œê±°)
- **ì‹œê°„ì  ë¶„ë¦¬ê°€ ì•„ë‹Œ ë©”ëª¨ë¦¬ ì¤‘ì²© ìµœì†Œí™”**: ZIT(20.5GB) + rembg(0.5GB) = 21GB

**íš¨ê³¼**:
- í”¼í¬ ë©”ëª¨ë¦¬: 21GB (L4 24GB ë‚´ ì•ˆì • ì‘ë™)
- ControlNet ë°©ì‹ ëŒ€ë¹„ 2.5GB ì ˆê° (ZIT 20.5GB + ControlNet 3GB = 23.5GB vs 21GB)
- ZIT ì¬ë¡œë”© ë¶ˆí•„ìš” (Shared Cache ì¬ì‚¬ìš©)

### 3.5 í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ ì„¤ê³„

**ë„ì „ ê³¼ì œ**: ìŠ¤íƒ€ì¼ë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±

**í˜„ì¬ ì‹œìŠ¤í…œ ë¶„ì„** (private_doc/í”„ë¡¬í”„íŠ¸_ê°œì„ ë°©ì•ˆ.md ê¸°ë°˜):

```
[í•œê¸€ ì…ë ¥] â†’ [GPT í‚¤ì›Œë“œ ì¶”ì¶œ] â†’ [HybridPromptBuilder] â†’ [Positive/Negative Prompt]
                                         â†“
                              industries.yaml í…œí”Œë¦¿ ì°¸ì¡°
```

**í˜„ì¬ êµ¬í˜„**:
1. **PromptProcessorNode**
   - í•œê¸€ ì…ë ¥ì„ GPT APIë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
   - ì—…ì¢…ë³„ í…œí”Œë¦¿ ì ìš© (cafe, restaurant, retail, service)
   - Positive/Negative í”„ë¡¬í”„íŠ¸ ìƒì„±

2. **ì—…ì¢…ë³„ í”„ë¦¬ì…‹** (industries.yaml)
   ```yaml
   cafe:
     theme: "warm cozy cafe interior"
     lighting: "natural window lighting, soft ambient"
     props: "coffee cups, pastries, wooden tables"

   restaurant:
     theme: "elegant dining atmosphere"
     lighting: "professional food photography lighting"
     props: "plated dishes, table setting"
   ```

**í–¥í›„ ê°œì„  ë°©í–¥** (StyleRouter í†µí•© ê³„íš):

```
[í•œê¸€ ì…ë ¥]
    â†“
[GPT í‚¤ì›Œë“œ ì¶”ì¶œ] â† ì‚¬ìš©ì ì˜ë„ ì¶”ê°€ (style, purpose, tone)
    â†“
[StyleRouter] â† NEW: ìŠ¤íƒ€ì¼ë³„ ë¶„ê¸°
    â”œâ”€â”€ realistic â†’ RealisticPromptBuilder
    â”œâ”€â”€ anime â†’ AnimePromptBuilder
    â””â”€â”€ illustration â†’ IllustrationPromptBuilder
    â†“
[PromptAssembler] â† NEW: ìµœì¢… ì¡°ë¦½ + í…ìŠ¤íŠ¸ ë°©ì§€ ê°•í™”
```

**ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ì „ëµ** (ê³„íš):
- **Realistic**: "Professional commercial photography of..."
- **Anime**: "anime style illustration of...", "cel shading, vibrant colors"
- **Illustration**: "digital illustration of...", "flat design, vector art style"

**Note**: í˜„ì¬ëŠ” Realistic ì¤‘ì‹¬, StyleRouterëŠ” í–¥í›„ ê³¼ì œ

---

## 4. ìµœì¢… ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 4.1 ê³„ì¸µ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generator API (ê³ ìˆ˜ì¤€ ì¸í„°í˜ì´ìŠ¤)                    â”‚
â”‚  - generate_and_save_image()                        â”‚
â”‚  - generate_product_composite()                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ImageGenerationWorkflow (ë…¸ë“œ ì²´ì¸ ì‹¤í–‰)            â”‚
â”‚  - ë™ì  ì›Œí¬í”Œë¡œìš° êµ¬ì„±                              â”‚
â”‚  - ë©”íƒ€ë°ì´í„° ìˆ˜ì§‘ ë° ë¦¬í¬íŠ¸                          â”‚
â”‚  - ì—ëŸ¬ í•¸ë“¤ë§                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Nodes (BaseNode ìƒì†)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ì „ì²˜ë¦¬                                         â”‚  â”‚
â”‚  â”‚ - PromptProcessorNode                         â”‚  â”‚
â”‚  â”‚ - BackgroundRemovalNode                       â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ ìƒì„±                                           â”‚  â”‚
â”‚  â”‚ - Text2ImageNode                              â”‚  â”‚
â”‚  â”‚ - Image2ImageNode                             â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ ë¶„ì„                                           â”‚  â”‚
â”‚  â”‚ - GPTLayoutAnalyzerNode                       â”‚  â”‚
â”‚  â”‚ - ProductLayoutAnalyzerNode                   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ í›„ì²˜ë¦¬                                         â”‚  â”‚
â”‚  â”‚ - BackgroundCompositeNode                     â”‚  â”‚
â”‚  â”‚ - TextOverlayNode                             â”‚  â”‚
â”‚  â”‚ - SaveImageNode                               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Shared Cache (ë©”ëª¨ë¦¬ ê³µìœ )                          â”‚
â”‚  - Transformer (20.5GB)                             â”‚
â”‚  - VAE                                              â”‚
â”‚  - Text Encoder (Qwen 2.5)                          â”‚
â”‚  - Scheduler                                        â”‚
â”‚  - 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œ (ë™ì‹œì„± ì œì–´)                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Infrastructure                                     â”‚
â”‚  - Logging (src.utils.logging)                      â”‚
â”‚  - Config (config.py, industries.yaml)              â”‚
â”‚  - Storage (í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€)                     â”‚
â”‚  - Progress Callback (ì§„í–‰ ìƒí™© ì¶”ì )                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 ë…¸ë“œ ì„¤ê³„ ì² í•™

**BaseNode ì¶”ìƒ í´ë˜ìŠ¤**:
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, List
import time

class BaseNode(ABC):
    def __init__(self, node_name: str):
        self.node_name = node_name
        self.metadata = NodeMetadata(node_name)

    @abstractmethod
    def process(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ë…¸ë“œ ì‹¤í–‰ ë¡œì§ (ì„œë¸Œí´ë˜ìŠ¤ êµ¬í˜„)"""
        pass

    def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤í–‰ + ë©”íƒ€ë°ì´í„° ìë™ ìˆ˜ì§‘"""
        self.metadata.status = "running"
        start = time.time()

        try:
            result = self.process(inputs)
            self.metadata.status = "completed"
            self.metadata.execution_time = time.time() - start
            return result
        except Exception as e:
            self.metadata.status = "failed"
            self.metadata.error = str(e)
            raise

    @abstractmethod
    def get_required_inputs(self) -> List[str]:
        """í•„ìˆ˜ ì…ë ¥ í‚¤ ëª©ë¡"""
        pass

    @abstractmethod
    def get_output_keys(self) -> List[str]:
        """ì¶œë ¥ í‚¤ ëª©ë¡"""
        pass
```

**ì›Œí¬í”Œë¡œìš° ì‹¤í–‰**:
```python
from workflow import ImageGenerationWorkflow

# ì›Œí¬í”Œë¡œìš° êµ¬ì„±
workflow = ImageGenerationWorkflow(name="T2I_Realistic")
workflow.add_node(PromptProcessorNode(default_style="realistic"))
workflow.add_node(Text2ImageNode())
workflow.add_node(SaveImageNode(storage_dir="/mnt/data/generated"))

# ì‹¤í–‰
result = workflow.execute({
    "user_input": "ì¹´í˜ ì‹ ë©”ë‰´ ë”¸ê¸°ë¼ë–¼",
    "aspect_ratio": "1:1",
    "industry": "cafe"
})

# ë©”íƒ€ë°ì´í„° í™•ì¸
print(workflow.get_report())
# {
#   "total_time": 10.5,
#   "nodes": [
#     {"name": "PromptProcessorNode", "time": 1.2, "status": "completed"},
#     {"name": "Text2ImageNode", "time": 8.5, "status": "completed"},
#     {"name": "SaveImageNode", "time": 0.8, "status": "completed"}
#   ]
# }
```

**ì¥ì **:
1. **ëª¨ë“ˆí™”**: ê° ë…¸ë“œëŠ” ë…ë¦½ì ìœ¼ë¡œ ê°œë°œ/í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
2. **ì¬ì‚¬ìš©ì„±**: ë™ì¼í•œ ë…¸ë“œë¥¼ ì—¬ëŸ¬ ì›Œí¬í”Œë¡œìš°ì— ì‚¬ìš©
3. **í™•ì¥ì„±**: ìƒˆ ê¸°ëŠ¥ì€ ë…¸ë“œ ì¶”ê°€ë¡œ êµ¬í˜„
4. **ì¶”ì ì„±**: ë©”íƒ€ë°ì´í„°ë¡œ ì „ì²´ ê³¼ì • ì¶”ì 

### 4.3 ë™ì‹œì„± ì œì–´

**3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œ**:
```python
# shared_cache.py

_CACHE_LOCK = threading.Lock()      # 1. ì»´í¬ë„ŒíŠ¸ ë¡œë“œ ì‹œ
_PIPELINE_LOCK = threading.Lock()   # 2. íŒŒì´í”„ë¼ì¸ flush ë°©ì§€
_EXECUTION_LOCK = threading.Lock()  # 3. GPU ìˆœì°¨ ì²˜ë¦¬

def get_t2i_pipeline(device):
    with _CACHE_LOCK:  # 1ë‹¨ê³„: ìºì‹œ ì•ˆì „í•˜ê²Œ ë¡œë“œ
        if _SHARED_COMPONENTS["transformer"] is None:
            load_shared_components()

    with _PIPELINE_LOCK:  # 2ë‹¨ê³„: íŒŒì´í”„ë¼ì¸ êµ¬ì„± ë³´í˜¸
        pipeline = ZImagePipeline(...)

    return pipeline

# text2image.py
def process(self, inputs):
    with _EXECUTION_LOCK:  # 3ë‹¨ê³„: GPU ìˆœì°¨ ì‹¤í–‰
        output = self.pipeline(
            prompt=prompt,
            num_inference_steps=steps
        )
    return output
```

**ë½ ëª©ì **:
1. `_CACHE_LOCK`: ì—¬ëŸ¬ ì“°ë ˆë“œê°€ ë™ì‹œì— ì»´í¬ë„ŒíŠ¸ ë¡œë“œí•˜ëŠ” ê²ƒ ë°©ì§€
2. `_PIPELINE_LOCK`: íŒŒì´í”„ë¼ì¸ ê°ì²´ flush ë°©ì§€ (ë©€í‹°ì“°ë ˆë“œ ì•ˆì „)
3. `_EXECUTION_LOCK`: GPUëŠ” ìˆœì°¨ ì²˜ë¦¬ë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ ë™ì‹œ ì¶”ë¡  ë°©ì§€

---

## 5. ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 5.1 ë©”ëª¨ë¦¬ ìµœì í™”

| ì „ëµ | êµ¬í˜„ | íš¨ê³¼ |
|------|------|------|
| **BF16 ì •ë°€ë„** | `torch.bfloat16` ì‚¬ìš© | 33GB â†’ 20.5GB (38% ì ˆê°) |
| **ê³µìœ  ìºì‹œ** | Transformer/VAE/Encoder ì¬ì‚¬ìš© | 40GB â†’ 24GB (40% ì ˆê°) |
| **VAE Tiling** | `vae.enable_tiling()` | ë©”ëª¨ë¦¬ í”¼í¬ ê°ì†Œ |
| **VAE Slicing** | `vae.enable_slicing()` | ê³ í•´ìƒë„ ì²˜ë¦¬ ê°€ëŠ¥ |
| **ìˆœì°¨ ì‹¤í–‰** | rembg â†’ ZIT ì‹œê°„ ë¶„ë¦¬ | ë™ì‹œ ì¡´ì¬ ë°©ì§€ |
| **ì¦‰ì‹œ ì–¸ë¡œë“œ** | rembg ì‚¬ìš© í›„ ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ | í”¼í¬ ë©”ëª¨ë¦¬ 21GB |
| **ì£¼ê¸°ì  GC** | 5íšŒë§ˆë‹¤ `gc.collect()` | ë©”ëª¨ë¦¬ íŒŒí¸í™” ë°©ì§€ |

**CUDA ë©”ëª¨ë¦¬ ìµœì í™”**:
```python
# config.py
os.environ["PYTORCH_ALLOC_CONF"] = "max_split_size_mb:256"

# VAE ìµœì í™”
vae.enable_tiling()   # íƒ€ì¼ ë‹¨ìœ„ ì²˜ë¦¬
vae.enable_slicing()  # ìŠ¬ë¼ì´ìŠ¤ ë‹¨ìœ„ ì²˜ë¦¬
```

### 5.2 ìŠ¤í† ë¦¬ì§€ ìµœì í™”

**SDXL vs ZIT ë¹„êµ**:
```
SDXL ë°©ì‹:
  Realistic      (33GB)
  Semi-Realistic (33GB)
  Anime          (33GB)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total: 99GB

ZIT ë°©ì‹:
  Base Model     (20.5GB)
  LoRA Realistic (500MB)
  LoRA Semi      (500MB)
  LoRA Anime     (500MB)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total: 22GB

ì ˆê°: 77GB (78% ê°ì†Œ)
```

**í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€**:
```python
# SaveImageNode
def process(self, inputs):
    image = inputs["image"]

    # ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚°
    img_hash = hashlib.sha256(image.tobytes()).hexdigest()[:16]

    # í•´ì‹œ ê¸°ë°˜ ê²½ë¡œ (ì¶©ëŒ ë°©ì§€)
    subdir = img_hash[:2]
    filename = f"{img_hash}.jpg"
    path = storage_dir / subdir / filename

    # ì¤‘ë³µ í™•ì¸
    if path.exists():
        logger.info(f"Duplicate image, reusing {path}")
        return {"image_path": str(path)}

    # ì €ì¥
    image.save(path)
    return {"image_path": str(path)}
```

### 5.3 ì „í™˜ ì†ë„ ìµœì í™”

**ìŠ¤íƒ€ì¼ ì „í™˜ ë©”ì»¤ë‹ˆì¦˜**:
```python
# SDXL: ì „ì²´ ëª¨ë¸ êµì²´
def switch_style_sdxl(old_style, new_style):
    unload_model(old_style)  # 33GB ì–¸ë¡œë“œ
    load_model(new_style)    # 33GB ë¡œë“œ
    # ì´ ì‹œê°„: ëª¨ë¸ ë¡œë”© ì‹œê°„

# ZIT: LoRAë§Œ êµì²´
def switch_style_zit(new_lora):
    pipe.unload_lora_weights()      # 500MB ì–¸ë¡œë“œ
    pipe.load_lora_weights(new_lora)  # 500MB ë¡œë“œ
    # ì´ ì‹œê°„: LoRA ë¡œë”© ì‹œê°„ (í›¨ì”¬ ë¹ ë¦„)
```

**Singleton íŒ¨í„´**:
```python
# shared_cache.py
_GLOBAL_PIPE = None

def get_t2i_pipeline(device):
    global _GLOBAL_PIPE

    if _GLOBAL_PIPE is None:
        _GLOBAL_PIPE = load_pipeline()  # ìµœì´ˆ 1íšŒë§Œ

    return _GLOBAL_PIPE  # ì¬ë¡œë”© 0ì´ˆ
```

### 5.4 í’ˆì§ˆ ìµœì í™”

**í•´ìƒë„ ë°˜ì˜¬ë¦¼** (16í”½ì…€ ë°°ìˆ˜):
```python
def _adjust_resolution(width, height):
    """VAE ìµœì í™”ë¥¼ ìœ„í•œ í•´ìƒë„ ì¡°ì •"""
    width = int(round(width / 16) * 16)
    height = int(round(height / 16) * 16)
    return width, height
```

**FlashAttention í™œìš©**:
```python
from diffusers.models.attention_processor import AttnProcessor2_0

transformer.set_attn_processor(AttnProcessor2_0())
```

**ìŠ¤íƒ€ì¼ë³„ Negative í”„ë¡¬í”„íŠ¸**:
```python
STYLE_NEGATIVE_PROMPTS = {
    "realistic": (
        "cartoon, anime, 3d render, illustration, painting, "
        "low quality, blurry, distorted"
    ),
    "anime": (
        "photorealistic, photograph, realistic, "
        "low quality, blurry, distorted"
    ),
}
```

---

## 6. í•µì‹¬ ì„±ê³¼ ì§€í‘œ

### 6.1 ì •ëŸ‰ì  ì„±ê³¼

| í•­ëª© | Before (SDXL) | After (ZIT) | ê°œì„ ìœ¨ |
|------|---------------|-------------|--------|
| **ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©** | 99GB (3 ëª¨ë¸) | 22GB (1+LoRA) | **78% â†“** |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | 40GB (T2I+I2I) | 24GB (ê³µìœ  ìºì‹œ) | **40% â†“** |
| **í”„ë¡¬í”„íŠ¸ ê¸¸ì´** | 77 í† í° (CLIP) | 512+ í† í° (Qwen) | **6ë°° â†‘** |
| **ìŠ¤íƒ€ì¼ ì „í™˜** | ì „ì²´ ëª¨ë¸ ì¬ë¡œë”© | LoRA êµì²´ | **êµ¬ì¡°ì  ê°œì„ ** |

### 6.2 ê¸°ìˆ ì  ì„±ê³¼

#### ì™„ì„±ëœ êµ¬ì„±ìš”ì†Œ

**ì•„í‚¤í…ì²˜**:
- âœ… BaseNode ì¶”ìƒ í´ë˜ìŠ¤ (process, execute, ë©”íƒ€ë°ì´í„° ì¶”ì )
- âœ… ImageGenerationWorkflow (ë…¸ë“œ ì²´ì¸ ì‹¤í–‰, ë™ì  êµ¬ì„±)
- âœ… 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œ (CACHE, PIPELINE, EXECUTION)

**ë…¸ë“œ êµ¬í˜„**:
- âœ… PromptProcessorNode (í•œê¸€â†’ì˜ì–´, ì—…ì¢…ë³„ í…œí”Œë¦¿)
- âœ… Text2ImageNode (ZIT íŒŒì´í”„ë¼ì¸, ê³µìœ  ìºì‹œ)
- âœ… Image2ImageNode (Strength ê¸°ë°˜, ê³µìœ  ìºì‹œ)
- âœ… BackgroundRemovalNode (rembg, ì¦‰ì‹œ ì–¸ë¡œë“œ)
- âœ… BackgroundCompositeNode (ì•ŒíŒŒ ë¸”ë Œë”©, ìë™ ìŠ¤ì¼€ì¼)
- âœ… GPTLayoutAnalyzerNode (GPT-4V í…ìŠ¤íŠ¸ ë°°ì¹˜)
- âœ… ProductLayoutAnalyzerNode (GPT-4V ì œí’ˆ ë°°ì¹˜)
- âœ… TextOverlayNode (PIL ê³ í’ˆì§ˆ ë Œë”ë§)
- âœ… SaveImageNode (í•´ì‹œ ê¸°ë°˜ ì¤‘ë³µ ë°©ì§€)

**ì¸í”„ë¼**:
- âœ… í†µí•© ë¡œê¹… ì‹œìŠ¤í…œ (`src.utils.logging`)
- âœ… ìŠ¤íƒ€ì¼ë³„ ì„¤ì • ì‹œìŠ¤í…œ (config.py)
- âœ… ì—…ì¢…ë³„ í”„ë¦¬ì…‹ (industries.yaml)
- âœ… ì§„í–‰ ìƒí™© ì½œë°± (progress_callback)
- âœ… í•´ì‹œ ê¸°ë°˜ ì €ì¥ (ì¤‘ë³µ ë°©ì§€, origin í´ë”)

#### ì§€ì› ì›Œí¬í”Œë¡œìš°

1. **T2I (Text-to-Image)**
   - í•œê¸€ ì…ë ¥ â†’ ì´ë¯¸ì§€ ìƒì„± â†’ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´

2. **I2I (Image-to-Image)**
   - ì°¸ì¡° ì´ë¯¸ì§€ + í”„ë¡¬í”„íŠ¸ â†’ ìŠ¤íƒ€ì¼ ë³€í™˜

3. **ì œí’ˆ ë°°ê²½ í•©ì„±**
   - ì œí’ˆ ë°°ê²½ ì œê±° â†’ AI ë°°ê²½ ìƒì„± â†’ ìë™ ë°°ì¹˜ â†’ í•©ì„±

### 6.3 í”„ë¡œë•ì…˜ ì•ˆì •ì„±

**ë©”ëª¨ë¦¬ ì•ˆì •ì„±**:
- âœ… L4 24GB VRAMì—ì„œ ì•ˆì •ì  ë™ì‘ (í”¼í¬ 21GB)
- âœ… Swap ë©”ëª¨ë¦¬ë¡œ ì‹œìŠ¤í…œ RAM ë¶€ì¡± í•´ì†Œ
- âœ… ê³µìœ  ìºì‹œë¡œ ë©”ëª¨ë¦¬ ì¤‘ë³µ ì œê±°

**ë™ì‹œì„± ì œì–´**:
- âœ… 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œìœ¼ë¡œ ë©€í‹°ì“°ë ˆë“œ ì•ˆì „
- âœ… GPU ìˆœì°¨ ì²˜ë¦¬ë¡œ OOM ë°©ì§€
- âœ… ì£¼ê¸°ì  GCë¡œ ë©”ëª¨ë¦¬ íŒŒí¸í™” ë°©ì§€

**ì—ëŸ¬ ì²˜ë¦¬**:
- âœ… Self-Repair ë¡œì§ (ì„¤ì • íŒŒì¼ ìë™ íŒ¨ì¹˜)
- âœ… Fallback ë©”ì»¤ë‹ˆì¦˜ (VRAM ì‹¤íŒ¨ ì‹œ CPU Offload)
- âœ… ë…¸ë“œë³„ ë©”íƒ€ë°ì´í„°ë¡œ ë””ë²„ê¹… ìš©ì´

---

## 7. ì£¼ìš” API ì‚¬ìš© ì˜ˆì‹œ

### 7.1 ê¸°ë³¸ T2I ìƒì„±

```python
from src.generation.image_generation.generator import generate_and_save_image

result = generate_and_save_image(
    user_input="ì¹´í˜ ì‹ ë©”ë‰´ ë”¸ê¸°ë¼ë–¼, ë”°ëœ»í•˜ê³  ì•„ëŠ‘í•œ ë¶„ìœ„ê¸°",
    style="realistic",
    aspect_ratio="1:1",
    industry="cafe",
    num_inference_steps=8,
    guidance_scale=7.5
)

print(f"ìƒì„± ì™„ë£Œ: {result['image_path']}")
# ì¶œë ¥: /mnt/data/generated/ab/abc123def.jpg

print(f"ë©”íƒ€ë°ì´í„°: {result['metadata']}")
# ë…¸ë“œë³„ ì‹¤í–‰ ì‹œê°„, ìƒíƒœ í™•ì¸ ê°€ëŠ¥
```

### 7.2 I2I ìƒì„±

```python
from PIL import Image
from src.generation.image_generation.generator import generate_and_save_image

reference = Image.open("product_photo.jpg")

result = generate_and_save_image(
    user_input="ë” ë°ê³  ë”°ëœ»í•œ ëŠë‚Œìœ¼ë¡œ",
    reference_image=reference,  # I2I ìë™ ë¶„ê¸°
    strength=0.6,  # ì›ë³¸ 40% ìœ ì§€
    style="realistic",
    aspect_ratio="1:1"
)

print(f"ë³€í˜• ì™„ë£Œ: {result['image_path']}")
```

### 7.3 ì œí’ˆ ë°°ê²½ í•©ì„±

```python
from PIL import Image
from src.generation.image_generation.generator import generate_product_composite

product_image = Image.open("coffee_cup.jpg")

result = generate_product_composite(
    product_image=product_image,
    background_prompt="modern cafe interior, warm professional lighting, clean background",
    style="realistic",
    aspect_ratio="1:1",
    context="ì¹´í˜ ì‹ ë©”ë‰´",
    auto_layout=True  # GPT-4V ìë™ ë°°ì¹˜
)

print(f"í•©ì„± ì™„ë£Œ: {result['image_path']}")
print(f"ë°°ì¹˜ ìœ„ì¹˜: {result['layout']['position']}")
print(f"ë°°ì¹˜ í¬ê¸°: {result['layout']['scale']}")
print(f"GPT-4V ë¶„ì„: {result['layout']['reasoning']}")
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```python
{
    "success": True,
    "image_path": "/mnt/data/generated/cd/cdef456789.jpg",
    "layout": {
        "position": (512, 384),  # ì¤‘ì‹¬ë³´ë‹¤ ì•½ê°„ ìš°ì¸¡
        "scale": 0.7,
        "reasoning": "ì œí’ˆì„ ìš°ì¸¡ì— ë°°ì¹˜í•˜ì—¬ ì¢Œì¸¡ ì—¬ë°±ì— í…ìŠ¤íŠ¸ ì¶”ê°€ ê°€ëŠ¥. í¬ê¸°ëŠ” ë°°ê²½ì˜ 70%ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¹„ìœ¨ ìœ ì§€."
    },
    "generation_method": "composite"
}
```

### 7.4 ë°°ì¹˜ ì²˜ë¦¬ (ë™ì¼ ë°°ê²½, ì—¬ëŸ¬ ì œí’ˆ)

```python
from PIL import Image
from src.generation.image_generation.nodes.preprocessing import BackgroundRemovalNode
from src.generation.image_generation.nodes.text2image import Text2ImageNode
from src.generation.image_generation.nodes.postprocessing import BackgroundCompositeNode

# 1. AI ë°°ê²½ 1íšŒ ìƒì„±
t2i = Text2ImageNode()
bg_result = t2i.execute({
    "prompt": "clean white studio background, professional product photography",
    "aspect_ratio": "1:1"
})
background = bg_result["image"]

# 2. ì—¬ëŸ¬ ì œí’ˆ ì²˜ë¦¬
removal = BackgroundRemovalNode()
composite = BackgroundCompositeNode()

products = ["product1.jpg", "product2.jpg", "product3.jpg"]
for product_path in products:
    product = Image.open(product_path)

    # ë°°ê²½ ì œê±°
    fg_result = removal.execute({"image": product})
    foreground = fg_result["foreground"]

    # í•©ì„± (ë™ì¼ ë°°ê²½ ì¬ì‚¬ìš©)
    final = composite.execute({
        "foreground": foreground,
        "background": background,
        "scale": 0.75
    })

    # ì €ì¥
    final["image"].save(f"{product_path}_composite.png")
```

---

## 8. í–¥í›„ ê°œì„  ë°©í–¥

### 8.1 ë‹¨ê¸° ê³¼ì œ (1-2ê°œì›”)

**1. ì—…ì¢…ë³„ ë°°ê²½ í…œí”Œë¦¿ í™•ì¥**
- í˜„ì¬: ì¹´í˜/ìŒì‹ì /ì†Œë§¤/ì„œë¹„ìŠ¤ 4ê°œ ì—…ì¢…
- ëª©í‘œ: 20+ ì—…ì¢… ì„¸ë¶„í™” (í—¤ì–´ìƒµ, ë„¤ì¼ìƒµ, ê½ƒì§‘, ì„œì  ë“±)
- êµ¬í˜„: industries.yaml í™•ì¥

**2. ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€**
- í˜„ì¬: í•©ì„± ì‹œ ê·¸ë¦¼ì ì—†ìŒ
- ëª©í‘œ: ìì—°ìŠ¤ëŸ¬ìš´ ê·¸ë¦¼ì ìƒì„±
- ê¸°ìˆ : ì¡°ëª… ë°©í–¥ ë¶„ì„ + PIL ë“œë¡­ ì‰ë„ìš°

**3. ProductLayoutAnalyzerNode ì„±ëŠ¥ ê°œì„ **
- í˜„ì¬: GPT-4V API í˜¸ì¶œ (ë¹„ìš©/ì§€ì—°)
- ëª©í‘œ: ë¡œì»¬ ë¹„ì „ ëª¨ë¸ í†µí•© (LLaVA, Qwen-VL ë“±)
- íš¨ê³¼: ë¹„ìš© ì ˆê°, ì‘ë‹µ ì†ë„ í–¥ìƒ

### 8.2 ì¤‘ê¸° ê³¼ì œ (3-6ê°œì›”)

**1. StyleRouter í†µí•©**
- í˜„ì¬: Realistic ì¤‘ì‹¬ í”„ë¡¬í”„íŠ¸
- ëª©í‘œ: Anime, Illustration ìŠ¤íƒ€ì¼ë³„ ìµœì í™”
- êµ¬í˜„:
  - config/styles/*.yaml ìƒì„±
  - StyleRouter í´ë˜ìŠ¤ êµ¬í˜„
  - ìŠ¤íƒ€ì¼ë³„ PromptBuilder

**2. LoRA ë™ì  ì „í™˜ í™œì„±í™”**
- í˜„ì¬: Base Modelë§Œ ì‚¬ìš©
- ëª©í‘œ: ìŠ¤íƒ€ì¼ë³„ LoRA ë™ì  ë¡œë“œ/ì–¸ë¡œë“œ
- íš¨ê³¼: ìŠ¤íƒ€ì¼ ë‹¤ì–‘ì„± í™•ë³´

**3. í…ìŠ¤íŠ¸ ë°©ì§€ ê°•í™”**
- í˜„ì¬: Negative Promptë§Œ ì‚¬ìš©
- ëª©í‘œ: Positive + Negative ëª¨ë‘ ê°•í™”
- êµ¬í˜„:
  ```python
  ANTI_TEXT_KEYWORDS = [
      "text", "letters", "words", "watermark", "signature",
      "caption", "subtitle", "logo", "label", "writing"
  ]
  ```

### 8.3 ì¥ê¸° ê³¼ì œ (6ê°œì›”+)

**1. ì˜¤í”„ë¼ì¸ ì§€ì›**
- í˜„ì¬: OpenAI API ì˜ì¡´ (GPT-4V, GPT-4)
- ëª©í‘œ: ë¡œì»¬ LLM/ë¹„ì „ ëª¨ë¸ í†µí•©
- í›„ë³´: LLaVA (ë°°ì¹˜ ë¶„ì„), Qwen-VL (í…ìŠ¤íŠ¸ ë°°ì¹˜)

**2. í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±**
- í˜„ì¬: ìˆ˜ë™ í…ŒìŠ¤íŠ¸
- ëª©í‘œ: E2E ìë™í™” í…ŒìŠ¤íŠ¸
- ë²”ìœ„:
  - T2I/I2I ì›Œí¬í”Œë¡œìš° ì •ìƒ ë™ì‘
  - ì œí’ˆ í•©ì„± ì›Œí¬í”Œë¡œìš° ì •ìƒ ë™ì‘
  - ë©”ëª¨ë¦¬ ë²¤ì¹˜ë§ˆí¬ (í”¼í¬ 21GB ë¯¸ë§Œ ë³´ì¥)
  - ì„±ëŠ¥ íšŒê·€ ë°©ì§€

**3. ê³ ê¸‰ í•©ì„± ê¸°ëŠ¥**
- ì—¬ëŸ¬ ì œí’ˆ ë™ì‹œ ë°°ì¹˜
- ì œí’ˆ ê°„ ê²¹ì¹¨ ì²˜ë¦¬
- ë°°ê²½ ìƒ‰ìƒ ìë™ ì¡°ì • (ì œí’ˆ í†¤ì— ë§ì¶¤)

---

## 9. íŒ€ ê¸°ì—¬ ë° ì—­í• 

### 9.1 ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„

**ë…¸ë“œ ê¸°ë°˜ ì•„í‚¤í…ì²˜**:
- BaseNode ì¶”ìƒ í´ë˜ìŠ¤ ì„¤ê³„ (process, execute, ë©”íƒ€ë°ì´í„°)
- ImageGenerationWorkflow êµ¬í˜„ (ë™ì  êµ¬ì„±, ì—ëŸ¬ í•¸ë“¤ë§)
- ë…¸ë“œ ê°„ ë°ì´í„° í”Œë¡œìš° í‘œì¤€í™” (Dict ê¸°ë°˜ ì…ì¶œë ¥)

**ì›Œí¬í”Œë¡œìš° ì„¤ê³„**:
- T2I, I2I, ì œí’ˆ í•©ì„± 3ê°€ì§€ ì›Œí¬í”Œë¡œìš° êµ¬í˜„
- ë…¸ë“œ ì¡°í•©ìœ¼ë¡œ ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„ ê°€ëŠ¥í•œ êµ¬ì¡°

**ê³µìœ  ìºì‹œ ì‹œìŠ¤í…œ**:
- ì»´í¬ë„ŒíŠ¸ ë ˆë²¨ ìºì‹œ ì„¤ê³„ (Transformer, VAE, Encoder)
- 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œ (CACHE, PIPELINE, EXECUTION)
- ë©”ëª¨ë¦¬ 40% ì ˆê° íš¨ê³¼

### 9.2 ì„±ëŠ¥ ìµœì í™”

**ë©”ëª¨ë¦¬ ìµœì í™”**:
- BF16 ëª¨ë¸ ë„ì… (33GB â†’ 20.5GB)
- ê³µìœ  ìºì‹œ ì‹œìŠ¤í…œ (40GB â†’ 24GB)
- ìˆœì°¨ ì‹¤í–‰ + ì¦‰ì‹œ ì–¸ë¡œë“œ (rembg â†’ ZIT)
- VAE Tiling/Slicing ì ìš©

**ìŠ¤í† ë¦¬ì§€ ìµœì í™”**:
- SDXL â†’ ZIT ì „í™˜ (99GB â†’ 22GB, 78% ì ˆê°)
- LoRA ê¸°ë°˜ ìŠ¤íƒ€ì¼ ì‹œìŠ¤í…œ ì„¤ê³„

**ë™ì‹œì„± ì œì–´**:
- threading.Lock ê¸°ë°˜ 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œ
- ë©€í‹°ì“°ë ˆë“œ ì•ˆì „í•œ GPU ì ‘ê·¼ ë³´ì¥

### 9.3 ê¸°ëŠ¥ êµ¬í˜„

**ì œí’ˆ ë°°ê²½ í•©ì„± ì›Œí¬í”Œë¡œìš°**:
- BackgroundRemovalNode (rembg í†µí•©, ì¦‰ì‹œ ì–¸ë¡œë“œ)
- ProductLayoutAnalyzerNode (GPT-4V ìë™ ë°°ì¹˜)
- BackgroundCompositeNode (ì•ŒíŒŒ ë¸”ë Œë”©, ìë™ ìŠ¤ì¼€ì¼)

**í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì‹œìŠ¤í…œ**:
- GPTLayoutAnalyzerNode (GPT-4V ë°°ì¹˜ ë¶„ì„)
- TextOverlayNode (PIL ê³ í’ˆì§ˆ ë Œë”ë§, í°íŠ¸ ìë™ ê²€ìƒ‰)

**ì§„í–‰ ìƒí™© ì¶”ì **:
- progress_callback ì‹œìŠ¤í…œ (ë…¸ë“œë³„ ì´ë²¤íŠ¸)
- ë©”íƒ€ë°ì´í„° ìë™ ìˆ˜ì§‘ (ì‹¤í–‰ ì‹œê°„, ìƒíƒœ, ì—ëŸ¬)

### 9.4 í†µí•© ë° ì¸í”„ë¼

**ë¡œê¹… ì‹œìŠ¤í…œ**:
- src.utils.logging í†µí•©
- ë…¸ë“œë³„ ë¡œê·¸ ìë™ ì¶”ì 

**ì„¤ì • ì‹œìŠ¤í…œ**:
- config.py (í•´ìƒë„ í…œí”Œë¦¿, Negative í”„ë¡¬í”„íŠ¸)
- industries.yaml (ì—…ì¢…ë³„ í”„ë¦¬ì…‹)

**Generator API í™•ì¥**:
- generate_and_save_image() (T2I/I2I ìë™ ë¶„ê¸°)
- generate_product_composite() (ì œí’ˆ í•©ì„± ì „ìš©)

---

## 10. ê²°ë¡ 

### 10.1 í•µì‹¬ ì„±ê³¼

**1. ê¸°ìˆ  ìŠ¤íƒ ì „í™˜: SDXL â†’ Z-Image Turbo**
- ìŠ¤í† ë¦¬ì§€ 78% ì ˆê° (99GB â†’ 22GB)
- LoRA ê¸°ë°˜ ë¹ ë¥¸ ìŠ¤íƒ€ì¼ ì „í™˜
- ê¸´ í”„ë¡¬í”„íŠ¸ ì§€ì› (77 â†’ 512+ í† í°)
- í’ˆì§ˆ í–¥ìƒ (Qwen 2.5 LLM ì¸ì½”ë”)

**2. ë©”ëª¨ë¦¬ ìµœì í™”: ê³µìœ  ìºì‹œ ì‹œìŠ¤í…œ**
- 40% ë©”ëª¨ë¦¬ ì ˆê° (40GB â†’ 24GB)
- T2I â†” I2I ì „í™˜ ì‹œ ì¬ë¡œë”© ë¶ˆí•„ìš”
- 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´

**3. í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜: ë…¸ë“œ ê¸°ë°˜ ì‹œìŠ¤í…œ**
- ëª¨ë“ˆí™”ëœ ë…¸ë“œ ì„¤ê³„ (ì¬ì‚¬ìš©ì„±, í™•ì¥ì„±)
- ë™ì  ì›Œí¬í”Œë¡œìš° êµ¬ì„± (3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤)
- ë©”íƒ€ë°ì´í„° ìë™ ì¶”ì  (ë””ë²„ê¹… ìš©ì´)

**4. ì œí’ˆ ë°°ê²½ í•©ì„± ì›Œí¬í”Œë¡œìš°**
- ìˆœì°¨ ì‹¤í–‰ + ì¦‰ì‹œ ì–¸ë¡œë“œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
- GPT-4V ê¸°ë°˜ ìë™ ë°°ì¹˜
- ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›

### 10.2 í•™ìŠµ í¬ì¸íŠ¸

**ë¬¸ì œ í•´ê²° ê³¼ì •**:
- **í† í° ì œí•œ** â†’ Qwen 2.5 ì¸ì½”ë”ë¡œ 512+ í† í° ì§€ì›
- **ìŠ¤í† ë¦¬ì§€ ê³¼ë‹¤** â†’ ë² ì´ìŠ¤ 1ê°œ + LoRAë¡œ 78% ì ˆê°
- **ì „í™˜ ëŠë¦¼** â†’ LoRA ë™ì  êµì²´ë¡œ ë¹ ë¥¸ ì „í™˜
- **OOM** â†’ BF16 + ê³µìœ  ìºì‹œ + ìˆœì°¨ ì‹¤í–‰ìœ¼ë¡œ í•´ê²°
- **í…ìŠ¤íŠ¸ ìƒì„± ë¶ˆê°€** â†’ GPT-4V + PIL í›„ì²˜ë¦¬ë¡œ í•´ê²°
- **ì œí’ˆ í•©ì„± ë©”ëª¨ë¦¬** â†’ ìˆœì°¨ ì‹¤í–‰ + ì¦‰ì‹œ ì–¸ë¡œë“œë¡œ 21GB ë‹¬ì„±

**ì•„í‚¤í…ì²˜ ì„¤ê³„**:
- í™•ì¥ì„±ê³¼ ì¬ì‚¬ìš©ì„±ì„ ê³ ë ¤í•œ ë…¸ë“œ ê¸°ë°˜ ì„¤ê³„
- BaseNode ì¶”ìƒ í´ë˜ìŠ¤ë¡œ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤
- ImageGenerationWorkflowë¡œ ë™ì  êµ¬ì„±

**ì„±ëŠ¥ ìµœì í™”**:
- ë©”ëª¨ë¦¬/ìŠ¤í† ë¦¬ì§€/ì „í™˜ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„ ê· í˜•
- ê³µìœ  ìºì‹œë¡œ ì¤‘ë³µ ì œê±°
- 3ë‹¨ê³„ ë½ ì‹œìŠ¤í…œìœ¼ë¡œ ë™ì‹œì„± ì œì–´

**ê¸°ìˆ  ì„ íƒì˜ ì‚¬ê³  ê³¼ì •**:
- SDXL â†’ ZIT: í”„ë¡¬í”„íŠ¸ ì´í•´ë„, ìŠ¤í† ë¦¬ì§€, ì „í™˜ ì†ë„ ê°œì„ 
- ControlNet â†’ rembg: ë©”ëª¨ë¦¬ ì œì•½ í•´ê²°
- GPT-4V: í…ìŠ¤íŠ¸/ì œí’ˆ ë°°ì¹˜ ìë™í™” (í–¥í›„ ë¡œì»¬ ëª¨ë¸ êµì²´ ê³„íš)

### 10.3 í–¥í›„ ë°œì „ ë°©í–¥

ì†Œìƒê³µì¸ ë§ì¶¤í˜• ê´‘ê³  ì´ë¯¸ì§€ ìƒì„± ì‹œìŠ¤í…œìœ¼ë¡œì„œ ë‹¤ìŒ ëª©í‘œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤:

**ë‹¨ê¸° (1-2ê°œì›”)**:
- ì—…ì¢…ë³„ ë°°ê²½ í…œí”Œë¦¿ í™•ì¥ (20+ ì—…ì¢…)
- ê·¸ë¦¼ì íš¨ê³¼ ì¶”ê°€ (ìì—°ìŠ¤ëŸ¬ìš´ í•©ì„±)
- ProductLayoutAnalyzerNode ì„±ëŠ¥ ê°œì„  (ë¡œì»¬ ëª¨ë¸)

**ì¤‘ê¸° (3-6ê°œì›”)**:
- **StyleRouter í†µí•©** (Anime, Illustration ìŠ¤íƒ€ì¼ ì§€ì›)
- LoRA ë™ì  ì „í™˜ í™œì„±í™” (ìŠ¤íƒ€ì¼ ë‹¤ì–‘ì„±)
- í…ìŠ¤íŠ¸ ë°©ì§€ ê°•í™” (Positive + Negative)

**ì¥ê¸° (6ê°œì›”+)**:
- **ì˜¤í”„ë¼ì¸ ì§€ì›** (ë¡œì»¬ LLM/ë¹„ì „ ëª¨ë¸)
- **í†µí•© í…ŒìŠ¤íŠ¸** (E2E ìë™í™”, ë©”ëª¨ë¦¬ ë²¤ì¹˜ë§ˆí¬)
- ê³ ê¸‰ í•©ì„± ê¸°ëŠ¥ (ì—¬ëŸ¬ ì œí’ˆ ë™ì‹œ ë°°ì¹˜)

ì´ë¥¼ í†µí•´ **í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ ì‹œìŠ¤í…œ**ìœ¼ë¡œ ë°œì „í•  ê³„íšì…ë‹ˆë‹¤.

---

**ì‘ì„±ì¼**: 2026-01-27
**ì‘ì„±ì**: ì´ë¯¸ì§€ ìƒì„± ëª¨ë“ˆ ë‹´ë‹¹
**ì°¸ê³  ë¬¸ì„œ**:
- [Image_README.md](../private_doc/Image_README.md)
- [technical_README.md](../private_doc/technical_README.md)
- [í”„ë¡¬í”„íŠ¸_ê°œì„ ë°©ì•ˆ.md](../private_doc/í”„ë¡¬í”„íŠ¸_ê°œì„ ë°©ì•ˆ.md)
- [ë°œí‘œìë£Œ_í•µì‹¬ìš”ì•½.md](./ë°œí‘œìë£Œ_í•µì‹¬ìš”ì•½.md)
