"""
ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ í¬ë¡¤ëŸ¬ v6 - ì™„ì „íŒ

ì¶”ê°€ ê¸°ëŠ¥:
1. ë³„ì  None â†’ ì¶”ì • ì ìˆ˜ ìƒì„±
2. ì—…ì²´ ì†Œê°œê¸€ í¬ë¡¤ë§
3. ì‹¤ì œ ë¦¬ë·° í…ìŠ¤íŠ¸ 3-5ê°œ
4. ì—…ì²´ ë“±ë¡ ì‚¬ì§„ URL
"""

import os
import re
import json
import time
import random
import hashlib
import requests
import tempfile
import urllib.parse
from datetime import datetime
from typing import Dict, List, Optional
from dataclasses import dataclass

# API í‚¤
NAVER_CLIENT_ID = os.getenv("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.getenv("NAVER_CLIENT_SECRET")

if not NAVER_CLIENT_ID or not NAVER_CLIENT_SECRET:
    print("âŒ í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”!")
    exit(1)

# ì„¤ì •
TARGET_COUNT = 1000  # ì „êµ­ í™•ëŒ€ë¡œ 1000ê°œ
DISPLAY_MAX = 5
REQUEST_SLEEP = 0.3
SELENIUM_SLEEP = 3.0
MAX_RETRIES = 2

OUT_DIR = "data"
os.makedirs(OUT_DIR, exist_ok=True)

# ì§€ì—­/í‚¤ì›Œë“œ (ì „êµ­ í™•ëŒ€)
LOCATIONS = [
    # ì„œìš¸ ì£¼ìš” ì§€ì—­
    "ê°•ë‚¨", "í™ëŒ€", "ì‹ ì´Œ", "ì´íƒœì›", "ì„±ìˆ˜", "ì—°ë‚¨", "ë§ì›", "í•œë‚¨", "ì²­ë‹´", "ì••êµ¬ì •",
    "ê±´ëŒ€", "ì ì‹¤", "ì‹ ë¦¼", "ë…¸ì›", "ê°•ì„œ", "ë§ˆí¬", "ìš©ì‚°", "ì¢…ë¡œ", "ëª…ë™", "ì„ì§€ë¡œ",
    
    # ê²½ê¸° ì£¼ìš” ì§€ì—­
    "íŒêµ", "ë¶„ë‹¹", "ìˆ˜ì›", "ì¼ì‚°", "ì•ˆì–‘", "ë¶€ì²œ", "í‰ì´Œ", "ì˜ì •ë¶€", "ê³ ì–‘", "ì„±ë‚¨",
    "ìš©ì¸", "í™”ì„±", "ê¹€í¬", "ê´‘ëª…", "ê³¼ì²œ", "ì‹œí¥",
    
    # ì¸ì²œ
    "ì†¡ë„", "êµ¬ì›”ë™", "ë¶€í‰", "ê³„ì–‘", "ì¸ì²œ",
    
    # ë¶€ì‚°
    "ì„œë©´", "í•´ìš´ëŒ€", "ê´‘ì•ˆë¦¬", "ë‚¨í¬ë™", "ë¶€ì‚°ëŒ€", "ë¶€ì‚°",
    
    # ëŒ€êµ¬
    "ë™ì„±ë¡œ", "ìˆ˜ì„±êµ¬", "ë²”ì–´ë™", "ëŒ€êµ¬",
    
    # ëŒ€ì „
    "ë‘”ì‚°", "ìœ ì„±", "ëŒ€ì „",
    
    # ê´‘ì£¼
    "ì¶©ì¥ë¡œ", "ìƒë¬´ì§€êµ¬", "ê´‘ì£¼",
    
    # ìš¸ì‚°
    "ì‚¼ì‚°ë™", "ìš¸ì‚°",
    
    # ì„¸ì¢…
    "ì„¸ì¢…",
    
    # ê°•ì›
    "ì¶˜ì²œ", "ê°•ë¦‰", "ì†ì´ˆ", "ì›ì£¼",
    
    # ì¶©ì²­
    "ì²œì•ˆ", "ì²­ì£¼", "ì•„ì‚°", "ì¶©ì£¼",
    
    # ì „ë¼
    "ì „ì£¼", "ìµì‚°", "êµ°ì‚°", "ëª©í¬", "ìˆœì²œ", "ì—¬ìˆ˜",
    
    # ê²½ìƒ
    "í¬í•­", "ê²½ì£¼", "êµ¬ë¯¸", "ì°½ì›", "ì§„ì£¼", "ê¹€í•´", "ê±°ì œ",
    
    # ì œì£¼
    "ì œì£¼ì‹œ", "ì„œê·€í¬", "ì œì£¼"
]

KEYWORDS = {
    "ì¹´í˜": [
        "ì¹´í˜", "ì»¤í”¼", "ì»¤í”¼ìˆ",
        "ë¸ŒëŸ°ì¹˜ì¹´í˜", "ë””ì €íŠ¸ì¹´í˜", "ë² ì´ì»¤ë¦¬ì¹´í˜",
        "ê°ì„±ì¹´í˜", "ë·°ë§›ì§‘", "ë£¨í”„íƒ‘ì¹´í˜",
        "ì• ê²¬ì¹´í˜", "ë¶ì¹´í˜", "ì‘ì—…ì¹´í˜"
    ],
    "ë§›ì§‘": [
        "ë§›ì§‘", "ì‹ë‹¹", "í˜„ì§€ì¸ë§›ì§‘",
        "í•œì‹ë‹¹", "ì¤‘ì‹ë‹¹", "ì¼ì‹ë‹¹", "ì–‘ì‹ë‹¹",
        "ê³ ê¸°ì§‘", "íšŒì§‘", "ì¹˜í‚¨ì§‘",
        "ë¶„ì‹ì§‘", "êµ­ë°¥ì§‘", "ì°Œê°œì „ê³¨",
        "ìˆ ì§‘", "í¬ì°¨", "ì´ìì¹´ì•¼",
        "ë¸ŒëŸ°ì¹˜", "ë·”í˜"
    ],
    "ë² ì´ì»¤ë¦¬": [
        "ë² ì´ì»¤ë¦¬", "ë¹µì§‘", "ì œê³¼ì ",
        "ì¼€ì´í¬ìƒµ", "ë””ì €íŠ¸ìƒµ", "ë§ˆì¹´ë¡±",
        "ë„ë„›", "í¬ë¡œì™€ìƒ", "ìŠ¤ì½˜ì „ë¬¸ì "
    ]
}

# ============================================
# ë„¤ì´ë²„ API
# ============================================
@dataclass
class NaverPlace:
    title: str
    link: str
    category: str
    address: str
    roadAddress: str
    telephone: str
    mapx: str
    mapy: str


class NaverAPICollector:
    BASE_URL = "https://openapi.naver.com/v1/search/local.json"

    def __init__(self, client_id: str, client_secret: str):
        self.session = requests.Session()
        self.session.headers.update({
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
        })

    def search(self, query: str, display: int = 5) -> List[NaverPlace]:
        params = {"query": query, "display": min(display, DISPLAY_MAX), "start": 1, "sort": "random"}

        try:
            resp = self.session.get(self.BASE_URL, params=params, timeout=15)
            if resp.status_code != 200:
                return []

            data = resp.json()
            items = []
            
            for it in data.get("items", []):
                title = re.sub(r'<\/?b>', '', it.get("title", "")).strip()
                items.append(NaverPlace(
                    title=title,
                    link=it.get("link", ""),
                    category=it.get("category", ""),
                    address=it.get("address", ""),
                    roadAddress=it.get("roadAddress", ""),
                    telephone=it.get("telephone", ""),
                    mapx=str(it.get("mapx", "")),
                    mapy=str(it.get("mapy", "")),
                ))

            time.sleep(REQUEST_SLEEP)
            return items
        
        except:
            return []


# ============================================
# Selenium - ì™„ì „íŒ
# ============================================
class CompleteCrawler:
    
    def __init__(self, headless: bool = True):
        self.driver = None
        self._init_driver(headless)
    
    def _init_driver(self, headless: bool):
        from selenium import webdriver
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.chrome.service import Service
        
        options = Options()
        
        if headless:
            options.add_argument('--headless=new')
        
        # ê¸°ë³¸ ì˜µì…˜
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        
        # ë´‡ íƒì§€ ìš°íšŒ
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        
        # ë°ìŠ¤í¬í†± User-Agent
        options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        profile_dir = tempfile.mkdtemp(prefix="chrome-")
        options.add_argument(f'--user-data-dir={profile_dir}')
        
        # Mac Chrome
        mac_chrome = "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
        if os.path.exists(mac_chrome):
            options.binary_location = mac_chrome
        
        # webdriver-manager
        from webdriver_manager.chrome import ChromeDriverManager
        driver_path = ChromeDriverManager().install()
        
        service = Service(driver_path)
        self.driver = webdriver.Chrome(service=service, options=options)
        
        # webdriver ì†ì„± ìˆ¨ê¸°ê¸°
        self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                });
            '''
        })
        
        print("  âœ… Selenium ì´ˆê¸°í™” (ì™„ì „íŒ)")
    
    def scrape(self, title: str, address: str, idx: int) -> Dict:
        """
        ëª¨ë“  ì •ë³´ ìˆ˜ì§‘
        """
        for attempt in range(MAX_RETRIES):
            try:
                result = self._scrape_once(title, address, idx, attempt)
                if result["success"] or attempt == MAX_RETRIES - 1:
                    return result
                
                print(f"  ì¬ì‹œë„ {attempt + 1}/{MAX_RETRIES}...", end=" ")
                time.sleep(2)
            
            except Exception as e:
                if attempt == MAX_RETRIES - 1:
                    print(f"âš ï¸ ìµœì¢… ì‹¤íŒ¨: {str(e)[:50]}")
                    return {
                        "review_count": None,
                        "rating": None,
                        "estimated_rating": None,
                        "business_description": None,
                        "sample_reviews": [],
                        "business_photos": [],
                        "success": False
                    }
                time.sleep(2)
        
        return {
            "review_count": None,
            "rating": None,
            "estimated_rating": None,
            "business_description": None,
            "sample_reviews": [],
            "business_photos": [],
            "success": False
        }
    
    def _scrape_once(self, title: str, address: str, idx: int, attempt: int) -> Dict:
        """
        ì‹¤ì œ í¬ë¡¤ë§ ë¡œì§ (í™•ì¥íŒ)
        """
        result = {
            "review_count": None,
            "rating": None,
            "estimated_rating": None,
            "business_description": None,
            "sample_reviews": [],
            "business_photos": [],
            "success": False
        }
        
        query = title.strip()
        
        if attempt == 0:
            print(f"ê²€ìƒ‰: {query[:30]}", end=" â†’ ")
        
        # ë°ìŠ¤í¬í†± ê²€ìƒ‰ URL
        url = f"https://map.naver.com/v5/search/{urllib.parse.quote(query)}"
        
        self.driver.get(url)
        time.sleep(SELENIUM_SLEEP)
        
        # ë¡œê·¸ì¸ ì²´í¬
        page_text = self.driver.execute_script("return document.body.innerText;")
        if "ë¡œê·¸ì¸" in page_text[:500] and "ë¹„ë°€ë²ˆí˜¸" in page_text[:500]:
            print(f"âš ï¸ ë¡œê·¸ì¸")
            return result
        
        # iframeìœ¼ë¡œ ì „í™˜
        try:
            iframe = self.driver.find_element("css selector", "iframe#searchIframe")
            self.driver.switch_to.frame(iframe)
            print(f"iframe!", end=" â†’ ")
            time.sleep(2)
        except:
            print(f"iframe X")
            return result
        
        # ì²« ë²ˆì§¸ ì¥ì†Œ í´ë¦­
        click_script = """
        var links = document.querySelectorAll('a');
        var clicked = false;
        
        for (var i = 0; i < links.length; i++) {
            var link = links[i];
            var text = link.textContent.trim();
            
            if (text.length > 2 && 
                !text.includes('ê´‘ê³ ') && 
                !text.includes('ì§€ë„') &&
                !text.includes('ê¸¸ì°¾ê¸°') &&
                link.href && 
                link.href.includes('place')) {
                link.click();
                clicked = true;
                break;
            }
        }
        return clicked;
        """
        
        clicked = self.driver.execute_script(click_script)
        
        if not clicked:
            print(f"í´ë¦­ X")
            self.driver.switch_to.default_content()
            return result
        
        print(f"í´ë¦­!", end=" â†’ ")
        time.sleep(4)
        
        # ìƒì„¸ ì •ë³´ iframeìœ¼ë¡œ ì „í™˜
        try:
            self.driver.switch_to.default_content()
            detail_iframe = self.driver.find_element("css selector", "iframe#entryIframe")
            self.driver.switch_to.frame(detail_iframe)
            print(f"ìƒì„¸!", end=" â†’ ")
            time.sleep(3)
        except:
            print(f"ìƒì„¸ X")
            self.driver.switch_to.default_content()
            return result
        
        # ğŸ”¥ ë¦¬ë·° íƒ­ í´ë¦­!
        review_tab_script = """
        var tabs = document.querySelectorAll('a, button, div, span');
        var clicked = false;
        
        for (var i = 0; i < tabs.length; i++) {
            var elem = tabs[i];
            var text = elem.innerText || elem.textContent || '';
            
            if (text.trim() === 'ë¦¬ë·°' || text.includes('ë°©ë¬¸ìë¦¬ë·°') || text.includes('ë¦¬ë·°ë³´ê¸°')) {
                elem.click();
                clicked = true;
                break;
            }
        }
        return clicked;
        """
        
        try:
            clicked_review_tab = self.driver.execute_script(review_tab_script)
            if clicked_review_tab:
                print(f"ë¦¬ë·°íƒ­!", end=" â†’ ")
                time.sleep(3)  # ë¦¬ë·° ë¡œë”© ëŒ€ê¸°
            else:
                print(f"í™ˆíƒ­", end=" â†’ ")
        except:
            print(f"íƒ­X", end=" â†’ ")
        
        # ğŸ”¥ ëª¨ë“  ì •ë³´ ì¶”ì¶œ! (ë²”ìš© íŒ¨í„´)
        extract_script = """
        var data = {
            review: null,
            rating: null,
            description: null,
            reviews: [],
            photos: []
        };
        
        var allText = document.body.innerText;
        
        // 1. ë¦¬ë·° ìˆ˜
        var patterns = [
            /ë°©ë¬¸ì\\s*ë¦¬ë·°\\s*([\\d,]+)/,
            /ë¦¬ë·°\\s*([\\d,]+)/
        ];
        for (var i = 0; i < patterns.length; i++) {
            var match = allText.match(patterns[i]);
            if (match) {
                data.review = parseInt(match[1].replace(/,/g, ''));
                break;
            }
        }
        
        // 2. ë³„ì 
        var ratingPatterns = [
            /ë³„ì \\s*([\\d\\.]+)/,
            /([\\d\\.]+)\\s*\\/\\s*5/,
            /í‰ì \\s*([\\d\\.]+)/
        ];
        for (var i = 0; i < ratingPatterns.length; i++) {
            var match = allText.match(ratingPatterns[i]);
            if (match) {
                var num = parseFloat(match[1]);
                if (num >= 0 && num <= 5) {
                    data.rating = num;
                    break;
                }
            }
        }
        
        // 3. ì—…ì²´ ì†Œê°œê¸€ (ë²”ìš©: span, p, div ëª¨ë‘ íƒìƒ‰)
        var allElems = document.querySelectorAll('span, p, div');
        for (var i = 0; i < allElems.length; i++) {
            var elem = allElems[i];
            var text = elem.innerText ? elem.innerText.trim() : '';
            
            // ì¡°ê±´: 30ì ì´ìƒ, 500ì ì´í•˜, ìì‹ ìš”ì†Œ ì ìŒ
            if (text.length >= 30 && text.length <= 500 && 
                elem.children.length < 3 &&
                !text.includes('ë¦¬ë·°') &&
                !text.includes('ë³„ì ') &&
                !text.includes('ì˜ì—…ì‹œê°„') &&
                !text.includes('ì „í™”')) {
                data.description = text;
                break;
            }
        }
        
        // 4. ë¦¬ë·° í…ìŠ¤íŠ¸ (ë²”ìš©: ê¸´ í…ìŠ¤íŠ¸ ì°¾ê¸°)
        var textBlocks = [];
        var allElems2 = document.querySelectorAll('span, p, div, li');
        
        for (var i = 0; i < allElems2.length; i++) {
            var elem = allElems2[i];
            var text = elem.innerText ? elem.innerText.trim() : '';
            
            // ë¦¬ë·° ê°™ì€ í…ìŠ¤íŠ¸: 15ì ì´ìƒ (ë” ê³µê²©ì ìœ¼ë¡œ)
            if (text.length >= 15 && text.length <= 500 &&
                elem.children.length <= 2 &&
                !text.includes('ë³„ì ') &&
                !text.includes('ì˜ì—…') &&
                !text.includes('ì „í™”') &&
                !text.includes('ì£¼ì†Œ') &&
                !text.includes('ë©”ë‰´') &&
                !text.includes('ê°€ê²©') &&
                !text.match(/^\d+$/) &&  // ìˆœìˆ˜ ìˆ«ì ì œì™¸
                !text.match(/^[0-9,]+ì›$/)) {  // ê°€ê²© ì œì™¸
                
                // ì¤‘ë³µ ì²´í¬
                var isDuplicate = false;
                for (var j = 0; j < textBlocks.length; j++) {
                    if (textBlocks[j] === text) {
                        isDuplicate = true;
                        break;
                    }
                }
                
                if (!isDuplicate) {
                    textBlocks.push(text);
                    if (textBlocks.length >= 5) break;
                }
            }
        }
        
        data.reviews = textBlocks;
        
        // 5. ì—…ì²´ ë“±ë¡ ì‚¬ì§„ URL (ëª¨ë“  img íƒœê·¸)
        var allImages = document.querySelectorAll('img');
        var seenUrls = {};
        
        for (var i = 0; i < allImages.length; i++) {
            var img = allImages[i];
            var src = img.src || img.getAttribute('data-src') || img.getAttribute('data-lazy-src');
            
            if (src && src.startsWith('http') && !seenUrls[src]) {
                // ë¡œê³ ë‚˜ ì•„ì´ì½˜ ì œì™¸ (ë³´í†µ ì‘ìŒ)
                if (!src.includes('icon') && !src.includes('logo')) {
                    seenUrls[src] = true;
                    data.photos.push(src);
                    if (data.photos.length >= 10) break;
                }
            }
        }
        
        return data;
        """
        
        data = self.driver.execute_script(extract_script)
        
        if data:
            result["review_count"] = data.get('review')
            result["rating"] = data.get('rating')
            result["business_description"] = data.get('description')
            result["sample_reviews"] = data.get('reviews', [])
            result["business_photos"] = data.get('photos', [])
            
            # ë³„ì ì´ ì—†ìœ¼ë©´ ì¶”ì •
            if result["review_count"] and not result["rating"]:
                result["estimated_rating"] = self._estimate_rating(result["review_count"])
            
            if result["review_count"] or result["rating"]:
                result["success"] = True
                
                rating_display = result["rating"] if result["rating"] else f"~{result['estimated_rating']}"
                print(f"âœ… {result['review_count']}ê°œ, {rating_display}â˜…")
            else:
                print(f"â­ï¸ ë°ì´í„° ì—†ìŒ")
        else:
            print(f"â­ï¸ ì¶”ì¶œ ì‹¤íŒ¨")
        
        # iframeì—ì„œ ë‚˜ì˜¤ê¸°
        self.driver.switch_to.default_content()
        
        return result
    
    def _estimate_rating(self, review_count: int) -> float:
        """
        ë¦¬ë·° ìˆ˜ë¡œ ë³„ì  ì¶”ì •
        """
        if review_count >= 10000:
            return 4.5
        elif review_count >= 5000:
            return 4.3
        elif review_count >= 2000:
            return 4.0
        elif review_count >= 1000:
            return 3.8
        elif review_count >= 500:
            return 3.5
        else:
            return 3.0
    
    def close(self):
        if self.driver:
            try:
                self.driver.quit()
            except:
                pass


# ============================================
# ë°ì´í„° ë³€í™˜
# ============================================
def map_industry(category: str) -> str:
    if 'ì¹´í˜' in category or 'ì»¤í”¼' in category:
        return 'cafe'
    elif 'ë² ì´ì»¤ë¦¬' in category or 'ë¹µ' in category:
        return 'bakery'
    else:
        return 'restaurant'

def extract_location(address: str) -> str:
    for loc in LOCATIONS:
        if loc in address:
            return loc
    return "ê¸°íƒ€"

def create_data(place: NaverPlace, scrape_result: Dict) -> Dict:
    industry = map_industry(place.category)
    location = extract_location(place.roadAddress or place.address)
    
    review_count = scrape_result.get("review_count") or 0
    rating = scrape_result.get("rating")
    estimated_rating = scrape_result.get("estimated_rating")
    
    # ì‹¤ì œ ë³„ì  ë˜ëŠ” ì¶”ì • ë³„ì 
    final_rating = rating if rating else estimated_rating
    
    # ì‹ ë¢°ë„ ë ˆë²¨
    if review_count >= 5000 and final_rating and final_rating >= 4.5:
        trust_level = "ê²€ì¦ëœ ì¸ê¸° ë§¤ì¥"
    elif review_count >= 2000:
        trust_level = "ì§€ì—­ ëŒ€í‘œ ë§¤ì¥"
    elif review_count >= 1000:
        trust_level = "ì…ì†Œë¬¸ ë‚œ ë§¤ì¥"
    elif review_count >= 500:
        trust_level = "ì„±ì¥ ì¤‘ì¸ ë§¤ì¥"
    else:
        trust_level = "ì‹ ê·œ ë§¤ì¥"
    
    return {
        "context": {
            "title": place.title,
            "industry": industry,
            "location": location,
            "category": place.category
        },
        "performance_data": {
            "naver_place": {
                "review_count": review_count,
                "rating": rating,
                "estimated_rating": estimated_rating,
                "has_rating": rating is not None,
                "address": place.address,
                "road_address": place.roadAddress,
                "telephone": place.telephone,
                "link": place.link
            }
        },
        "business_info": {
            "description": scrape_result.get("business_description"),
            "has_description": bool(scrape_result.get("business_description"))
        },
        "customer_voice": {
            "sample_reviews": scrape_result.get("sample_reviews", []),
            "review_count": len(scrape_result.get("sample_reviews", []))
        },
        "visual_assets": {
            "business_photos": scrape_result.get("business_photos", []),
            "photo_count": len(scrape_result.get("business_photos", []))
        },
        "market_insights": {
            "trust_level": trust_level,
            "quality_indicator": "high" if final_rating and final_rating >= 4.3 else "medium",
            "popularity_indicator": "viral" if review_count >= 5000 else "popular" if review_count >= 1000 else "growing"
        },
        "metadata": {
            "crawl_date": datetime.now().isoformat(),
            "data_quality": "complete" if rating else "partial",
            "mapx": place.mapx,
            "mapy": place.mapy,
            "data_source": "naver_desktop_complete"
        }
    }


# ============================================
# ë©”ì¸
# ============================================
def main():
    print("=" * 80)
    print("ğŸš€ ë„¤ì´ë²„ í¬ë¡¤ëŸ¬ v6 - ì™„ì „íŒ (ì „êµ­ í™•ëŒ€)")
    print("=" * 80)
    print()
    
    # Step 1: API
    print("ğŸ“‹ Step 1: ë„¤ì´ë²„ APIë¡œ 1000ê°œ ìˆ˜ì§‘ (ì „êµ­)")
    print("-" * 80)
    print(f"  ì§€ì—­: {len(LOCATIONS)}ê³³")
    print(f"  í‚¤ì›Œë“œ: ì¹´í˜ {len(KEYWORDS['ì¹´í˜'])}ê°œ, ë§›ì§‘ {len(KEYWORDS['ë§›ì§‘'])}ê°œ, ë² ì´ì»¤ë¦¬ {len(KEYWORDS['ë² ì´ì»¤ë¦¬'])}ê°œ")
    print()
    
    api = NaverAPICollector(NAVER_CLIENT_ID, NAVER_CLIENT_SECRET)
    
    queries = []
    for loc in LOCATIONS:
        for category, keywords in KEYWORDS.items():
            for kw in keywords:
                queries.append(f"{loc} {kw}")
    
    random.shuffle(queries)
    
    all_places = []
    seen = set()
    
    for idx, query in enumerate(queries, 1):
        if len(all_places) >= TARGET_COUNT:
            break
        
        items = api.search(query, DISPLAY_MAX)
        
        added = 0
        for item in items:
            key = (item.title.lower(), item.mapx, item.mapy)
            if key in seen:
                continue
            
            seen.add(key)
            all_places.append(item)
            added += 1
        
        if idx % 20 == 0:
            print(f"[{idx}] {query} â†’ ì´ {len(all_places)}")
    
    print(f"\nâœ… {len(all_places)}ê°œ ìˆ˜ì§‘")
    print()
    
    # Step 2: ì™„ì „ í¬ë¡¤ë§
    print("ğŸ“‹ Step 2: ì™„ì „ í¬ë¡¤ë§ (ì†Œê°œ/ë¦¬ë·°/ì‚¬ì§„)")
    print("-" * 80)
    
    crawler = CompleteCrawler(headless=False)
    
    results = []
    success = 0
    
    # ì „ì²´ 500ê°œ ìˆ˜ì§‘!
    print(f"ì´ {len(all_places)}ê°œ ìˆ˜ì§‘ ì˜ˆì •...")
    print()
    
    for idx, place in enumerate(all_places, 1):
        print(f"[{idx}/{len(all_places)}] {place.title[:30]} ", end="")
        
        scrape_result = crawler.scrape(place.title, place.roadAddress or place.address, idx)
        
        if scrape_result["success"]:
            success += 1
        
        final = create_data(place, scrape_result)
        results.append(final)
        
        # ì¤‘ê°„ ì €ì¥ (100ê°œë§ˆë‹¤)
        if idx % 100 == 0:
            print(f"\n  --- ì¤‘ê°„ ì €ì¥ ({idx}ê°œ) ---")
            temp_filename = f"{OUT_DIR}/naver_temp_{idx}.json"
            with open(temp_filename, "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            print(f"  ğŸ’¾ {temp_filename}")
            print(f"  âœ… ì„±ê³µë¥ : {success}/{idx} ({success/idx*100:.1f}%)")
            print()
        
        # ì¤‘ê°„ íœ´ì‹ (50ê°œë§ˆë‹¤)
        if idx % 50 == 0:
            print(f"\n  --- ì ì‹œ íœ´ì‹ (5ì´ˆ) ---")
            time.sleep(5)
            print()
    
    crawler.close()
    
    print(f"\n{'='*80}")
    print(f"âœ… ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {success}/{len(results)} ({success/len(results)*100:.1f}%)")
    print(f"{'='*80}")
    print()
    
    # í†µê³„ ì¶œë ¥
    has_rating = sum(1 for r in results if r["performance_data"]["naver_place"]["has_rating"])
    has_description = sum(1 for r in results if r["business_info"]["has_description"])
    has_reviews = sum(1 for r in results if r["customer_voice"]["review_count"] > 0)
    has_photos = sum(1 for r in results if r["visual_assets"]["photo_count"] > 0)
    
    total = len(results)
    
    print("ğŸ“Š ìµœì¢… ë°ì´í„° ìˆ˜ì§‘ í†µê³„:")
    print(f"  - ì „ì²´ ìˆ˜ì§‘: {total}ê°œ")
    print(f"  - ë³„ì  ìˆìŒ: {has_rating}ê°œ ({has_rating/total*100:.1f}%)")
    print(f"  - ë³„ì  ì¶”ì •: {total-has_rating}ê°œ ({(total-has_rating)/total*100:.1f}%)")
    print(f"  - ì—…ì²´ ì†Œê°œ: {has_description}ê°œ ({has_description/total*100:.1f}%)")
    print(f"  - ë¦¬ë·° í…ìŠ¤íŠ¸: {has_reviews}ê°œ ({has_reviews/total*100:.1f}%)")
    print(f"  - ì‚¬ì§„ URL: {has_photos}ê°œ ({has_photos/total*100:.1f}%)")
    print()
    
    # ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{OUT_DIR}/naver_complete_{timestamp}.json"
    
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ ìµœì¢… ì €ì¥: {filename}")
    print()
    
    # ìµœì¢… í‰ê°€
    success_rate = success / len(results) * 100
    
    if success_rate >= 85:
        print("ğŸ‰ğŸ‰ğŸ‰ ëŒ€ì„±ê³µ! 85% ì´ìƒ ìˆ˜ì§‘ ì™„ë£Œ!")
    elif success_rate >= 70:
        print("ğŸ‘ğŸ‘ ì„±ê³µ! 70% ì´ìƒ ìˆ˜ì§‘ ì™„ë£Œ!")
    elif success_rate >= 50:
        print("ğŸ‘ ê´œì°®ìŒ! 50% ì´ìƒ ìˆ˜ì§‘ ì™„ë£Œ!")
    else:
        print("ğŸ˜” ì¶”ê°€ ê°œì„  í•„ìš”...")
    
    print()
    print(f"ë‹¤ìŒ ë‹¨ê³„: RAG ì‹œìŠ¤í…œì— ì„ë² ë”©í•˜ê³  GPT ì—°ê²°!")


if __name__ == "__main__":
    main()
