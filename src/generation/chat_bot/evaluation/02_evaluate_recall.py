"""
í‰ê°€ ìŠ¤í¬ë¦½íŠ¸: v5.9 Recall@K ì¸¡ì •

ëª©ì :
- v5.9 ì¿¼ë¦¬ (ë‹¤ì¤‘ ì •ë‹µ, ìƒë‹´ ì˜ë„ ë°˜ì˜)ì— ëŒ€í•œ Recall@K ì¸¡ì •
- Baseline (í•„í„° ì—†ìŒ) vs Filtered (ë©”íƒ€ë°ì´í„° í•„í„°) ë¹„êµ
- ì˜ë„ë³„ ì„±ëŠ¥ ë¶„ì„

ì‹¤í–‰:
  python evaluation/08_evaluate_v59_recall.py

ì¶œë ¥:
  evaluation/results/v59_recall_results.json
"""

import json
import os
import sys
from pathlib import Path
from collections import defaultdict
from typing import List, Dict, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CPU ìŠ¤ë ˆë“œ ì„¤ì •
os.environ.setdefault("OMP_NUM_THREADS", "2")
os.environ.setdefault("MKL_NUM_THREADS", "2")

# --------------------------------------------
# ì„¤ì •
# --------------------------------------------
QUERIES_PATH = PROJECT_ROOT / "evaluation" / "results" / "synthetic_queries_v59.json"
OUTPUT_PATH = PROJECT_ROOT / "evaluation" / "results" / "v59_recall_results.json"
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

# í‰ê°€í•  K ê°’ë“¤
K_VALUES = [1, 3, 5, 10]

# --------------------------------------------
# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
# --------------------------------------------
def init_rag():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    print("ğŸ”§ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    from rag.chain import SmallBizRAG

    rag = SmallBizRAG(use_reranker=False)
    print(f"âœ… RAG ë¡œë“œ ì™„ë£Œ: {rag.vectorstore._collection.count()}ê°œ ë¬¸ì„œ\n")

    return rag


# --------------------------------------------
# Location ë§¤í•‘ (ë¶€ëª¨-ìì‹ ê´€ê³„)
# --------------------------------------------
LOCATION_GROUPS = {
    "ê°•ë‚¨": ["ê°•ë‚¨", "ì—­ì‚¼", "ì„ ë¦‰", "ì‚¼ì„±", "ì²­ë‹´", "ì‹ ì‚¬", "ë…¼í˜„", "ì••êµ¬ì •"],
    "í™ëŒ€": ["í™ëŒ€", "ì—°ë‚¨", "ìƒìˆ˜", "í•©ì •", "ë§ì›"],
    "ì‹ ì´Œ": ["ì‹ ì´Œ", "ì´ëŒ€"],
    "ê±´ëŒ€": ["ê±´ëŒ€", "êµ¬ì˜", "ê´‘ì§„"],
    "ì‹ ë¦¼": ["ì‹ ë¦¼", "ë´‰ì²œ"],
    "ì„±ìˆ˜": ["ì„±ìˆ˜", "ëšì„¬"],
    "ì„œìš¸ëŒ€": ["ì‹ ë¦¼"],
    "ì´íƒœì›": ["ì´íƒœì›", "í•œë‚¨", "ê²½ë¦¬ë‹¨ê¸¸"],
    "ê°€ë¡œìˆ˜ê¸¸": ["ì‹ ì‚¬", "ì²­ë‹´"],
    # ê¸°íƒ€ ì§€ì—­ì€ ìê¸° ìì‹ ë§Œ
}

def expand_location(location: str) -> List[str]:
    """Locationì„ í™•ì¥ (ì˜ˆ: í™ëŒ€ â†’ [í™ëŒ€, ì—°ë‚¨, ìƒìˆ˜, ...])"""
    for parent, children in LOCATION_GROUPS.items():
        if location in children or location == parent:
            return children
    return [location]


# --------------------------------------------
# ê²€ìƒ‰ í•¨ìˆ˜
# --------------------------------------------
def search_baseline(rag, query: str, k: int = 10) -> List[str]:
    """Baseline: í•„í„° ì—†ì´ semantic searchë§Œ"""
    docs = rag.vectorstore.similarity_search(query, k=k)
    doc_ids = [doc.metadata.get("doc_id", "") for doc in docs]
    return doc_ids


def search_with_filters(rag, query: str, filters: Dict[str, Any], k: int = 10) -> List[str]:
    """Filtered: ë©”íƒ€ë°ì´í„° í•„í„° ì ìš©"""
    where_filter = {}
    where_conditions = []

    # Location í•„í„°
    if "location" in filters:
        locations = expand_location(filters["location"])
        if len(locations) == 1:
            where_conditions.append({"location": {"$eq": locations[0]}})
        else:
            where_conditions.append({"location": {"$in": locations}})

    # Industry í•„í„°
    if "industry" in filters:
        where_conditions.append({"industry": {"$eq": filters["industry"]}})

    # Review count í•„í„°
    if "review_count_range" in filters:
        min_r, max_r = filters["review_count_range"]
        where_conditions.append({"review_count": {"$gte": min_r}})
        where_conditions.append({"review_count": {"$lte": max_r}})
    elif "review_count_min" in filters:
        where_conditions.append({"review_count": {"$gte": filters["review_count_min"]}})

    # Rating í•„í„°
    if "rating_range" in filters:
        min_r, max_r = filters["rating_range"]
        where_conditions.append({"rating": {"$gte": min_r}})
        where_conditions.append({"rating": {"$lte": max_r}})
    elif "rating_min" in filters:
        where_conditions.append({"rating": {"$gte": filters["rating_min"]}})

    # ì¡°í•©
    if len(where_conditions) > 1:
        where_filter = {"$and": where_conditions}
    elif len(where_conditions) == 1:
        where_filter = where_conditions[0]
    else:
        where_filter = None

    # ê²€ìƒ‰
    try:
        docs = rag.vectorstore.similarity_search(
            query,
            k=k,
            filter=where_filter if where_filter else None,
        )
        doc_ids = [doc.metadata.get("doc_id", "") for doc in docs]
        return doc_ids
    except Exception as e:
        # í•„í„°ì— ë§ëŠ” ë¬¸ì„œê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []


# --------------------------------------------
# í‰ê°€ ì§€í‘œ ê³„ì‚°
# --------------------------------------------
def calculate_recall_at_k(retrieved_ids: List[str], relevant_doc_ids: List[str], k: int) -> float:
    """Recall@K ê³„ì‚°"""
    if not relevant_doc_ids:
        return 0.0

    top_k = retrieved_ids[:k]
    hits = len(set(top_k) & set(relevant_doc_ids))
    return 1.0 if hits > 0 else 0.0


def calculate_mrr(retrieved_ids: List[str], relevant_doc_ids: List[str]) -> float:
    """MRR (Mean Reciprocal Rank) ê³„ì‚°"""
    if not relevant_doc_ids:
        return 0.0

    for rank, doc_id in enumerate(retrieved_ids, start=1):
        if doc_id in relevant_doc_ids:
            return 1.0 / rank

    return 0.0


# --------------------------------------------
# í‰ê°€ ì‹¤í–‰
# --------------------------------------------
def evaluate(rag, queries: List[Dict[str, Any]]):
    """ì „ì²´ ì¿¼ë¦¬ì— ëŒ€í•´ í‰ê°€ ì‹¤í–‰"""
    print("=" * 80)
    print("ğŸ” í‰ê°€ ì‹œì‘")
    print("=" * 80)

    # ê²°ê³¼ ì €ì¥ìš©
    baseline_results = {f"recall@{k}": [] for k in K_VALUES}
    baseline_results["mrr"] = []

    filtered_results = {f"recall@{k}": [] for k in K_VALUES}
    filtered_results["mrr"] = []

    # ì˜ë„ë³„ ê²°ê³¼
    intent_baseline = defaultdict(lambda: {f"recall@{k}": [] for k in K_VALUES})
    intent_filtered = defaultdict(lambda: {f"recall@{k}": [] for k in K_VALUES})

    # ê° ì¿¼ë¦¬ í‰ê°€
    for idx, query_item in enumerate(queries):
        query = query_item["query"]
        intent = query_item.get("intent", "unknown")
        relevant_docs = query_item.get("relevant_docs", [])
        filters = query_item.get("filters", {})

        # relevant_doc_ids ì¶”ì¶œ (relevance >= 1ì¸ ë¬¸ì„œë“¤)
        relevant_doc_ids = [doc["doc_id"] for doc in relevant_docs if doc.get("relevance", 0) >= 1]

        if not relevant_doc_ids:
            continue

        # Baseline ê²€ìƒ‰
        baseline_ids = search_baseline(rag, query, k=max(K_VALUES))

        # Filtered ê²€ìƒ‰
        filtered_ids = search_with_filters(rag, query, filters, k=max(K_VALUES))

        # Recall@K ê³„ì‚°
        for k in K_VALUES:
            baseline_recall = calculate_recall_at_k(baseline_ids, relevant_doc_ids, k)
            filtered_recall = calculate_recall_at_k(filtered_ids, relevant_doc_ids, k)

            baseline_results[f"recall@{k}"].append(baseline_recall)
            filtered_results[f"recall@{k}"].append(filtered_recall)

            intent_baseline[intent][f"recall@{k}"].append(baseline_recall)
            intent_filtered[intent][f"recall@{k}"].append(filtered_recall)

        # MRR ê³„ì‚°
        baseline_mrr = calculate_mrr(baseline_ids, relevant_doc_ids)
        filtered_mrr = calculate_mrr(filtered_ids, relevant_doc_ids)

        baseline_results["mrr"].append(baseline_mrr)
        filtered_results["mrr"].append(filtered_mrr)

        # ì§„í–‰ ìƒí™©
        if (idx + 1) % 50 == 0:
            print(f"ì§„í–‰: {idx + 1}/{len(queries)}")

    print(f"âœ… í‰ê°€ ì™„ë£Œ: {len(queries)}ê°œ ì¿¼ë¦¬\n")

    # í‰ê·  ê³„ì‚°
    baseline_avg = {metric: sum(values) / len(values) if values else 0.0
                    for metric, values in baseline_results.items()}

    filtered_avg = {metric: sum(values) / len(values) if values else 0.0
                    for metric, values in filtered_results.items()}

    # ì˜ë„ë³„ í‰ê· 
    intent_baseline_avg = {}
    intent_filtered_avg = {}

    for intent in intent_baseline.keys():
        intent_baseline_avg[intent] = {
            metric: sum(values) / len(values) if values else 0.0
            for metric, values in intent_baseline[intent].items()
        }
        intent_filtered_avg[intent] = {
            metric: sum(values) / len(values) if values else 0.0
            for metric, values in intent_filtered[intent].items()
        }

    return {
        "baseline": baseline_avg,
        "filtered": filtered_avg,
        "intent_baseline": intent_baseline_avg,
        "intent_filtered": intent_filtered_avg,
        "raw_baseline": baseline_results,
        "raw_filtered": filtered_results,
    }


# --------------------------------------------
# ê²°ê³¼ ì¶œë ¥
# --------------------------------------------
def print_results(results: Dict[str, Any], total_queries: int):
    """ê²°ê³¼ ì¶œë ¥"""
    print("=" * 80)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("=" * 80)

    baseline = results["baseline"]
    filtered = results["filtered"]

    print("\n### ì „ì²´ ì„±ëŠ¥ (Baseline vs Filtered)")
    print(f"{'Metric':<15} {'Baseline':>12} {'Filtered':>12} {'Improvement':>12}")
    print("-" * 52)

    for metric in ["recall@1", "recall@3", "recall@5", "recall@10", "mrr"]:
        b_val = baseline[metric]
        f_val = filtered[metric]
        improvement = ((f_val - b_val) / b_val * 100) if b_val > 0 else 0.0

        print(f"{metric:<15} {b_val:>11.1%} {f_val:>11.1%} {improvement:>+10.1f}%")

    # ì˜ë„ë³„ ê²°ê³¼
    print("\n### ì˜ë„ë³„ ì„±ëŠ¥ (Filtered)")
    print(f"{'Intent':<20} {'R@1':>8} {'R@3':>8} {'R@5':>8} {'R@10':>8}")
    print("-" * 60)

    for intent, metrics in results["intent_filtered"].items():
        r1 = metrics.get("recall@1", 0.0)
        r3 = metrics.get("recall@3", 0.0)
        r5 = metrics.get("recall@5", 0.0)
        r10 = metrics.get("recall@10", 0.0)

        print(f"{intent:<20} {r1:>7.1%} {r3:>7.1%} {r5:>7.1%} {r10:>7.1%}")

    print(f"\nì´ ì¿¼ë¦¬ ìˆ˜: {total_queries}")
    print("=" * 80)


# --------------------------------------------
# ë©”ì¸
# --------------------------------------------
def main():
    # ì¿¼ë¦¬ ë¡œë“œ
    print("ğŸ“‹ ì¿¼ë¦¬ ë¡œë“œ ì¤‘...")
    with open(QUERIES_PATH, "r", encoding="utf-8") as f:
        queries_data = json.load(f)

    queries = queries_data.get("queries", [])
    print(f"âœ… {len(queries)}ê°œ ì¿¼ë¦¬ ë¡œë“œ ì™„ë£Œ\n")

    # RAG ì´ˆê¸°í™”
    rag = init_rag()

    # í‰ê°€ ì‹¤í–‰
    results = evaluate(rag, queries)

    # ê²°ê³¼ ì¶œë ¥
    print_results(results, len(queries))

    # ê²°ê³¼ ì €ì¥
    output = {
        "version": "v5.9",
        "total_queries": len(queries),
        "k_values": K_VALUES,
        "baseline": results["baseline"],
        "filtered": results["filtered"],
        "intent_baseline": results["intent_baseline"],
        "intent_filtered": results["intent_filtered"],
    }

    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {OUTPUT_PATH}")
    print("=" * 80)


if __name__ == "__main__":
    main()
