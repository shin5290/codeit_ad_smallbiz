"""
End-to-End ì‹œìŠ¤í…œ í‰ê°€ (200ê°œ ì¿¼ë¦¬)

í‰ê°€ í•­ëª©:
1. IntentRouter ì •í™•ë„ (RAG vs Agent ê²½ë¡œ ì„ íƒ)
2. Agent ë¹„ìš©/Latency (web_search)
3. Self-refine íš¨ê³¼ (í’ˆì§ˆ vs ë¹„ìš©)
4. ì „ì²´ ì‹œìŠ¤í…œ ì„±ëŠ¥

ì‹¤í–‰:
    OPENAI_API_KEY=xxx TAVILY_API_KEY=xxx python 06_end_to_end_eval.py

ê²°ê³¼:
    results/end_to_end_results.json
"""

import json
import os
import sys
import time
from pathlib import Path
from typing import Dict, List, Any, Optional
from collections import defaultdict
import traceback

# Setup paths
BASE_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = BASE_DIR.parent
sys.path.insert(0, str(PROJECT_ROOT))

from agent.agent import TrendAgent
from rag.prompts import IntentRouter, UserContext
from refine.self_refine import SelfRefiner
from rag.chain import SmallBizRAG

# API keys check
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

if not OPENAI_API_KEY:
    print("âš ï¸  OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("JupyterHubì—ì„œ ì‹¤í–‰ ì¤‘ì´ë¼ë©´ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤...")
    # raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    print(f"âœ… OPENAI_API_KEY: {OPENAI_API_KEY[:10]}...")

print(f"âœ… TAVILY_API_KEY: {'ìˆìŒ' if TAVILY_API_KEY else 'ì—†ìŒ (DuckDuckGo ì‚¬ìš©)'}")


# Token counting (approximate)
def count_tokens(text: str) -> int:
    """ê°„ë‹¨í•œ í† í° ì¹´ìš´íŒ… (ì‹¤ì œë¡œëŠ” tiktoken ì‚¬ìš© ê¶Œì¥)"""
    return len(text) // 4  # ëŒ€ëµ 4ê¸€ì = 1í† í°


def estimate_cost(input_tokens: int, output_tokens: int, model: str = "gpt-4o") -> float:
    """ë¹„ìš© ì¶”ì • (GPT-4o ê¸°ì¤€)"""
    # GPT-4o: $2.50 / 1M input, $10.00 / 1M output
    if "gpt-4o" in model:
        input_cost = input_tokens / 1_000_000 * 2.50
        output_cost = output_tokens / 1_000_000 * 10.00
    elif "gpt-4o-mini" in model:
        # GPT-4o-mini: $0.15 / 1M input, $0.60 / 1M output
        input_cost = input_tokens / 1_000_000 * 0.15
        output_cost = output_tokens / 1_000_000 * 0.60
    else:
        input_cost = output_cost = 0.0

    return input_cost + output_cost


def classify_query_intent(query: str) -> str:
    """ì¿¼ë¦¬ì˜ ì˜ˆìƒ ì˜ë„ ë¶„ë¥˜ (ì •ë‹µ ë¼ë²¨ìš©)"""
    # IntentRouter ê¸°ì¤€ê³¼ ìµœëŒ€í•œ ì •ë ¬ (í‰ê°€ ê¸°ì¤€ í˜„ì‹¤í™”)
    trend_keywords = [
        "ìš”ì¦˜", "ìµœê·¼", "íŠ¸ë Œë“œ", "ìœ í–‰", "ì¸ê¸°", "í•«í•œ", "ëœ¨ëŠ”",
        "ë°ˆ", "meme", "ë­í‚¹", "2024", "2025", "2026",
        "ì‹ ìƒ", "ì‹ ë©”ë‰´", "í•«í”Œ", "ë°”ì´ëŸ´",
    ]
    stats_keywords = [
        "ê°€ì¥ ë§ì´", "ê°€ì¥ ì ê²Œ", "1ìœ„", "2ìœ„", "3ìœ„", "ìˆœìœ„",
        "ëª‡ %", "ëª‡ í¼ì„¼íŠ¸", "ë¹„ìœ¨", "í†µê³„", "ë°ì´í„°",
        "í‰ê· ", "ì „ì²´", "ì‹œì¥", "ì ìœ ìœ¨",
        "ëŒ€í•œë¯¼êµ­", "í•œêµ­", "êµ­ë‚´", "ê¸€ë¡œë²Œ", "ì„¸ê³„",
    ]
    marketing_keywords = [
        "ì˜ˆì‚°", "ë¹„ìš©", "ì§‘í–‰", "ë°°ë¶„", "ë¶„ë°°",
        "ì „ëµ", "ë°©ë²•", "ì–´ë–»ê²Œ", "ë­ê°€ ì¢‹",
        "ë¦¬í…ì…˜", "ì¬ë°©ë¬¸", "ê³ ê°", "ë§¤ì¶œ", "ë°©ë¬¸ì",
        "í™ë³´", "ê´‘ê³ ", "ë§ˆì¼€íŒ…", "í”„ë¡œëª¨ì…˜",
    ]
    doc_rag_keywords = [
        "ì‚¬ë¡€", "ì¼€ì´ìŠ¤", "ì„±ê³µ", "ì‹¤íŒ¨", "ê²½í—˜",
        "ë§¤ì¥", "ê°€ê²Œ", "ë‹¤ë¥¸ ì¹´í˜", "ë‹¤ë¥¸ ë§›ì§‘",
        "ë¦¬ë·°", "í‰ì ", "ì‚¬ì§„", "ì´¬ì˜", "ì—…ë¡œë“œ",
    ]

    query_lower = query.lower().strip()
    has_personal = any(kw in query_lower for kw in ["ìš°ë¦¬", "ë‚´", "ì €í¬", "ë‚´ ë§¤ì¥", "ìš°ë¦¬ ê°€ê²Œ"])

    if any(kw in query_lower for kw in trend_keywords):
        return "trend_web"
    if any(kw in query_lower for kw in stats_keywords) and not has_personal:
        return "stats_query"
    if any(kw in query_lower for kw in marketing_keywords) or has_personal:
        return "marketing_counsel"
    if any(kw in query_lower for kw in doc_rag_keywords):
        return "doc_rag"
    return "doc_rag"


def main():
    # ==========================================
    # 1. ë°ì´í„° ë¡œë“œ
    # ==========================================
    print("\n" + "="*60)
    print("End-to-End ì‹œìŠ¤í…œ í‰ê°€ ì‹œì‘")
    print("="*60)

    queries_file = BASE_DIR / "results" / "queries_final.json"

    if not queries_file.exists():
        raise FileNotFoundError(f"ì¿¼ë¦¬ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {queries_file}")

    with open(queries_file, "r", encoding="utf-8") as f:
        queries_data = json.load(f)

    queries = queries_data["queries"]
    print(f"\nğŸ“Š í‰ê°€ ì¿¼ë¦¬: {len(queries)}ê°œ")

    # ==========================================
    # 2. ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    # ==========================================
    print("\nğŸ”§ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    try:
        agent = TrendAgent(
            llm_model="gpt-4o-mini",  # ë¹„ìš© ì ˆê°
            verbose=False
        )
        print("  âœ… TrendAgent ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"  âŒ TrendAgent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return

    try:
        intent_router = IntentRouter()
        print("  âœ… IntentRouter ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"  âŒ IntentRouter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    try:
        refiner = SelfRefiner(llm_model="gpt-4o-mini", verbose=False)
        print("  âœ… SelfRefiner ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"  âš ï¸  SelfRefiner ì´ˆê¸°í™” ì‹¤íŒ¨ (ì„ íƒì  ê¸°ëŠ¥): {e}")
        refiner = None

    # ==========================================
    # 3. í‰ê°€ ì‹¤í–‰
    # ==========================================
    results = []
    stats = {
        "total": len(queries),
        "completed": 0,
        "errors": 0,
        "intent_accuracy": 0,
        "route_distribution": defaultdict(int),
        "total_cost": 0.0,
        "total_time": 0.0,
        "refine_improvement": 0,
    }

    print("\n" + "="*60)
    print("í‰ê°€ ì‹œì‘ (200ê°œ ì¿¼ë¦¬)")
    print("="*60)

    for idx, q in enumerate(queries, 1):
        query_text = q["query"]
        query_intent_type = q.get("intent_type", "unknown")

        print(f"\n[{idx}/{len(queries)}] {query_text[:50]}...")

        result = {
            "idx": idx,
            "query": query_text,
            "intent_type": query_intent_type,
            "expected_route": classify_query_intent(query_text),
        }

        try:
            # ---------------------------------
            # A. Intent ë¶„ë¥˜
            # ---------------------------------
            start_time = time.time()

            context = UserContext()
            detected_intent = intent_router.classify(query_text)

            intent_time = time.time() - start_time

            result["detected_intent"] = detected_intent
            result["intent_match"] = (detected_intent == result["expected_route"])
            result["intent_time"] = round(intent_time, 3)

            stats["route_distribution"][detected_intent] += 1
            if result["intent_match"]:
                stats["intent_accuracy"] += 1

            print(f"  ğŸ¯ Intent: {detected_intent} (ì˜ˆìƒ: {result['expected_route']})")

            # ---------------------------------
            # B. ë‹µë³€ ìƒì„± (ê¸°ë³¸)
            # ---------------------------------
            start_time = time.time()

            # Agent invoke
            response = agent.run(query_text)

            answer_time = time.time() - start_time

            # ì‘ë‹µ íŒŒì‹±
            if isinstance(response, dict):
                answer_text = response.get("answer") or response.get("output") or str(response)
            else:
                answer_text = str(response)

            result["answer"] = answer_text[:500]  # ì €ì¥ ìš©ëŸ‰ ì ˆì•½
            result["answer_time"] = round(answer_time, 3)

            # ë¹„ìš© ì¶”ì •
            input_tokens = count_tokens(query_text)
            output_tokens = count_tokens(answer_text)
            cost = estimate_cost(input_tokens, output_tokens, "gpt-4o-mini")

            result["input_tokens"] = input_tokens
            result["output_tokens"] = output_tokens
            result["cost"] = round(cost, 6)

            stats["total_cost"] += cost
            stats["total_time"] += answer_time

            print(f"  ğŸ’¬ ë‹µë³€ ìƒì„±: {answer_time:.2f}ì´ˆ, ${cost:.4f}")

            # ---------------------------------
            # C. Self-Refine (ì„ íƒì )
            # ---------------------------------
            if refiner and idx <= 50:  # ì²˜ìŒ 50ê°œë§Œ í…ŒìŠ¤íŠ¸
                try:
                    start_time = time.time()

                    refine_result = refiner.run(
                        question=query_text,
                        initial_answer=answer_text
                    )

                    refine_time = time.time() - start_time

                    refined_answer = refine_result.get("final_answer", answer_text)
                    refined_flag = refine_result.get("refined", False)
                    refine_used = refine_result.get("used", True)

                    refine_cost = 0.0
                    if refine_used:
                        # Refine ë¹„ìš© (ì¶”ê°€ LLM í˜¸ì¶œ: critique + refine)
                        refine_tokens = count_tokens(refined_answer)
                        refine_cost = estimate_cost(
                            count_tokens(query_text + answer_text) * 2,  # critique + refine
                            refine_tokens,
                            "gpt-4o-mini"
                        )

                    result["refined_answer"] = refined_answer[:500]
                    result["refine_time"] = round(refine_time, 3) if refine_used else 0.0
                    result["refine_cost"] = round(refine_cost, 6)
                    result["refine_used"] = refine_used
                    result["refine_improved"] = refined_flag

                    # í’ˆì§ˆ í–¥ìƒ ì—¬ë¶€
                    if refined_flag:
                        stats["refine_improvement"] += 1

                    if refine_used:
                        print(f"  âœ¨ Refine: {refine_time:.2f}ì´ˆ, ${refine_cost:.4f}, í–¥ìƒ={refined_flag}")
                    else:
                        print("  âœ¨ Refine: skipped")

                except Exception as e:
                    print(f"  âš ï¸  Refine ì‹¤íŒ¨: {e}")
                    result["refine_used"] = False
            else:
                result["refine_used"] = False

            # ---------------------------------
            # ì™„ë£Œ
            # ---------------------------------
            stats["completed"] += 1

        except Exception as e:
            print(f"  âŒ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            result["error"] = str(e)
            stats["errors"] += 1

        results.append(result)

        # ì¤‘ê°„ ì €ì¥ (10ê°œë§ˆë‹¤)
        if idx % 10 == 0:
            temp_file = BASE_DIR / "results" / "end_to_end_results_temp.json"
            with open(temp_file, "w", encoding="utf-8") as f:
                json.dump({
                    "queries": results,
                    "stats": stats,
                    "progress": f"{idx}/{len(queries)}"
                }, f, ensure_ascii=False, indent=2)
            print(f"  ğŸ’¾ ì¤‘ê°„ ì €ì¥: {temp_file}")

    # ==========================================
    # 4. ìµœì¢… í†µê³„ ê³„ì‚°
    # ==========================================
    print("\n" + "="*60)
    print("í‰ê°€ ì™„ë£Œ! ìµœì¢… í†µê³„ ê³„ì‚° ì¤‘...")
    print("="*60)

    # Intent ì •í™•ë„
    if stats["completed"] > 0:
        stats["intent_accuracy"] = round(stats["intent_accuracy"] / stats["completed"], 3)

    # í‰ê·  ë¹„ìš©/ì‹œê°„
    stats["avg_cost"] = round(stats["total_cost"] / stats["completed"], 6) if stats["completed"] > 0 else 0
    stats["avg_time"] = round(stats["total_time"] / stats["completed"], 3) if stats["completed"] > 0 else 0

    # Route distribution
    stats["route_distribution"] = dict(stats["route_distribution"])

    # ==========================================
    # 5. ê²°ê³¼ ì €ì¥
    # ==========================================
    output_file = BASE_DIR / "results" / "end_to_end_results.json"

    final_output = {
        "metadata": {
            "total_queries": len(queries),
            "completed": stats["completed"],
            "errors": stats["errors"],
            "model": "gpt-4o-mini",
            "tavily_enabled": TAVILY_API_KEY is not None,
        },
        "summary": {
            "intent_accuracy": stats["intent_accuracy"],
            "route_distribution": stats["route_distribution"],
            "avg_cost_per_query": stats["avg_cost"],
            "avg_time_per_query": stats["avg_time"],
            "total_cost": round(stats["total_cost"], 4),
            "total_time": round(stats["total_time"], 2),
            "refine_improvement_rate": round(stats["refine_improvement"] / 50, 3) if stats["refine_improvement"] > 0 else 0,
        },
        "queries": results,
    }

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")

    # ==========================================
    # 6. ìš”ì•½ ì¶œë ¥
    # ==========================================
    print("\n" + "="*60)
    print("ğŸ“Š ìµœì¢… ê²°ê³¼ ìš”ì•½")
    print("="*60)

    print(f"\nâœ… ì™„ë£Œ: {stats['completed']}/{stats['total']}ê°œ")
    print(f"âŒ ì˜¤ë¥˜: {stats['errors']}ê°œ")

    print(f"\nğŸ¯ Intent ì •í™•ë„: {stats['intent_accuracy']:.1%}")
    print(f"\nğŸ“ Route ë¶„í¬:")
    for route, count in stats["route_distribution"].items():
        pct = count / stats["completed"] * 100 if stats["completed"] > 0 else 0
        print(f"  â€¢ {route}: {count}ê°œ ({pct:.1f}%)")

    print(f"\nğŸ’° ë¹„ìš©:")
    print(f"  â€¢ ì´ ë¹„ìš©: ${stats['total_cost']:.4f}")
    print(f"  â€¢ ì¿¼ë¦¬ë‹¹ í‰ê· : ${stats['avg_cost']:.6f}")
    print(f"  â€¢ ì›” 1ë§Œ ì¿¼ë¦¬ ì˜ˆìƒ: ${stats['avg_cost'] * 10000:.2f}")

    print(f"\nâ±ï¸  ì‹œê°„:")
    print(f"  â€¢ ì´ ì‹œê°„: {stats['total_time']:.1f}ì´ˆ")
    print(f"  â€¢ ì¿¼ë¦¬ë‹¹ í‰ê· : {stats['avg_time']:.3f}ì´ˆ")

    if stats["refine_improvement"] > 0:
        print(f"\nâœ¨ Self-Refine (50ê°œ ìƒ˜í”Œ):")
        print(f"  â€¢ í’ˆì§ˆ í–¥ìƒ: {stats['refine_improvement']}/50 ({stats['refine_improvement']/50:.1%})")

    print("\n" + "="*60)
    print("í‰ê°€ ì™„ë£Œ!")
    print("="*60)


if __name__ == "__main__":
    main()
