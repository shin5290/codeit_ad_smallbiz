"""
í‰ê°€ ìŠ¤í¬ë¦½íŠ¸: Hybrid Search + Reranker ì„±ëŠ¥ ë¹„êµ

ëª©ì :
- v5.9 ì¿¼ë¦¬ë¡œ Hybrid Search (Dense + BM25) ì„±ëŠ¥ ì¸¡ì •
- Reranker (BGE Reranker, Cross-Encoder) ì„±ëŠ¥ ë¹„êµ
- Latency ì¸¡ì •

ë¹„êµêµ°:
1. Baseline: Dense only (E5)
2. Hybrid Search: Dense + BM25 (alpha = 0.1, 0.3, 0.5, 0.7, 0.9)
3. Reranker: BGE Reranker v2-m3
4. Cross-Encoder: BGE Reranker v2-m3

ì‹¤í–‰:
  python evaluation/09_hybrid_reranker_eval.py

ì¶œë ¥:
  evaluation/results/v59_hybrid_reranker_results.json
"""

import json
import os
import sys
import time
from pathlib import Path
from collections import defaultdict
from typing import List, Dict, Any, Tuple

import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CPU ìŠ¤ë ˆë“œ ì„¤ì •
os.environ.setdefault("OMP_NUM_THREADS", "2")
os.environ.setdefault("MKL_NUM_THREADS", "2")

# --------------------------------------------
# ì„¤ì •
# --------------------------------------------
QUERIES_PATH = PROJECT_ROOT / "evaluation" / "results" / "synthetic_queries_v59.json"
DOCS_PATH = PROJECT_ROOT / "data" / "processed" / "documents_v5.jsonl"
OUTPUT_PATH = PROJECT_ROOT / "evaluation" / "results" / "v59_hybrid_reranker_results.json"
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

# í‰ê°€í•  K ê°’ë“¤
K_VALUES = [1, 3, 5, 10]

# Hybrid Search alpha ê°’ë“¤ (alpha * dense + (1-alpha) * bm25)
ALPHA_VALUES = [0.1, 0.3, 0.5, 0.7, 0.9]

# Reranker ëª¨ë¸
BGE_RERANKER_MODEL = "BAAI/bge-reranker-v2-m3"


# --------------------------------------------
# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
# --------------------------------------------
def init_rag():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    print("ğŸ”§ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    from rag.chain import SmallBizRAG

    rag = SmallBizRAG(use_reranker=False)
    print(f"âœ… RAG ë¡œë“œ ì™„ë£Œ: {rag.vectorstore._collection.count()}ê°œ ë¬¸ì„œ\n")

    return rag


# --------------------------------------------
# ë¬¸ì„œ ë¡œë“œ (BM25ìš©)
# --------------------------------------------
def load_documents():
    """documents_v5.jsonl ë¡œë“œ"""
    docs = []
    with open(DOCS_PATH, "r", encoding="utf-8") as f:
        for line in f:
            if line.strip():
                doc = json.loads(line.strip())
                docs.append(doc)
    return docs


# --------------------------------------------
# BM25 ì´ˆê¸°í™”
# --------------------------------------------
def init_bm25(documents: List[Dict[str, Any]]):
    """BM25 ì¸ë±ìŠ¤ ì´ˆê¸°í™”"""
    print("ğŸ”§ BM25 ì´ˆê¸°í™” ì¤‘...")
    from rank_bm25 import BM25Okapi

    # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    corpus = []
    for doc in documents:
        text = doc.get("text", "") or doc.get("content", {}).get("text", "")
        meta = doc.get("metadata", {})
        title = meta.get("title", "")
        location = meta.get("location", "")
        industry = meta.get("industry", "")

        # ì œëª© + ì§€ì—­ + ì—…ì¢… + ë³¸ë¬¸
        full_text = f"{title} {location} {industry} {text}"

        # ê°„ë‹¨í•œ í† í°í™” (ê³µë°± ê¸°ì¤€)
        tokens = full_text.split()
        corpus.append(tokens)

    bm25 = BM25Okapi(corpus)
    print(f"âœ… BM25 ì´ˆê¸°í™” ì™„ë£Œ: {len(corpus)}ê°œ ë¬¸ì„œ\n")

    return bm25


# --------------------------------------------
# Reranker ì´ˆê¸°í™”
# --------------------------------------------
class BGEReranker:
    """BGE Reranker v2-m3"""
    def __init__(self, model_name: str = BGE_RERANKER_MODEL):
        print(f"ğŸ”§ BGE Reranker ë¡œë“œ ì¤‘: {model_name}")
        from sentence_transformers import CrossEncoder

        self.model = CrossEncoder(model_name, max_length=512, device="cpu")
        print(f"âœ… BGE Reranker ë¡œë“œ ì™„ë£Œ\n")

    def rerank(self, query: str, documents: List[Any], top_k: int = 10) -> List[Any]:
        """ë¬¸ì„œ ì¬ì •ë ¬ (LangChain Document ê°ì²´ ì§€ì›)"""
        if not documents:
            return []

        # ì¿¼ë¦¬-ë¬¸ì„œ í˜ì–´ ìƒì„±
        pairs = []
        for doc in documents:
            # LangChain Document ê°ì²´ì¸ ê²½ìš°
            if hasattr(doc, 'page_content'):
                text = doc.page_content
            # dictionaryì¸ ê²½ìš°
            elif isinstance(doc, dict):
                text = doc.get("text", "")
            else:
                text = str(doc)

            pairs.append([query, text])

        # ì ìˆ˜ ê³„ì‚°
        scores = self.model.predict(pairs)

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        scored_docs = list(zip(documents, scores))
        scored_docs.sort(key=lambda x: x[1], reverse=True)

        return [doc for doc, score in scored_docs[:top_k]]


# --------------------------------------------
# ê²€ìƒ‰ í•¨ìˆ˜ë“¤
# --------------------------------------------
def search_dense(rag, query: str, k: int = 10) -> Tuple[List[str], float]:
    """Dense ê²€ìƒ‰ (E5)"""
    start = time.time()
    docs = rag.vectorstore.similarity_search(query, k=k)
    latency = time.time() - start

    doc_ids = [doc.metadata.get("doc_id", "") for doc in docs]
    return doc_ids, latency


def search_bm25(bm25, documents: List[Dict[str, Any]], query: str, k: int = 10) -> List[str]:
    """BM25 ê²€ìƒ‰"""
    tokens = query.split()
    scores = bm25.get_scores(tokens)

    # Top K ì¸ë±ìŠ¤
    top_indices = np.argsort(scores)[::-1][:k]

    doc_ids = [documents[i].get("doc_id", "") for i in top_indices]
    return doc_ids


def search_hybrid(
    rag,
    bm25,
    documents: List[Dict[str, Any]],
    query: str,
    alpha: float = 0.5,
    k: int = 10
) -> Tuple[List[str], float]:
    """Hybrid ê²€ìƒ‰ (Dense + BM25)

    alpha: Dense ê°€ì¤‘ì¹˜ (0~1)
    - alpha=1.0: Dense only
    - alpha=0.0: BM25 only
    """
    start = time.time()

    # Dense ê²€ìƒ‰ (ë” ë§ì´ ê°€ì ¸ì˜¤ê¸°)
    dense_k = min(k * 3, 100)
    dense_docs = rag.vectorstore.similarity_search_with_score(query, k=dense_k)

    # Dense ì ìˆ˜ ì •ê·œí™” (cosine similarityëŠ” 0~1 ë²”ìœ„)
    dense_scores = {}
    for doc, score in dense_docs:
        doc_id = doc.metadata.get("doc_id", "")
        dense_scores[doc_id] = score

    # BM25 ê²€ìƒ‰
    bm25_tokens = query.split()
    bm25_raw_scores = bm25.get_scores(bm25_tokens)

    # BM25 ì ìˆ˜ ì •ê·œí™” (0~1)
    max_bm25 = max(bm25_raw_scores) if max(bm25_raw_scores) > 0 else 1.0
    bm25_scores = {}
    for i, score in enumerate(bm25_raw_scores):
        doc_id = documents[i].get("doc_id", "")
        bm25_scores[doc_id] = score / max_bm25

    # Hybrid ì ìˆ˜ ê³„ì‚°
    all_doc_ids = set(dense_scores.keys()) | set(bm25_scores.keys())
    hybrid_scores = {}

    for doc_id in all_doc_ids:
        dense_s = dense_scores.get(doc_id, 0.0)
        bm25_s = bm25_scores.get(doc_id, 0.0)
        hybrid_scores[doc_id] = alpha * dense_s + (1 - alpha) * bm25_s

    # Top K ì„ íƒ
    sorted_docs = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)
    top_doc_ids = [doc_id for doc_id, score in sorted_docs[:k]]

    latency = time.time() - start
    return top_doc_ids, latency


def search_with_reranker(
    rag,
    reranker,
    documents: List[Dict[str, Any]],
    query: str,
    k: int = 10,
    initial_k: int = 50
) -> Tuple[List[str], float]:
    """Reranker ì ìš© ê²€ìƒ‰"""
    start = time.time()

    # 1. Denseë¡œ initial_kê°œ ê²€ìƒ‰
    initial_docs = rag.vectorstore.similarity_search(query, k=initial_k)

    # 2. Rerankerë¡œ ì¬ì •ë ¬
    reranked = reranker.rerank(query, initial_docs, top_k=k)

    latency = time.time() - start

    doc_ids = [doc.metadata.get("doc_id", "") for doc in reranked]
    return doc_ids, latency


# --------------------------------------------
# í‰ê°€ ì§€í‘œ ê³„ì‚°
# --------------------------------------------
def calculate_recall_at_k(retrieved_ids: List[str], relevant_doc_ids: List[str], k: int) -> float:
    """Recall@K ê³„ì‚° (Hit@K)"""
    if not relevant_doc_ids:
        return 0.0

    top_k = retrieved_ids[:k]
    hits = len(set(top_k) & set(relevant_doc_ids))
    return 1.0 if hits > 0 else 0.0


def calculate_mrr(retrieved_ids: List[str], relevant_doc_ids: List[str]) -> float:
    """MRR (Mean Reciprocal Rank) ê³„ì‚°"""
    if not relevant_doc_ids:
        return 0.0

    for rank, doc_id in enumerate(retrieved_ids, start=1):
        if doc_id in relevant_doc_ids:
            return 1.0 / rank

    return 0.0


# --------------------------------------------
# í‰ê°€ ì‹¤í–‰
# --------------------------------------------
def evaluate_method(
    method_name: str,
    search_fn,
    queries: List[Dict[str, Any]],
    k_values: List[int] = K_VALUES
) -> Dict[str, Any]:
    """ë‹¨ì¼ ë°©ë²• í‰ê°€"""
    print(f"ğŸ” [{method_name}] í‰ê°€ ì‹œì‘...")

    results = {f"recall@{k}": [] for k in k_values}
    results["mrr"] = []
    latencies = []

    for idx, query_item in enumerate(queries):
        query = query_item["query"]
        relevant_docs = query_item.get("relevant_docs", [])

        # relevant_doc_ids ì¶”ì¶œ (relevance >= 1)
        relevant_doc_ids = [doc["doc_id"] for doc in relevant_docs if doc.get("relevance", 0) >= 1]

        if not relevant_doc_ids:
            continue

        # ê²€ìƒ‰ ì‹¤í–‰
        retrieved_ids, latency = search_fn(query, k=max(k_values))
        latencies.append(latency)

        # Recall@K ê³„ì‚°
        for k in k_values:
            recall = calculate_recall_at_k(retrieved_ids, relevant_doc_ids, k)
            results[f"recall@{k}"].append(recall)

        # MRR ê³„ì‚°
        mrr = calculate_mrr(retrieved_ids, relevant_doc_ids)
        results["mrr"].append(mrr)

        if (idx + 1) % 50 == 0:
            print(f"  [{method_name}] ì§„í–‰: {idx + 1}/{len(queries)}")

    # í‰ê·  ê³„ì‚°
    avg_results = {
        metric: sum(values) / len(values) if values else 0.0
        for metric, values in results.items()
    }

    # Latency í†µê³„
    avg_results["latency_mean"] = np.mean(latencies) if latencies else 0.0
    avg_results["latency_p50"] = np.percentile(latencies, 50) if latencies else 0.0
    avg_results["latency_p95"] = np.percentile(latencies, 95) if latencies else 0.0

    print(f"  [{method_name}] âœ… í‰ê°€ ì™„ë£Œ\n")
    return avg_results


# --------------------------------------------
# ê²°ê³¼ ì¶œë ¥
# --------------------------------------------
def print_results(all_results: Dict[str, Dict[str, Any]]):
    """ê²°ê³¼ ì¶œë ¥"""
    print("=" * 90)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼")
    print("=" * 90)

    # 1. Recall ë¹„êµ
    print("\n### Recall@K ë¹„êµ")
    print(f"{'Method':<30} {'R@1':>8} {'R@3':>8} {'R@5':>8} {'R@10':>8} {'MRR':>8}")
    print("-" * 90)

    for method_name, results in all_results.items():
        r1 = results.get("recall@1", 0.0)
        r3 = results.get("recall@3", 0.0)
        r5 = results.get("recall@5", 0.0)
        r10 = results.get("recall@10", 0.0)
        mrr = results.get("mrr", 0.0)

        print(f"{method_name:<30} {r1:>7.1%} {r3:>7.1%} {r5:>7.1%} {r10:>7.1%} {mrr:>7.1%}")

    # 2. Latency ë¹„êµ
    print("\n### Latency ë¹„êµ (ì´ˆ)")
    print(f"{'Method':<30} {'í‰ê· ':>10} {'ì¤‘ì•™ê°’(P50)':>14} {'P95':>10}")
    print("-" * 90)

    for method_name, results in all_results.items():
        mean = results.get("latency_mean", 0.0)
        p50 = results.get("latency_p50", 0.0)
        p95 = results.get("latency_p95", 0.0)

        print(f"{method_name:<30} {mean:>9.4f} {p50:>13.4f} {p95:>9.4f}")

    print("=" * 90)


# --------------------------------------------
# ë©”ì¸
# --------------------------------------------
def main():
    # ì¿¼ë¦¬ ë¡œë“œ
    print("ğŸ“‹ ì¿¼ë¦¬ ë¡œë“œ ì¤‘...")
    with open(QUERIES_PATH, "r", encoding="utf-8") as f:
        queries_data = json.load(f)

    queries = queries_data.get("queries", [])
    print(f"âœ… {len(queries)}ê°œ ì¿¼ë¦¬ ë¡œë“œ ì™„ë£Œ\n")

    # ë¬¸ì„œ ë¡œë“œ
    print("ğŸ“„ ë¬¸ì„œ ë¡œë“œ ì¤‘...")
    documents = load_documents()
    print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n")

    # RAG ì´ˆê¸°í™”
    rag = init_rag()

    # BM25 ì´ˆê¸°í™”
    bm25 = init_bm25(documents)

    # Reranker ì´ˆê¸°í™”
    reranker = BGEReranker()

    # í‰ê°€ ì‹¤í–‰
    all_results = {}

    # 1. Baseline (Dense only)
    all_results["Baseline (Dense)"] = evaluate_method(
        "Baseline (Dense)",
        lambda q, k: search_dense(rag, q, k),
        queries
    )

    # 2. Hybrid Search (ì—¬ëŸ¬ alpha ê°’)
    for alpha in ALPHA_VALUES:
        method_name = f"Hybrid (Î±={alpha})"
        all_results[method_name] = evaluate_method(
            method_name,
            lambda q, k, a=alpha: search_hybrid(rag, bm25, documents, q, alpha=a, k=k),
            queries
        )

    # 3. Reranker (Dense + BGE Reranker)
    all_results["Dense + BGE Reranker"] = evaluate_method(
        "Dense + BGE Reranker",
        lambda q, k: search_with_reranker(rag, reranker, documents, q, k=k, initial_k=50),
        queries
    )

    # 4. Hybrid + Reranker (ìµœì  alpha ì‚¬ìš©)
    best_alpha = 0.5  # ì‹¤í—˜ í›„ ìµœì ê°’ ì„ íƒ ê°€ëŠ¥
    all_results[f"Hybrid (Î±={best_alpha}) + Reranker"] = evaluate_method(
        f"Hybrid (Î±={best_alpha}) + Reranker",
        lambda q, k: search_with_reranker(
            rag,
            reranker,
            documents,
            q,
            k=k,
            initial_k=50
        ),
        queries
    )

    # ê²°ê³¼ ì¶œë ¥
    print_results(all_results)

    # ê²°ê³¼ ì €ì¥
    output = {
        "version": "v5.9",
        "total_queries": len(queries),
        "k_values": K_VALUES,
        "alpha_values": ALPHA_VALUES,
        "results": all_results
    }

    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {OUTPUT_PATH}")
    print("=" * 90)


if __name__ == "__main__":
    main()
