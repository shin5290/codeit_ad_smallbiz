"""
í‰ê°€ ìŠ¤í¬ë¦½íŠ¸: Query Rewritingìœ¼ë¡œ ìˆ«ì ì¡°ê±´ ê°œì„ 

ëª©ì :
- ìˆ«ì ì¡°ê±´ (ë¦¬ë·° ìˆ˜, í‰ì )ì„ semantic í‘œí˜„ìœ¼ë¡œ ë³€í™˜
- problem_solving, scale_based ì˜ë„ ì„±ëŠ¥ ê°œì„ 
- Baseline vs Query Rewriting ë¹„êµ

ì‹¤í–‰:
  OPENAI_API_KEY=xxx python evaluation/11_query_rewriting_eval.py

ì¶œë ¥:
  evaluation/results/v59_query_rewriting_results.json
"""

import json
import os
import sys
import time
from pathlib import Path
from collections import defaultdict
from typing import List, Dict, Any, Tuple, Optional

import numpy as np

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# CPU ìŠ¤ë ˆë“œ ì„¤ì •
os.environ.setdefault("OMP_NUM_THREADS", "2")
os.environ.setdefault("MKL_NUM_THREADS", "2")

# --------------------------------------------
# ì„¤ì •
# --------------------------------------------
QUERIES_PATH = PROJECT_ROOT / "evaluation" / "results" / "synthetic_queries_v59.json"
OUTPUT_PATH = PROJECT_ROOT / "evaluation" / "results" / "v59_query_rewriting_results.json"
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

# OpenAI API Key
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")

# í‰ê°€í•  K ê°’ë“¤
K_VALUES = [1, 3, 5, 10]

# LLM ì„¤ì •
LLM_MODEL = "gpt-4o-mini"


# --------------------------------------------
# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
# --------------------------------------------
def init_rag():
    """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    print("ğŸ”§ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    from rag.chain import SmallBizRAG

    rag = SmallBizRAG(use_reranker=False)
    print(f"âœ… RAG ë¡œë“œ ì™„ë£Œ: {rag.vectorstore._collection.count()}ê°œ ë¬¸ì„œ\n")

    return rag


# --------------------------------------------
# Query Rewriter í´ë˜ìŠ¤
# --------------------------------------------
class QueryRewriter:
    """Query Rewriting: ìˆ«ì ì¡°ê±´ì„ semantic í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""

    def __init__(self, api_key: str, model: str = LLM_MODEL):
        print("ğŸ”§ Query Rewriter ì´ˆê¸°í™” ì¤‘...")
        from openai import OpenAI

        self.client = OpenAI(api_key=api_key)
        self.model = model
        print(f"âœ… Query Rewriter ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})\n")

    def rewrite(self, query: str) -> str:
        """ì¿¼ë¦¬ ì¬ì‘ì„±: ìˆ«ì ì¡°ê±´ì„ semantic í‘œí˜„ìœ¼ë¡œ ë³€í™˜"""

        prompt = f"""ë‹¤ìŒì€ ì†Œìƒê³µì¸ ë§ˆì¼€íŒ… ìƒë‹´ ì§ˆë¬¸ì…ë‹ˆë‹¤.

ì§ˆë¬¸: {query}

ì´ ì§ˆë¬¸ì— ìˆ«ì ì¡°ê±´(ë¦¬ë·° ìˆ˜, í‰ì  ë“±)ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´, ê·¸ ìˆ«ìë¥¼ ì˜ë¯¸ì (semantic) í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ì„œ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.

ë³€í™˜ ê·œì¹™:
- "ë¦¬ë·° 1000ê°œ ì´ìƒ" â†’ "ë¦¬ë·°ê°€ ë§¤ìš° ë§ì€ ì¸ê¸° ìˆëŠ”"
- "ë¦¬ë·° 100-500ê°œ" â†’ "ì ë‹¹í•œ ë¦¬ë·°ë¥¼ ë°›ê³  ìˆëŠ”"
- "ë¦¬ë·° 100ê°œ ë¯¸ë§Œ" â†’ "ì‹ ìƒ ë˜ëŠ” ë¦¬ë·°ê°€ ì ì€"
- "í‰ì  4.5ì  ì´ìƒ" â†’ "í‰ì ì´ ë§¤ìš° ë†’ì€"
- "í‰ì  4ì ëŒ€" â†’ "í‰ì ì´ ë†’ì€"
- "í‰ì  3ì ëŒ€" â†’ "í‰ì ì´ ë³´í†µì´ê±°ë‚˜ ê°œì„ ì´ í•„ìš”í•œ"

ìˆ«ì ì¡°ê±´ì´ ì—†ë‹¤ë©´ ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

ì¬ì‘ì„±ëœ ì§ˆë¬¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”:"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=200,
            )

            rewritten = response.choices[0].message.content.strip()

            # ë”°ì˜´í‘œ ì œê±°
            rewritten = rewritten.strip('"\'')

            return rewritten

        except Exception as e:
            print(f"  âš ï¸  Query Rewriting ì‹¤íŒ¨: {e}")
            return query  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜


# --------------------------------------------
# ê²€ìƒ‰ í•¨ìˆ˜ë“¤
# --------------------------------------------
def search_baseline(rag, query: str, k: int = 10) -> Tuple[List[str], float]:
    """Baseline: ì›ë³¸ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰"""
    start = time.time()
    docs = rag.vectorstore.similarity_search(query, k=k)
    latency = time.time() - start

    doc_ids = [doc.metadata.get("doc_id", "") for doc in docs]
    return doc_ids, latency


def search_with_rewriting(
    rag,
    rewriter: QueryRewriter,
    query: str,
    k: int = 10
) -> Tuple[List[str], str, float]:
    """Query Rewriting ì ìš© ê²€ìƒ‰"""
    start = time.time()

    # 1. Query Rewriting
    rewritten_query = rewriter.rewrite(query)

    # 2. ê²€ìƒ‰
    docs = rag.vectorstore.similarity_search(rewritten_query, k=k)

    latency = time.time() - start

    doc_ids = [doc.metadata.get("doc_id", "") for doc in docs]
    return doc_ids, rewritten_query, latency


# --------------------------------------------
# í‰ê°€ ì§€í‘œ ê³„ì‚°
# --------------------------------------------
def calculate_recall_at_k(retrieved_ids: List[str], relevant_doc_ids: List[str], k: int) -> float:
    """Recall@K ê³„ì‚° (Hit@K)"""
    if not relevant_doc_ids:
        return 0.0

    top_k = retrieved_ids[:k]
    hits = len(set(top_k) & set(relevant_doc_ids))
    return 1.0 if hits > 0 else 0.0


def calculate_mrr(retrieved_ids: List[str], relevant_doc_ids: List[str]) -> float:
    """MRR (Mean Reciprocal Rank) ê³„ì‚°"""
    if not relevant_doc_ids:
        return 0.0

    for rank, doc_id in enumerate(retrieved_ids, start=1):
        if doc_id in relevant_doc_ids:
            return 1.0 / rank

    return 0.0


def calculate_relevance_at_k(
    retrieved_ids: List[str],
    ground_truth: Dict[str, int],
    k: int
) -> float:
    """Relevance@K ê³„ì‚°"""
    if not retrieved_ids:
        return 0.0

    top_k = retrieved_ids[:k]
    relevances = [ground_truth.get(doc_id, 0) for doc_id in top_k]
    return np.mean(relevances) if relevances else 0.0


# --------------------------------------------
# í‰ê°€ ì‹¤í–‰
# --------------------------------------------
def evaluate_method(
    method_name: str,
    search_fn,
    queries: List[Dict[str, Any]],
    k_values: List[int] = K_VALUES,
    save_examples: bool = False
) -> Dict[str, Any]:
    """ë‹¨ì¼ ë°©ë²• í‰ê°€"""
    print(f"ğŸ” [{method_name}] í‰ê°€ ì‹œì‘...")

    results = {f"recall@{k}": [] for k in k_values}
    results.update({f"relevance@{k}": [] for k in k_values})
    results["mrr"] = []
    latencies = []

    # ì˜ë„ë³„ ê²°ê³¼
    intent_results = defaultdict(lambda: {
        **{f"recall@{k}": [] for k in k_values},
        **{f"relevance@{k}": [] for k in k_values},
        "mrr": [],
    })

    # ì˜ˆì‹œ ì €ì¥ (Query Rewriting ì „í›„ ë¹„êµ)
    examples = []

    for idx, query_item in enumerate(queries):
        query = query_item["query"]
        intent = query_item.get("intent", "unknown")
        relevant_docs = query_item.get("relevant_docs", [])

        # relevant_doc_ids ë° ground_truth
        relevant_doc_ids = [doc["doc_id"] for doc in relevant_docs if doc.get("relevance", 0) >= 1]
        ground_truth = {doc["doc_id"]: doc.get("relevance", 0) for doc in relevant_docs}

        if not relevant_doc_ids:
            continue

        # ê²€ìƒ‰ ì‹¤í–‰
        search_result = search_fn(query, k=max(k_values))

        # Baseline vs Rewriting ì²˜ë¦¬
        if len(search_result) == 2:  # Baseline
            retrieved_ids, latency = search_result
            rewritten_query = query
        else:  # Rewriting
            retrieved_ids, rewritten_query, latency = search_result

        latencies.append(latency)

        # ì˜ˆì‹œ ì €ì¥ (ì²˜ìŒ 5ê°œë§Œ)
        if save_examples and len(examples) < 5 and rewritten_query != query:
            examples.append({
                "intent": intent,
                "original": query,
                "rewritten": rewritten_query,
            })

        # Recall@K ê³„ì‚°
        for k in k_values:
            recall = calculate_recall_at_k(retrieved_ids, relevant_doc_ids, k)
            results[f"recall@{k}"].append(recall)
            intent_results[intent][f"recall@{k}"].append(recall)

        # Relevance@K ê³„ì‚°
        for k in k_values:
            relevance = calculate_relevance_at_k(retrieved_ids, ground_truth, k)
            results[f"relevance@{k}"].append(relevance)
            intent_results[intent][f"relevance@{k}"].append(relevance)

        # MRR ê³„ì‚°
        mrr = calculate_mrr(retrieved_ids, relevant_doc_ids)
        results["mrr"].append(mrr)
        intent_results[intent]["mrr"].append(mrr)

        # ì§„í–‰ ìƒí™©
        if (idx + 1) % 20 == 0:
            print(f"  [{method_name}] ì§„í–‰: {idx + 1}/{len(queries)}")

    print(f"  [{method_name}] âœ… í‰ê°€ ì™„ë£Œ\n")

    # í‰ê·  ê³„ì‚°
    avg_results = {
        metric: sum(values) / len(values) if values else 0.0
        for metric, values in results.items()
    }

    # ì˜ë„ë³„ í‰ê· 
    intent_avg = {}
    for intent, metrics_dict in intent_results.items():
        intent_avg[intent] = {
            metric: sum(values) / len(values) if values else 0.0
            for metric, values in metrics_dict.items()
        }

    # Latency í†µê³„
    avg_results["latency_mean"] = np.mean(latencies) if latencies else 0.0
    avg_results["latency_p50"] = np.percentile(latencies, 50) if latencies else 0.0
    avg_results["latency_p95"] = np.percentile(latencies, 95) if latencies else 0.0

    return {
        "overall": avg_results,
        "by_intent": intent_avg,
        "examples": examples,
    }


# --------------------------------------------
# ê²°ê³¼ ì¶œë ¥
# --------------------------------------------
def print_results(baseline_results: Dict, rewriting_results: Dict):
    """ê²°ê³¼ ì¶œë ¥"""
    print("=" * 90)
    print("ğŸ“Š í‰ê°€ ê²°ê³¼: Baseline vs Query Rewriting")
    print("=" * 90)

    baseline = baseline_results["overall"]
    rewriting = rewriting_results["overall"]

    # 1. Recall@K ë¹„êµ
    print("\n### Recall@K ë¹„êµ")
    print(f"{'Metric':<15} {'Baseline':>12} {'Rewriting':>12} {'Improvement':>12}")
    print("-" * 52)

    for k in K_VALUES:
        b_val = baseline.get(f"recall@{k}", 0.0)
        r_val = rewriting.get(f"recall@{k}", 0.0)
        improvement = ((r_val - b_val) / b_val * 100) if b_val > 0 else 0.0

        print(f"Recall@{k:<2}       {b_val:>11.1%} {r_val:>11.1%} {improvement:>+10.1f}%")

    b_mrr = baseline.get("mrr", 0.0)
    r_mrr = rewriting.get("mrr", 0.0)
    improvement = ((r_mrr - b_mrr) / b_mrr * 100) if b_mrr > 0 else 0.0
    print(f"MRR            {b_mrr:>11.1%} {r_mrr:>11.1%} {improvement:>+10.1f}%")

    # 2. Relevance@K ë¹„êµ
    print("\n### Relevance@K ë¹„êµ (0-2)")
    print(f"{'Metric':<15} {'Baseline':>12} {'Rewriting':>12} {'Improvement':>12}")
    print("-" * 52)

    for k in K_VALUES:
        b_val = baseline.get(f"relevance@{k}", 0.0)
        r_val = rewriting.get(f"relevance@{k}", 0.0)
        improvement = ((r_val - b_val) / b_val * 100) if b_val > 0 else 0.0

        print(f"Relevance@{k:<2}    {b_val:>12.3f} {r_val:>12.3f} {improvement:>+10.1f}%")

    # 3. Latency ë¹„êµ
    print("\n### Latency ë¹„êµ (ì´ˆ)")
    print(f"{'Metric':<15} {'Baseline':>12} {'Rewriting':>12}")
    print("-" * 40)

    b_lat = baseline.get("latency_mean", 0.0)
    r_lat = rewriting.get("latency_mean", 0.0)
    print(f"í‰ê·            {b_lat:>12.4f} {r_lat:>12.4f}")

    b_p50 = baseline.get("latency_p50", 0.0)
    r_p50 = rewriting.get("latency_p50", 0.0)
    print(f"ì¤‘ì•™ê°’(P50)    {b_p50:>12.4f} {r_p50:>12.4f}")

    # 4. ì˜ë„ë³„ ê°œì„  (ë¬¸ì œ ì˜ë„ ì¤‘ì‹¬)
    print("\n### ì˜ë„ë³„ ì„±ëŠ¥ (Recall@5)")
    print(f"{'Intent':<20} {'Baseline':>12} {'Rewriting':>12} {'Improvement':>12}")
    print("-" * 57)

    for intent in ["problem_solving", "scale_based", "location_based", "channel_strategy",
                   "industry_trend", "complex_condition"]:
        if intent in baseline_results["by_intent"] and intent in rewriting_results["by_intent"]:
            b_val = baseline_results["by_intent"][intent].get("recall@5", 0.0)
            r_val = rewriting_results["by_intent"][intent].get("recall@5", 0.0)
            improvement = ((r_val - b_val) / b_val * 100) if b_val > 0 else 0.0

            print(f"{intent:<20} {b_val:>11.1%} {r_val:>11.1%} {improvement:>+10.1f}%")

    # 5. Query Rewriting ì˜ˆì‹œ
    if rewriting_results.get("examples"):
        print("\n### Query Rewriting ì˜ˆì‹œ")
        print("-" * 90)
        for i, example in enumerate(rewriting_results["examples"], 1):
            print(f"\n{i}. [{example['intent']}]")
            print(f"   ì›ë³¸:   {example['original']}")
            print(f"   ë³€í™˜:   {example['rewritten']}")

    print("\n" + "=" * 90)


# --------------------------------------------
# ë©”ì¸
# --------------------------------------------
def main():
    # ì¿¼ë¦¬ ë¡œë“œ
    print("ğŸ“‹ ì¿¼ë¦¬ ë¡œë“œ ì¤‘...")
    with open(QUERIES_PATH, "r", encoding="utf-8") as f:
        queries_data = json.load(f)

    queries = queries_data.get("queries", [])
    print(f"âœ… {len(queries)}ê°œ ì¿¼ë¦¬ ë¡œë“œ ì™„ë£Œ\n")

    # RAG ì´ˆê¸°í™”
    rag = init_rag()

    # Query Rewriter ì´ˆê¸°í™”
    rewriter = QueryRewriter(api_key=OPENAI_API_KEY)

    # í‰ê°€ ì‹¤í–‰
    print("=" * 80)
    print("ğŸ” í‰ê°€ ì‹œì‘")
    print("=" * 80)
    print()

    # 1. Baseline
    baseline_results = evaluate_method(
        "Baseline",
        lambda q, k: search_baseline(rag, q, k),
        queries
    )

    # 2. Query Rewriting
    rewriting_results = evaluate_method(
        "Query Rewriting",
        lambda q, k: search_with_rewriting(rag, rewriter, q, k),
        queries,
        save_examples=True
    )

    # ê²°ê³¼ ì¶œë ¥
    print_results(baseline_results, rewriting_results)

    # ê²°ê³¼ ì €ì¥
    output = {
        "version": "v5.9",
        "total_queries": len(queries),
        "k_values": K_VALUES,
        "baseline": baseline_results["overall"],
        "rewriting": rewriting_results["overall"],
        "baseline_by_intent": baseline_results["by_intent"],
        "rewriting_by_intent": rewriting_results["by_intent"],
        "examples": rewriting_results["examples"],
    }

    with OUTPUT_PATH.open("w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {OUTPUT_PATH}")
    print("=" * 90)


if __name__ == "__main__":
    main()
